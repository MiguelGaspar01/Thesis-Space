{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444a49bd-270c-4174-8a95-e94d53f0f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "#pip install git+https://github.com/KindXiaoming/pykan.git\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f75fa4e-1729-49f1-a197-a9b40368377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_X = pd.read_csv(r\"C:\\Users\\ADMIN\\Desktop\\Thesis Space Desktop\\Data After Preprocess\\processed_test_data_X_data.csv\")\n",
    "train_data_X = pd.read_csv(r\"C:\\Users\\ADMIN\\Desktop\\Thesis Space Desktop\\Data After Preprocess\\processed_train_data_X_data.csv\")\n",
    "test_labels_encoded = pd.read_csv(r\"C:\\Users\\ADMIN\\Desktop\\Thesis Space Desktop\\Data After Preprocess\\processed_test_data_y_data.csv\")\n",
    "train_labels_encoded = pd.read_csv(r\"C:\\Users\\ADMIN\\Desktop\\Thesis Space Desktop\\Data After Preprocess\\processed_train_data_y_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbdef64-5462-455b-96fa-863d4b36bdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "6    56000\n",
       "5    40000\n",
       "3    33393\n",
       "4    18184\n",
       "2    12264\n",
       "7    10491\n",
       "0     2000\n",
       "1     1746\n",
       "8     1133\n",
       "9      130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2c096b-e87b-4597-a60e-d432d11ad8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_distribution = {\n",
    "    0: 20000,  # Class 0 should have 56000 samples\n",
    "    1: 20000,  # Class 1 should have 56000 samples\n",
    "    2: 30000,  # Class 2 should have 56000 samples\n",
    "    3: 34000,  # Class 3 should have 56000 samples\n",
    "    4: 30000,  # Class 4 should have 56000 samples\n",
    "    5: 41000,  # Class 5 should have 56000 samples\n",
    "    6: 56000,  # Class 6 should have 56000 samples\n",
    "    7: 30000,  # Class 7 should have 56000 samples\n",
    "    8: 20000,  # Class 8 should have 56000 samples\n",
    "    9: 10000,  # Class 9 should have 56000 samples\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bae611-6e41-45ec-93de-712ad2cefa5a",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45addaf4-c17e-4cb2-94b3-a5c6629a8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Current class distribution\n",
    "unique, counts = np.unique(train_labels_encoded, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "majority_class = 6\n",
    "majority_target_size = class_distribution[majority_class] // 2\n",
    "\n",
    "# Define the target size for the minority classes (e.g., match the majority target size)\n",
    "target_distribution = {cls: majority_target_size for cls in unique}\n",
    "\n",
    "# Step 1: Under-sample the majority class\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={majority_class: majority_target_size}, random_state=42)\n",
    "#train_data_X, train_labels_encoded = under_sampler.fit_resample(train_data_X, train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96863f09-6fdd-47a1-aa2a-0c75a380e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Current class distribution\n",
    "unique, counts = np.unique(train_labels_encoded, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "\n",
    "majority_class = 5\n",
    "majority_target_size = class_distribution[majority_class] // 2\n",
    "\n",
    "# Define the target size for the minority classes (e.g., match the majority target size)\n",
    "target_distribution = {cls: majority_target_size for cls in unique}\n",
    "\n",
    "# Step 1: Under-sample the majority class\n",
    "under_sampler = RandomUnderSampler(sampling_strategy={majority_class: majority_target_size}, random_state=42)\n",
    "#train_data_X, train_labels_encoded = under_sampler.fit_resample(train_data_X, train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011c575f-d547-4b41-84c0-1af4ba290d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "6    56000\n",
       "5    40000\n",
       "3    33393\n",
       "4    18184\n",
       "2    12264\n",
       "7    10491\n",
       "0     2000\n",
       "1     1746\n",
       "8     1133\n",
       "9      130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_encoded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "901db99f-954c-4b86-bcd8-af1845f20941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c45b32-8a1e-4e15-a328-d2da3f718461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "#ENN reduces the majority class by keeping only well separated instances\n",
    "enn = EditedNearestNeighbours(sampling_strategy = \"majority\", n_neighbors = 3)\n",
    "#train_data_X, train_data_y = enn.fit_resample(train_data_X, train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af5f4e3-48a5-4a60-b951-1cb02855acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102d84fa-c8e2-425c-84f8-25b8a6272498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(sampling_strategy = \"all\", random_state=42, n_neighbors= 3)\n",
    "#train_data_X,train_data_y = adasyn.fit_resample(train_data_X, train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da2d9fc-1ea8-4570-8c1c-073cd9455e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# Combine SMOTE (oversampling) and ENN (cleaning majority class)\n",
    "smote_enn = SMOTEENN(sampling_strategy=\"not majority\", enn = enn, random_state=42)\n",
    "\n",
    "# Apply SMOTEENN\n",
    "train_data_X, train_data_y = smote_enn.fit_resample(train_data_X, train_labels_encoded)\n",
    "\n",
    "# Check the class distribution after resampling\n",
    "from collections import Counter\n",
    "#print(f\"Class distribution after resampling: {Counter(train_data_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46c173ce-09da-44d1-9c68-8d351f7e5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "1    56000\n",
       "2    56000\n",
       "6    56000\n",
       "3    56000\n",
       "4    56000\n",
       "5    56000\n",
       "8    56000\n",
       "7    56000\n",
       "9    56000\n",
       "0    21306\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a52f54-b0d2-4d50-aad1-43bcbf2637fb",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "486b73a0-a8b5-459b-acca-6894afffdd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=15)\n",
    "numeric_cols = train_data_X.select_dtypes(include = \"number\")\n",
    "rf_classifier.fit(numeric_cols, train_data_y.values.ravel())\n",
    "\n",
    "feature_importances = pd.Series(rf_classifier.feature_importances_, index=numeric_cols.columns)\n",
    "\n",
    "def plot_importance(coef, name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(8,10))\n",
    "    imp_coef.plot(kind=\"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.show()\n",
    "\n",
    "plot_importance(feature_importances, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39e9a23a-0d26-4f7f-bdc9-a59255c48132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder__proto_arp              0.001001\n",
       "encoder__proto_ospf             0.001411\n",
       "encoder__proto_sctp             0.001499\n",
       "encoder__proto_tcp              0.002474\n",
       "encoder__proto_udp              0.021177\n",
       "encoder__proto_unas             0.003322\n",
       "encoder__service_dns            0.027205\n",
       "encoder__service_ftp            0.000318\n",
       "encoder__service_ftp-data       0.000963\n",
       "encoder__service_http           0.023667\n",
       "encoder__service_smtp           0.000809\n",
       "encoder__state_CON              0.001573\n",
       "encoder__state_ECO              0.000009\n",
       "encoder__state_FIN              0.001534\n",
       "encoder__state_INT              0.002402\n",
       "encoder__state_REQ              0.000482\n",
       "encoder__state_RST              0.000010\n",
       "remainder__dur                  0.024278\n",
       "remainder__spkts                0.016953\n",
       "remainder__dpkts                0.018492\n",
       "remainder__sbytes               0.097607\n",
       "remainder__dbytes               0.034328\n",
       "remainder__rate                 0.025488\n",
       "remainder__sttl                 0.042771\n",
       "remainder__dttl                 0.009549\n",
       "remainder__sload                0.035111\n",
       "remainder__dload                0.020561\n",
       "remainder__sloss                0.014259\n",
       "remainder__dloss                0.016041\n",
       "remainder__sinpkt               0.023454\n",
       "remainder__dinpkt               0.011117\n",
       "remainder__sjit                 0.013519\n",
       "remainder__djit                 0.008867\n",
       "remainder__swin                 0.002639\n",
       "remainder__stcpb                0.008247\n",
       "remainder__dtcpb                0.009990\n",
       "remainder__dwin                 0.001111\n",
       "remainder__tcprtt               0.012244\n",
       "remainder__synack               0.012396\n",
       "remainder__ackdat               0.009581\n",
       "remainder__smean                0.074582\n",
       "remainder__dmean                0.031946\n",
       "remainder__trans_depth          0.014912\n",
       "remainder__response_body_len    0.008861\n",
       "remainder__ct_srv_src           0.032743\n",
       "remainder__ct_state_ttl         0.023484\n",
       "remainder__ct_dst_ltm           0.023912\n",
       "remainder__ct_src_dport_ltm     0.027297\n",
       "remainder__ct_dst_sport_ltm     0.033619\n",
       "remainder__ct_dst_src_ltm       0.059033\n",
       "remainder__is_ftp_login         0.000058\n",
       "remainder__ct_ftp_cmd           0.000103\n",
       "remainder__ct_flw_http_mthd     0.021052\n",
       "remainder__ct_src_ltm           0.031302\n",
       "remainder__ct_srv_dst           0.057743\n",
       "remainder__is_sm_ips_ports      0.000896\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f599f8b-d01b-4450-9d58-f774daf505af",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_features = [\n",
    "    \"sttl\",\n",
    "    \"PC1\",\n",
    "    \"dttl\",\n",
    "    \"ct_dst_src_ltm\",\n",
    "    \"ct_dst_ltm\",\n",
    "    \"ct_dst_sport_ltm\",\n",
    "    \"ct_state_ttl\",\n",
    "    \"ct_src_dport_ltm\",\n",
    "    \"ct_src_ltm\",\n",
    "    \"ct_srv_dst\",\n",
    "    \"ct_srv_src\",\n",
    "    \"ackdat\",\n",
    "    \"tcprtt\",\n",
    "    \"sbytes\",\n",
    "    \"smean\",\n",
    "    \"dload\",\n",
    "    \"rate\",\n",
    "    \"dmean\",\n",
    "    \"dur\",\n",
    "    \"PC3\",\n",
    "    \"PC10\",\n",
    "    \"dbytes\",\n",
    "    \"synack\",\n",
    "    \"PC2\",\n",
    "    \"ct_flw_http_mthd\",\n",
    "    \"trans_depth\",\n",
    "    \"PC4\",\n",
    "    \"sload\",\n",
    "    \"PC5\",\n",
    "    \"sinpkt\",\n",
    "    \"PC8\",\n",
    "    \"spkts\",\n",
    "    \"dpkts\",\n",
    "    \"PC9\",\n",
    "    \"sloss\",\n",
    "    \"sjit\",\n",
    "    \"PC7\",\n",
    "    \"dloss\",\n",
    "    \"dwin\",\n",
    "    \"swin\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72805ac9-20ef-4b74-be70-1e6bdf82cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif #computes ANOVA \n",
    "from sklearn.feature_selection import SelectKBest  #Orders f statistics and selects the Kbest ones\n",
    "\n",
    "def anova_test():\n",
    "\n",
    "    \n",
    "    X_vars = train_data_X[train_data_X.select_dtypes(include='number').columns]\n",
    "    \n",
    "    y_var = train_data_y\n",
    "    \n",
    "    anova = SelectKBest(f_classif, k=40) #we choose to keep the 10 best ones, try different numbers\n",
    "    \n",
    "    \n",
    "    X_anova = anova.fit_transform(X_vars, y_var)\n",
    "    \n",
    "    anova_results = pd.DataFrame({'Feature': X_vars.columns, \n",
    "                                  'F-value': anova.scores_,\n",
    "                                  'p-value': anova.pvalues_})\n",
    "    \n",
    "    anova_results.sort_values(by='F-value', ascending=False, inplace=True)\n",
    "\n",
    "    \n",
    "    selected_features = pd.Series(anova.get_support(), index = X_vars.columns)\n",
    "    features_to_use = [feature for feature, keep in selected_features.items() if keep]\n",
    "\n",
    "    features_to_use_str = '\", \"'.join(features_to_use)\n",
    "    \n",
    "    return selected_features, anova_results, features_to_use_str,features_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "274cf472-2ba7-457e-9b57-19cbec027843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "selected_features, anova_results, features_to_use_str,features_to_use = anova_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d62f5e-a44a-4930-9c89-85e4d3f84270",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features_to_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fec4c1-e780-4ade-b035-e8e6469310af",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035c2ae-2be5-4249-bb01-77bc7d29585d",
   "metadata": {},
   "source": [
    "## Modelling EfficentKan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ccf7cd-d4f0-49f5-9b06-ed0b2d444d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_X_tensor = torch.tensor(train_data_X[features].values, dtype=torch.float32).squeeze()\n",
    "#test_X_tensor = torch.tensor(test_data_X[features].values, dtype=torch.float32).squeeze() #changed to have all features\n",
    "\n",
    "train_X_tensor = torch.tensor(train_data_X[features_to_use].values, dtype=torch.float32).squeeze()\n",
    "test_X_tensor = torch.tensor(test_data_X[features_to_use].values, dtype=torch.float32).squeeze()\n",
    "\n",
    "train_Y_tensor = torch.tensor(train_data_y.values, dtype=torch.long).squeeze()\n",
    "\n",
    "test_Y_tensor = torch.tensor(test_labels_encoded.values, dtype=torch.long).squeeze()\n",
    "#a dictionary with the 4 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1357325e-6c3f-4696-ac8c-9c4ab4c8a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b9c01a6-69d2-466f-88eb-3bfa57eee8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_X_tensor, train_Y_tensor)\n",
    "test_dataset = TensorDataset(test_X_tensor, test_Y_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e638f1d3-b977-41bb-b150-6698ce803af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2519ea5f-6950-458e-aaae-c3d4aae9ecf0",
   "metadata": {},
   "source": [
    "## Modelling with efficient Kan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c90c1ca-27d1-4494-9b5b-d6ec3020f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_kan import KAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4eaf5f-fbfd-4db6-b316-e5b93ee0a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define model\n",
    "model = KAN([40, 64, 10])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# Define learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "# Define loss\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8606303-5979-499a-9480-020063f0530e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.grid_size, model.spline_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00e210a4-fe86-4b81-813b-4ddfc926ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "370ae572-eb21-41d2-b309-d7526d5413cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KAN([40, 10,10, 4,10],grid_size = 4, spline_order = 2, scale_noise=0.1, scale_base=0.2, scale_spline=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d53a788-40a9-46d1-b42e-dc9948a173d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0  # For accuracy tracking\n",
    "    total = 0\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Train Accuracy: {accuracy:.4f}%\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            # Collect all predictions and true labels for F1-score calculation\n",
    "            all_preds.extend(pred.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted') * 100  # Weighted F1-score to handle class imbalance\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro') * 100  # Macro F1-score to handle class imbalance\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}, F1-score: {f1:.2f}%, Macro_F1-Score: {f1_macro: .2f}%  \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b92990a-790c-4d0d-b1fe-550199e0b99a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.305709  [    0/525306]\n",
      "loss: 2.285767  [ 1600/525306]\n",
      "loss: 2.296463  [ 3200/525306]\n",
      "loss: 2.305368  [ 4800/525306]\n",
      "loss: 2.246013  [ 6400/525306]\n",
      "loss: 2.239725  [ 8000/525306]\n",
      "loss: 2.235504  [ 9600/525306]\n",
      "loss: 2.182312  [11200/525306]\n",
      "loss: 2.054942  [12800/525306]\n",
      "loss: 2.068282  [14400/525306]\n",
      "loss: 2.059515  [16000/525306]\n",
      "loss: 1.867981  [17600/525306]\n",
      "loss: 2.116738  [19200/525306]\n",
      "loss: 1.905615  [20800/525306]\n",
      "loss: 1.717109  [22400/525306]\n",
      "loss: 2.096778  [24000/525306]\n",
      "loss: 1.770264  [25600/525306]\n",
      "loss: 1.701589  [27200/525306]\n",
      "loss: 1.517267  [28800/525306]\n",
      "loss: 1.695374  [30400/525306]\n",
      "loss: 1.502354  [32000/525306]\n",
      "loss: 1.608741  [33600/525306]\n",
      "loss: 1.655699  [35200/525306]\n",
      "loss: 1.254934  [36800/525306]\n",
      "loss: 1.631229  [38400/525306]\n",
      "loss: 1.673294  [40000/525306]\n",
      "loss: 2.186661  [41600/525306]\n",
      "loss: 1.690411  [43200/525306]\n",
      "loss: 1.368729  [44800/525306]\n",
      "loss: 1.452599  [46400/525306]\n",
      "loss: 1.903442  [48000/525306]\n",
      "loss: 1.700625  [49600/525306]\n",
      "loss: 1.518589  [51200/525306]\n",
      "loss: 1.719043  [52800/525306]\n",
      "loss: 1.453647  [54400/525306]\n",
      "loss: 1.487088  [56000/525306]\n",
      "loss: 1.392962  [57600/525306]\n",
      "loss: 1.717592  [59200/525306]\n",
      "loss: 1.702461  [60800/525306]\n",
      "loss: 1.444526  [62400/525306]\n",
      "loss: 1.531997  [64000/525306]\n",
      "loss: 1.487378  [65600/525306]\n",
      "loss: 1.774235  [67200/525306]\n",
      "loss: 1.483947  [68800/525306]\n",
      "loss: 1.580608  [70400/525306]\n",
      "loss: 1.234714  [72000/525306]\n",
      "loss: 1.112911  [73600/525306]\n",
      "loss: 1.281327  [75200/525306]\n",
      "loss: 1.290165  [76800/525306]\n",
      "loss: 1.202090  [78400/525306]\n",
      "loss: 1.225284  [80000/525306]\n",
      "loss: 1.465600  [81600/525306]\n",
      "loss: 1.253070  [83200/525306]\n",
      "loss: 1.382165  [84800/525306]\n",
      "loss: 1.122283  [86400/525306]\n",
      "loss: 1.450146  [88000/525306]\n",
      "loss: 1.078390  [89600/525306]\n",
      "loss: 0.930016  [91200/525306]\n",
      "loss: 1.357140  [92800/525306]\n",
      "loss: 1.270750  [94400/525306]\n",
      "loss: 0.916519  [96000/525306]\n",
      "loss: 1.229234  [97600/525306]\n",
      "loss: 0.948296  [99200/525306]\n",
      "loss: 1.787761  [100800/525306]\n",
      "loss: 0.746132  [102400/525306]\n",
      "loss: 1.313118  [104000/525306]\n",
      "loss: 1.222922  [105600/525306]\n",
      "loss: 1.183326  [107200/525306]\n",
      "loss: 0.929688  [108800/525306]\n",
      "loss: 1.614971  [110400/525306]\n",
      "loss: 1.543934  [112000/525306]\n",
      "loss: 1.456456  [113600/525306]\n",
      "loss: 1.025063  [115200/525306]\n",
      "loss: 1.615642  [116800/525306]\n",
      "loss: 1.247342  [118400/525306]\n",
      "loss: 1.462825  [120000/525306]\n",
      "loss: 1.442188  [121600/525306]\n",
      "loss: 1.234780  [123200/525306]\n",
      "loss: 1.439827  [124800/525306]\n",
      "loss: 1.214837  [126400/525306]\n",
      "loss: 1.913067  [128000/525306]\n",
      "loss: 1.232169  [129600/525306]\n",
      "loss: 1.204125  [131200/525306]\n",
      "loss: 1.096097  [132800/525306]\n",
      "loss: 1.084741  [134400/525306]\n",
      "loss: 0.982004  [136000/525306]\n",
      "loss: 0.918582  [137600/525306]\n",
      "loss: 1.232896  [139200/525306]\n",
      "loss: 1.082881  [140800/525306]\n",
      "loss: 0.842637  [142400/525306]\n",
      "loss: 0.598439  [144000/525306]\n",
      "loss: 1.039229  [145600/525306]\n",
      "loss: 0.886544  [147200/525306]\n",
      "loss: 1.101800  [148800/525306]\n",
      "loss: 1.289747  [150400/525306]\n",
      "loss: 1.140257  [152000/525306]\n",
      "loss: 1.323527  [153600/525306]\n",
      "loss: 0.861198  [155200/525306]\n",
      "loss: 1.375451  [156800/525306]\n",
      "loss: 0.960006  [158400/525306]\n",
      "loss: 1.092745  [160000/525306]\n",
      "loss: 1.214681  [161600/525306]\n",
      "loss: 1.337608  [163200/525306]\n",
      "loss: 0.762295  [164800/525306]\n",
      "loss: 1.194924  [166400/525306]\n",
      "loss: 1.098847  [168000/525306]\n",
      "loss: 1.033310  [169600/525306]\n",
      "loss: 0.992834  [171200/525306]\n",
      "loss: 1.273837  [172800/525306]\n",
      "loss: 1.067035  [174400/525306]\n",
      "loss: 0.728351  [176000/525306]\n",
      "loss: 1.360012  [177600/525306]\n",
      "loss: 0.936033  [179200/525306]\n",
      "loss: 1.165109  [180800/525306]\n",
      "loss: 0.851347  [182400/525306]\n",
      "loss: 1.003709  [184000/525306]\n",
      "loss: 0.936614  [185600/525306]\n",
      "loss: 0.694107  [187200/525306]\n",
      "loss: 1.093451  [188800/525306]\n",
      "loss: 1.188777  [190400/525306]\n",
      "loss: 0.892659  [192000/525306]\n",
      "loss: 1.548951  [193600/525306]\n",
      "loss: 1.048385  [195200/525306]\n",
      "loss: 0.957585  [196800/525306]\n",
      "loss: 1.298928  [198400/525306]\n",
      "loss: 1.330325  [200000/525306]\n",
      "loss: 0.957120  [201600/525306]\n",
      "loss: 1.220296  [203200/525306]\n",
      "loss: 0.771771  [204800/525306]\n",
      "loss: 1.254217  [206400/525306]\n",
      "loss: 1.017970  [208000/525306]\n",
      "loss: 1.338162  [209600/525306]\n",
      "loss: 1.208306  [211200/525306]\n",
      "loss: 0.981614  [212800/525306]\n",
      "loss: 1.198495  [214400/525306]\n",
      "loss: 1.161958  [216000/525306]\n",
      "loss: 1.086344  [217600/525306]\n",
      "loss: 0.772473  [219200/525306]\n",
      "loss: 0.875171  [220800/525306]\n",
      "loss: 0.968830  [222400/525306]\n",
      "loss: 0.909387  [224000/525306]\n",
      "loss: 0.863594  [225600/525306]\n",
      "loss: 1.078202  [227200/525306]\n",
      "loss: 0.777650  [228800/525306]\n",
      "loss: 0.842010  [230400/525306]\n",
      "loss: 0.814109  [232000/525306]\n",
      "loss: 0.918181  [233600/525306]\n",
      "loss: 1.519810  [235200/525306]\n",
      "loss: 1.204992  [236800/525306]\n",
      "loss: 1.253484  [238400/525306]\n",
      "loss: 0.874884  [240000/525306]\n",
      "loss: 1.201751  [241600/525306]\n",
      "loss: 1.075584  [243200/525306]\n",
      "loss: 1.436860  [244800/525306]\n",
      "loss: 0.803098  [246400/525306]\n",
      "loss: 1.705297  [248000/525306]\n",
      "loss: 0.870775  [249600/525306]\n",
      "loss: 0.724500  [251200/525306]\n",
      "loss: 1.318556  [252800/525306]\n",
      "loss: 0.834292  [254400/525306]\n",
      "loss: 1.156359  [256000/525306]\n",
      "loss: 0.597841  [257600/525306]\n",
      "loss: 1.011745  [259200/525306]\n",
      "loss: 1.447022  [260800/525306]\n",
      "loss: 0.996812  [262400/525306]\n",
      "loss: 0.820401  [264000/525306]\n",
      "loss: 0.945349  [265600/525306]\n",
      "loss: 0.975275  [267200/525306]\n",
      "loss: 0.819516  [268800/525306]\n",
      "loss: 1.497877  [270400/525306]\n",
      "loss: 0.876654  [272000/525306]\n",
      "loss: 0.579183  [273600/525306]\n",
      "loss: 1.057233  [275200/525306]\n",
      "loss: 0.958744  [276800/525306]\n",
      "loss: 1.157323  [278400/525306]\n",
      "loss: 0.578392  [280000/525306]\n",
      "loss: 1.019052  [281600/525306]\n",
      "loss: 1.141880  [283200/525306]\n",
      "loss: 1.146746  [284800/525306]\n",
      "loss: 1.173989  [286400/525306]\n",
      "loss: 1.044500  [288000/525306]\n",
      "loss: 0.930492  [289600/525306]\n",
      "loss: 1.333069  [291200/525306]\n",
      "loss: 0.871179  [292800/525306]\n",
      "loss: 1.024805  [294400/525306]\n",
      "loss: 1.101201  [296000/525306]\n",
      "loss: 0.904721  [297600/525306]\n",
      "loss: 0.813612  [299200/525306]\n",
      "loss: 1.173641  [300800/525306]\n",
      "loss: 0.845793  [302400/525306]\n",
      "loss: 1.105105  [304000/525306]\n",
      "loss: 1.314841  [305600/525306]\n",
      "loss: 1.286546  [307200/525306]\n",
      "loss: 0.818332  [308800/525306]\n",
      "loss: 1.169138  [310400/525306]\n",
      "loss: 1.252713  [312000/525306]\n",
      "loss: 1.088404  [313600/525306]\n",
      "loss: 0.970791  [315200/525306]\n",
      "loss: 0.794817  [316800/525306]\n",
      "loss: 1.002188  [318400/525306]\n",
      "loss: 1.053738  [320000/525306]\n",
      "loss: 1.074430  [321600/525306]\n",
      "loss: 1.114412  [323200/525306]\n",
      "loss: 1.042722  [324800/525306]\n",
      "loss: 0.900572  [326400/525306]\n",
      "loss: 0.646543  [328000/525306]\n",
      "loss: 0.567681  [329600/525306]\n",
      "loss: 0.922783  [331200/525306]\n",
      "loss: 1.124257  [332800/525306]\n",
      "loss: 0.476804  [334400/525306]\n",
      "loss: 0.790922  [336000/525306]\n",
      "loss: 1.147865  [337600/525306]\n",
      "loss: 1.011818  [339200/525306]\n",
      "loss: 1.231772  [340800/525306]\n",
      "loss: 1.340521  [342400/525306]\n",
      "loss: 0.795923  [344000/525306]\n",
      "loss: 1.581433  [345600/525306]\n",
      "loss: 0.947732  [347200/525306]\n",
      "loss: 0.896064  [348800/525306]\n",
      "loss: 0.799451  [350400/525306]\n",
      "loss: 1.065492  [352000/525306]\n",
      "loss: 0.742077  [353600/525306]\n",
      "loss: 1.024502  [355200/525306]\n",
      "loss: 0.574436  [356800/525306]\n",
      "loss: 1.311197  [358400/525306]\n",
      "loss: 1.342722  [360000/525306]\n",
      "loss: 1.598864  [361600/525306]\n",
      "loss: 0.843400  [363200/525306]\n",
      "loss: 1.158001  [364800/525306]\n",
      "loss: 1.051422  [366400/525306]\n",
      "loss: 1.125782  [368000/525306]\n",
      "loss: 0.736555  [369600/525306]\n",
      "loss: 0.870642  [371200/525306]\n",
      "loss: 1.172225  [372800/525306]\n",
      "loss: 1.056219  [374400/525306]\n",
      "loss: 0.883814  [376000/525306]\n",
      "loss: 0.879649  [377600/525306]\n",
      "loss: 1.241089  [379200/525306]\n",
      "loss: 1.737146  [380800/525306]\n",
      "loss: 0.995764  [382400/525306]\n",
      "loss: 0.777343  [384000/525306]\n",
      "loss: 1.116256  [385600/525306]\n",
      "loss: 0.634792  [387200/525306]\n",
      "loss: 1.054718  [388800/525306]\n",
      "loss: 0.993941  [390400/525306]\n",
      "loss: 0.676057  [392000/525306]\n",
      "loss: 1.444063  [393600/525306]\n",
      "loss: 0.919027  [395200/525306]\n",
      "loss: 0.883433  [396800/525306]\n",
      "loss: 0.661714  [398400/525306]\n",
      "loss: 0.715274  [400000/525306]\n",
      "loss: 1.432813  [401600/525306]\n",
      "loss: 0.483830  [403200/525306]\n",
      "loss: 0.821839  [404800/525306]\n",
      "loss: 1.111820  [406400/525306]\n",
      "loss: 1.807689  [408000/525306]\n",
      "loss: 1.236041  [409600/525306]\n",
      "loss: 1.019514  [411200/525306]\n",
      "loss: 0.750239  [412800/525306]\n",
      "loss: 1.051359  [414400/525306]\n",
      "loss: 1.181390  [416000/525306]\n",
      "loss: 0.608545  [417600/525306]\n",
      "loss: 0.886935  [419200/525306]\n",
      "loss: 0.834837  [420800/525306]\n",
      "loss: 1.207533  [422400/525306]\n",
      "loss: 0.620377  [424000/525306]\n",
      "loss: 1.212601  [425600/525306]\n",
      "loss: 0.707860  [427200/525306]\n",
      "loss: 1.007019  [428800/525306]\n",
      "loss: 0.915284  [430400/525306]\n",
      "loss: 0.859305  [432000/525306]\n",
      "loss: 1.056071  [433600/525306]\n",
      "loss: 1.598169  [435200/525306]\n",
      "loss: 1.411500  [436800/525306]\n",
      "loss: 1.244241  [438400/525306]\n",
      "loss: 0.951603  [440000/525306]\n",
      "loss: 0.645418  [441600/525306]\n",
      "loss: 0.984084  [443200/525306]\n",
      "loss: 1.049924  [444800/525306]\n",
      "loss: 0.927213  [446400/525306]\n",
      "loss: 1.417328  [448000/525306]\n",
      "loss: 0.956773  [449600/525306]\n",
      "loss: 1.059676  [451200/525306]\n",
      "loss: 1.114815  [452800/525306]\n",
      "loss: 0.842777  [454400/525306]\n",
      "loss: 0.491336  [456000/525306]\n",
      "loss: 0.762745  [457600/525306]\n",
      "loss: 0.863839  [459200/525306]\n",
      "loss: 1.410312  [460800/525306]\n",
      "loss: 1.255799  [462400/525306]\n",
      "loss: 1.025478  [464000/525306]\n",
      "loss: 1.051808  [465600/525306]\n",
      "loss: 1.245292  [467200/525306]\n",
      "loss: 0.872229  [468800/525306]\n",
      "loss: 0.743645  [470400/525306]\n",
      "loss: 1.365890  [472000/525306]\n",
      "loss: 0.876672  [473600/525306]\n",
      "loss: 0.889175  [475200/525306]\n",
      "loss: 1.021868  [476800/525306]\n",
      "loss: 0.863078  [478400/525306]\n",
      "loss: 0.816442  [480000/525306]\n",
      "loss: 0.895293  [481600/525306]\n",
      "loss: 1.439948  [483200/525306]\n",
      "loss: 0.897985  [484800/525306]\n",
      "loss: 0.743067  [486400/525306]\n",
      "loss: 0.779969  [488000/525306]\n",
      "loss: 1.006651  [489600/525306]\n",
      "loss: 1.218408  [491200/525306]\n",
      "loss: 1.161942  [492800/525306]\n",
      "loss: 1.486042  [494400/525306]\n",
      "loss: 0.799826  [496000/525306]\n",
      "loss: 1.049902  [497600/525306]\n",
      "loss: 0.913047  [499200/525306]\n",
      "loss: 1.270714  [500800/525306]\n",
      "loss: 1.234945  [502400/525306]\n",
      "loss: 0.920550  [504000/525306]\n",
      "loss: 1.123268  [505600/525306]\n",
      "loss: 0.854197  [507200/525306]\n",
      "loss: 1.110565  [508800/525306]\n",
      "loss: 1.118356  [510400/525306]\n",
      "loss: 0.758349  [512000/525306]\n",
      "loss: 0.837587  [513600/525306]\n",
      "loss: 0.985856  [515200/525306]\n",
      "loss: 0.734758  [516800/525306]\n",
      "loss: 1.163874  [518400/525306]\n",
      "loss: 0.820126  [520000/525306]\n",
      "loss: 0.798478  [521600/525306]\n",
      "loss: 1.055661  [523200/525306]\n",
      "loss: 1.146937  [524800/525306]\n",
      "Train Accuracy: 58.0039%\n",
      "Test Error: \n",
      " Accuracy: 60.3%, Avg loss: 1.003190, F1-score: 66.22%, Macro_F1-Score:  29.44%  \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.832366  [    0/525306]\n",
      "loss: 1.142000  [ 1600/525306]\n",
      "loss: 1.249048  [ 3200/525306]\n",
      "loss: 1.009723  [ 4800/525306]\n",
      "loss: 1.187846  [ 6400/525306]\n",
      "loss: 1.130899  [ 8000/525306]\n",
      "loss: 0.902102  [ 9600/525306]\n",
      "loss: 0.650257  [11200/525306]\n",
      "loss: 0.829121  [12800/525306]\n",
      "loss: 0.722338  [14400/525306]\n",
      "loss: 0.760564  [16000/525306]\n",
      "loss: 1.032468  [17600/525306]\n",
      "loss: 0.779082  [19200/525306]\n",
      "loss: 1.011824  [20800/525306]\n",
      "loss: 0.833364  [22400/525306]\n",
      "loss: 1.151693  [24000/525306]\n",
      "loss: 1.250009  [25600/525306]\n",
      "loss: 1.193335  [27200/525306]\n",
      "loss: 0.701442  [28800/525306]\n",
      "loss: 0.932129  [30400/525306]\n",
      "loss: 1.078020  [32000/525306]\n",
      "loss: 0.792297  [33600/525306]\n",
      "loss: 0.720915  [35200/525306]\n",
      "loss: 0.983308  [36800/525306]\n",
      "loss: 0.824558  [38400/525306]\n",
      "loss: 0.976656  [40000/525306]\n",
      "loss: 0.730214  [41600/525306]\n",
      "loss: 0.653463  [43200/525306]\n",
      "loss: 0.514172  [44800/525306]\n",
      "loss: 0.995965  [46400/525306]\n",
      "loss: 1.224237  [48000/525306]\n",
      "loss: 0.989868  [49600/525306]\n",
      "loss: 0.956552  [51200/525306]\n",
      "loss: 1.024962  [52800/525306]\n",
      "loss: 0.930284  [54400/525306]\n",
      "loss: 1.129905  [56000/525306]\n",
      "loss: 0.530806  [57600/525306]\n",
      "loss: 0.819700  [59200/525306]\n",
      "loss: 0.692094  [60800/525306]\n",
      "loss: 1.171913  [62400/525306]\n",
      "loss: 1.004398  [64000/525306]\n",
      "loss: 1.220593  [65600/525306]\n",
      "loss: 1.223744  [67200/525306]\n",
      "loss: 1.023842  [68800/525306]\n",
      "loss: 0.801914  [70400/525306]\n",
      "loss: 0.802539  [72000/525306]\n",
      "loss: 1.045084  [73600/525306]\n",
      "loss: 1.186419  [75200/525306]\n",
      "loss: 0.688330  [76800/525306]\n",
      "loss: 0.584825  [78400/525306]\n",
      "loss: 1.348813  [80000/525306]\n",
      "loss: 0.551663  [81600/525306]\n",
      "loss: 0.749103  [83200/525306]\n",
      "loss: 1.119661  [84800/525306]\n",
      "loss: 0.858795  [86400/525306]\n",
      "loss: 0.773225  [88000/525306]\n",
      "loss: 0.968216  [89600/525306]\n",
      "loss: 0.882096  [91200/525306]\n",
      "loss: 1.006912  [92800/525306]\n",
      "loss: 0.874152  [94400/525306]\n",
      "loss: 1.186440  [96000/525306]\n",
      "loss: 0.903714  [97600/525306]\n",
      "loss: 0.546073  [99200/525306]\n",
      "loss: 1.205103  [100800/525306]\n",
      "loss: 0.738934  [102400/525306]\n",
      "loss: 0.756400  [104000/525306]\n",
      "loss: 0.974239  [105600/525306]\n",
      "loss: 0.697716  [107200/525306]\n",
      "loss: 1.212216  [108800/525306]\n",
      "loss: 1.084708  [110400/525306]\n",
      "loss: 0.846422  [112000/525306]\n",
      "loss: 1.145291  [113600/525306]\n",
      "loss: 0.748513  [115200/525306]\n",
      "loss: 0.975421  [116800/525306]\n",
      "loss: 0.855516  [118400/525306]\n",
      "loss: 1.017298  [120000/525306]\n",
      "loss: 0.738585  [121600/525306]\n",
      "loss: 0.529560  [123200/525306]\n",
      "loss: 0.982830  [124800/525306]\n",
      "loss: 0.675096  [126400/525306]\n",
      "loss: 1.073109  [128000/525306]\n",
      "loss: 1.105129  [129600/525306]\n",
      "loss: 0.884475  [131200/525306]\n",
      "loss: 0.994980  [132800/525306]\n",
      "loss: 0.890376  [134400/525306]\n",
      "loss: 0.510720  [136000/525306]\n",
      "loss: 0.605409  [137600/525306]\n",
      "loss: 0.613570  [139200/525306]\n",
      "loss: 1.044458  [140800/525306]\n",
      "loss: 1.062179  [142400/525306]\n",
      "loss: 0.799081  [144000/525306]\n",
      "loss: 0.704088  [145600/525306]\n",
      "loss: 1.011283  [147200/525306]\n",
      "loss: 0.729886  [148800/525306]\n",
      "loss: 0.821445  [150400/525306]\n",
      "loss: 1.028811  [152000/525306]\n",
      "loss: 0.761949  [153600/525306]\n",
      "loss: 0.969540  [155200/525306]\n",
      "loss: 0.592763  [156800/525306]\n",
      "loss: 1.024653  [158400/525306]\n",
      "loss: 0.817184  [160000/525306]\n",
      "loss: 0.454994  [161600/525306]\n",
      "loss: 1.145632  [163200/525306]\n",
      "loss: 0.958493  [164800/525306]\n",
      "loss: 0.432132  [166400/525306]\n",
      "loss: 1.039670  [168000/525306]\n",
      "loss: 0.928855  [169600/525306]\n",
      "loss: 0.772259  [171200/525306]\n",
      "loss: 0.723698  [172800/525306]\n",
      "loss: 0.888444  [174400/525306]\n",
      "loss: 0.952241  [176000/525306]\n",
      "loss: 1.238853  [177600/525306]\n",
      "loss: 0.981604  [179200/525306]\n",
      "loss: 0.975037  [180800/525306]\n",
      "loss: 0.804282  [182400/525306]\n",
      "loss: 0.938698  [184000/525306]\n",
      "loss: 1.289173  [185600/525306]\n",
      "loss: 0.769431  [187200/525306]\n",
      "loss: 0.961632  [188800/525306]\n",
      "loss: 0.991647  [190400/525306]\n",
      "loss: 0.650533  [192000/525306]\n",
      "loss: 0.804736  [193600/525306]\n",
      "loss: 1.145205  [195200/525306]\n",
      "loss: 1.015168  [196800/525306]\n",
      "loss: 1.185015  [198400/525306]\n",
      "loss: 0.763009  [200000/525306]\n",
      "loss: 0.673164  [201600/525306]\n",
      "loss: 0.817870  [203200/525306]\n",
      "loss: 0.825112  [204800/525306]\n",
      "loss: 1.037075  [206400/525306]\n",
      "loss: 1.123241  [208000/525306]\n",
      "loss: 1.163910  [209600/525306]\n",
      "loss: 1.434398  [211200/525306]\n",
      "loss: 0.648218  [212800/525306]\n",
      "loss: 0.931009  [214400/525306]\n",
      "loss: 1.484772  [216000/525306]\n",
      "loss: 1.215078  [217600/525306]\n",
      "loss: 1.006775  [219200/525306]\n",
      "loss: 1.440813  [220800/525306]\n",
      "loss: 0.667827  [222400/525306]\n",
      "loss: 1.247978  [224000/525306]\n",
      "loss: 1.132313  [225600/525306]\n",
      "loss: 0.677896  [227200/525306]\n",
      "loss: 0.707052  [228800/525306]\n",
      "loss: 1.191709  [230400/525306]\n",
      "loss: 1.357949  [232000/525306]\n",
      "loss: 0.807690  [233600/525306]\n",
      "loss: 0.812817  [235200/525306]\n",
      "loss: 0.949794  [236800/525306]\n",
      "loss: 0.792758  [238400/525306]\n",
      "loss: 0.573580  [240000/525306]\n",
      "loss: 1.135292  [241600/525306]\n",
      "loss: 1.135559  [243200/525306]\n",
      "loss: 1.481920  [244800/525306]\n",
      "loss: 1.686460  [246400/525306]\n",
      "loss: 0.810756  [248000/525306]\n",
      "loss: 0.620895  [249600/525306]\n",
      "loss: 0.863917  [251200/525306]\n",
      "loss: 1.101599  [252800/525306]\n",
      "loss: 0.725350  [254400/525306]\n",
      "loss: 1.260776  [256000/525306]\n",
      "loss: 0.543757  [257600/525306]\n",
      "loss: 0.847216  [259200/525306]\n",
      "loss: 0.606298  [260800/525306]\n",
      "loss: 0.515022  [262400/525306]\n",
      "loss: 0.777735  [264000/525306]\n",
      "loss: 1.058857  [265600/525306]\n",
      "loss: 1.038360  [267200/525306]\n",
      "loss: 0.829215  [268800/525306]\n",
      "loss: 0.978154  [270400/525306]\n",
      "loss: 0.963397  [272000/525306]\n",
      "loss: 0.645190  [273600/525306]\n",
      "loss: 0.873057  [275200/525306]\n",
      "loss: 0.831152  [276800/525306]\n",
      "loss: 0.642589  [278400/525306]\n",
      "loss: 1.124232  [280000/525306]\n",
      "loss: 0.628801  [281600/525306]\n",
      "loss: 1.471970  [283200/525306]\n",
      "loss: 1.111901  [284800/525306]\n",
      "loss: 0.852831  [286400/525306]\n",
      "loss: 1.057376  [288000/525306]\n",
      "loss: 1.175455  [289600/525306]\n",
      "loss: 1.569648  [291200/525306]\n",
      "loss: 0.967772  [292800/525306]\n",
      "loss: 1.050641  [294400/525306]\n",
      "loss: 1.228859  [296000/525306]\n",
      "loss: 1.403555  [297600/525306]\n",
      "loss: 0.779635  [299200/525306]\n",
      "loss: 1.026492  [300800/525306]\n",
      "loss: 1.220871  [302400/525306]\n",
      "loss: 0.873004  [304000/525306]\n",
      "loss: 0.843272  [305600/525306]\n",
      "loss: 0.868124  [307200/525306]\n",
      "loss: 1.478815  [308800/525306]\n",
      "loss: 0.931344  [310400/525306]\n",
      "loss: 0.754172  [312000/525306]\n",
      "loss: 1.009406  [313600/525306]\n",
      "loss: 1.477101  [315200/525306]\n",
      "loss: 0.774097  [316800/525306]\n",
      "loss: 0.728231  [318400/525306]\n",
      "loss: 0.504051  [320000/525306]\n",
      "loss: 0.771633  [321600/525306]\n",
      "loss: 0.663006  [323200/525306]\n",
      "loss: 0.972233  [324800/525306]\n",
      "loss: 0.723778  [326400/525306]\n",
      "loss: 1.084666  [328000/525306]\n",
      "loss: 0.498190  [329600/525306]\n",
      "loss: 0.714056  [331200/525306]\n",
      "loss: 1.369141  [332800/525306]\n",
      "loss: 0.670682  [334400/525306]\n",
      "loss: 1.152724  [336000/525306]\n",
      "loss: 0.811790  [337600/525306]\n",
      "loss: 0.466278  [339200/525306]\n",
      "loss: 0.739176  [340800/525306]\n",
      "loss: 0.649040  [342400/525306]\n",
      "loss: 0.601127  [344000/525306]\n",
      "loss: 1.170701  [345600/525306]\n",
      "loss: 0.862129  [347200/525306]\n",
      "loss: 0.957481  [348800/525306]\n",
      "loss: 0.622593  [350400/525306]\n",
      "loss: 0.615933  [352000/525306]\n",
      "loss: 0.975761  [353600/525306]\n",
      "loss: 0.586264  [355200/525306]\n",
      "loss: 1.190967  [356800/525306]\n",
      "loss: 0.904650  [358400/525306]\n",
      "loss: 0.999073  [360000/525306]\n",
      "loss: 0.881043  [361600/525306]\n",
      "loss: 0.958101  [363200/525306]\n",
      "loss: 0.683845  [364800/525306]\n",
      "loss: 0.786514  [366400/525306]\n",
      "loss: 0.901540  [368000/525306]\n",
      "loss: 0.777972  [369600/525306]\n",
      "loss: 0.710773  [371200/525306]\n",
      "loss: 1.028779  [372800/525306]\n",
      "loss: 1.262346  [374400/525306]\n",
      "loss: 1.088470  [376000/525306]\n",
      "loss: 0.898535  [377600/525306]\n",
      "loss: 1.100425  [379200/525306]\n",
      "loss: 0.660112  [380800/525306]\n",
      "loss: 0.658537  [382400/525306]\n",
      "loss: 1.018144  [384000/525306]\n",
      "loss: 0.878770  [385600/525306]\n",
      "loss: 0.860758  [387200/525306]\n",
      "loss: 0.615399  [388800/525306]\n",
      "loss: 0.965458  [390400/525306]\n",
      "loss: 0.945486  [392000/525306]\n",
      "loss: 1.451330  [393600/525306]\n",
      "loss: 0.683285  [395200/525306]\n",
      "loss: 0.522973  [396800/525306]\n",
      "loss: 1.098876  [398400/525306]\n",
      "loss: 0.860708  [400000/525306]\n",
      "loss: 0.975160  [401600/525306]\n",
      "loss: 0.956745  [403200/525306]\n",
      "loss: 0.540317  [404800/525306]\n",
      "loss: 0.855251  [406400/525306]\n",
      "loss: 0.896958  [408000/525306]\n",
      "loss: 1.024958  [409600/525306]\n",
      "loss: 1.116604  [411200/525306]\n",
      "loss: 0.943059  [412800/525306]\n",
      "loss: 0.966128  [414400/525306]\n",
      "loss: 0.669366  [416000/525306]\n",
      "loss: 0.771535  [417600/525306]\n",
      "loss: 0.917348  [419200/525306]\n",
      "loss: 0.997929  [420800/525306]\n",
      "loss: 0.874650  [422400/525306]\n",
      "loss: 1.016033  [424000/525306]\n",
      "loss: 1.037347  [425600/525306]\n",
      "loss: 0.837644  [427200/525306]\n",
      "loss: 1.270627  [428800/525306]\n",
      "loss: 1.025483  [430400/525306]\n",
      "loss: 1.140955  [432000/525306]\n",
      "loss: 0.756548  [433600/525306]\n",
      "loss: 0.839841  [435200/525306]\n",
      "loss: 0.668419  [436800/525306]\n",
      "loss: 0.935294  [438400/525306]\n",
      "loss: 0.708080  [440000/525306]\n",
      "loss: 0.719033  [441600/525306]\n",
      "loss: 0.951788  [443200/525306]\n",
      "loss: 0.520674  [444800/525306]\n",
      "loss: 0.864748  [446400/525306]\n",
      "loss: 0.614478  [448000/525306]\n",
      "loss: 0.775800  [449600/525306]\n",
      "loss: 0.461195  [451200/525306]\n",
      "loss: 1.041350  [452800/525306]\n",
      "loss: 0.699384  [454400/525306]\n",
      "loss: 1.026591  [456000/525306]\n",
      "loss: 0.964040  [457600/525306]\n",
      "loss: 0.447406  [459200/525306]\n",
      "loss: 0.703138  [460800/525306]\n",
      "loss: 0.861684  [462400/525306]\n",
      "loss: 1.153080  [464000/525306]\n",
      "loss: 0.685979  [465600/525306]\n",
      "loss: 0.784404  [467200/525306]\n",
      "loss: 0.980201  [468800/525306]\n",
      "loss: 0.618577  [470400/525306]\n",
      "loss: 0.656065  [472000/525306]\n",
      "loss: 1.120816  [473600/525306]\n",
      "loss: 0.838253  [475200/525306]\n",
      "loss: 0.897932  [476800/525306]\n",
      "loss: 0.707553  [478400/525306]\n",
      "loss: 0.687765  [480000/525306]\n",
      "loss: 0.812481  [481600/525306]\n",
      "loss: 1.108227  [483200/525306]\n",
      "loss: 0.760086  [484800/525306]\n",
      "loss: 0.729766  [486400/525306]\n",
      "loss: 1.113719  [488000/525306]\n",
      "loss: 0.989297  [489600/525306]\n",
      "loss: 0.889965  [491200/525306]\n",
      "loss: 0.651799  [492800/525306]\n",
      "loss: 0.594991  [494400/525306]\n",
      "loss: 0.894692  [496000/525306]\n",
      "loss: 0.730788  [497600/525306]\n",
      "loss: 0.788149  [499200/525306]\n",
      "loss: 0.778057  [500800/525306]\n",
      "loss: 0.701546  [502400/525306]\n",
      "loss: 0.911015  [504000/525306]\n",
      "loss: 0.762855  [505600/525306]\n",
      "loss: 0.823702  [507200/525306]\n",
      "loss: 1.382133  [508800/525306]\n",
      "loss: 1.013113  [510400/525306]\n",
      "loss: 0.789460  [512000/525306]\n",
      "loss: 1.262531  [513600/525306]\n",
      "loss: 1.095445  [515200/525306]\n",
      "loss: 0.729226  [516800/525306]\n",
      "loss: 0.810981  [518400/525306]\n",
      "loss: 0.732442  [520000/525306]\n",
      "loss: 0.717451  [521600/525306]\n",
      "loss: 0.900200  [523200/525306]\n",
      "loss: 0.689361  [524800/525306]\n",
      "Train Accuracy: 64.5146%\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 0.978637, F1-score: 69.11%, Macro_F1-Score:  36.64%  \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.676779  [    0/525306]\n",
      "loss: 0.582500  [ 1600/525306]\n",
      "loss: 1.184852  [ 3200/525306]\n",
      "loss: 0.915763  [ 4800/525306]\n",
      "loss: 0.952964  [ 6400/525306]\n",
      "loss: 0.877991  [ 8000/525306]\n",
      "loss: 0.972188  [ 9600/525306]\n",
      "loss: 0.503289  [11200/525306]\n",
      "loss: 0.837471  [12800/525306]\n",
      "loss: 0.983278  [14400/525306]\n",
      "loss: 0.944173  [16000/525306]\n",
      "loss: 1.048295  [17600/525306]\n",
      "loss: 0.440079  [19200/525306]\n",
      "loss: 0.830542  [20800/525306]\n",
      "loss: 0.891799  [22400/525306]\n",
      "loss: 0.813951  [24000/525306]\n",
      "loss: 0.931283  [25600/525306]\n",
      "loss: 0.972957  [27200/525306]\n",
      "loss: 0.803769  [28800/525306]\n",
      "loss: 0.747171  [30400/525306]\n",
      "loss: 0.814955  [32000/525306]\n",
      "loss: 1.240709  [33600/525306]\n",
      "loss: 1.066505  [35200/525306]\n",
      "loss: 0.729854  [36800/525306]\n",
      "loss: 0.805587  [38400/525306]\n",
      "loss: 0.700690  [40000/525306]\n",
      "loss: 1.043942  [41600/525306]\n",
      "loss: 0.835542  [43200/525306]\n",
      "loss: 1.244126  [44800/525306]\n",
      "loss: 0.536624  [46400/525306]\n",
      "loss: 0.792611  [48000/525306]\n",
      "loss: 0.969134  [49600/525306]\n",
      "loss: 1.230702  [51200/525306]\n",
      "loss: 1.218273  [52800/525306]\n",
      "loss: 0.505823  [54400/525306]\n",
      "loss: 1.465169  [56000/525306]\n",
      "loss: 0.567893  [57600/525306]\n",
      "loss: 1.056691  [59200/525306]\n",
      "loss: 0.587448  [60800/525306]\n",
      "loss: 0.765692  [62400/525306]\n",
      "loss: 1.344238  [64000/525306]\n",
      "loss: 0.649971  [65600/525306]\n",
      "loss: 0.838453  [67200/525306]\n",
      "loss: 1.843836  [68800/525306]\n",
      "loss: 0.745895  [70400/525306]\n",
      "loss: 1.004443  [72000/525306]\n",
      "loss: 0.870763  [73600/525306]\n",
      "loss: 1.298010  [75200/525306]\n",
      "loss: 0.894054  [76800/525306]\n",
      "loss: 0.627129  [78400/525306]\n",
      "loss: 0.508012  [80000/525306]\n",
      "loss: 1.019136  [81600/525306]\n",
      "loss: 1.101319  [83200/525306]\n",
      "loss: 0.822675  [84800/525306]\n",
      "loss: 1.018105  [86400/525306]\n",
      "loss: 1.188832  [88000/525306]\n",
      "loss: 0.503116  [89600/525306]\n",
      "loss: 0.981648  [91200/525306]\n",
      "loss: 0.725082  [92800/525306]\n",
      "loss: 1.044508  [94400/525306]\n",
      "loss: 0.902508  [96000/525306]\n",
      "loss: 1.113846  [97600/525306]\n",
      "loss: 0.798946  [99200/525306]\n",
      "loss: 1.011021  [100800/525306]\n",
      "loss: 0.530926  [102400/525306]\n",
      "loss: 1.300420  [104000/525306]\n",
      "loss: 1.106889  [105600/525306]\n",
      "loss: 0.780689  [107200/525306]\n",
      "loss: 0.588933  [108800/525306]\n",
      "loss: 0.735934  [110400/525306]\n",
      "loss: 1.070479  [112000/525306]\n",
      "loss: 0.785942  [113600/525306]\n",
      "loss: 1.047251  [115200/525306]\n",
      "loss: 0.563602  [116800/525306]\n",
      "loss: 0.613036  [118400/525306]\n",
      "loss: 0.990794  [120000/525306]\n",
      "loss: 0.670471  [121600/525306]\n",
      "loss: 1.074487  [123200/525306]\n",
      "loss: 1.015027  [124800/525306]\n",
      "loss: 0.529191  [126400/525306]\n",
      "loss: 1.173655  [128000/525306]\n",
      "loss: 0.671663  [129600/525306]\n",
      "loss: 0.843639  [131200/525306]\n",
      "loss: 1.049812  [132800/525306]\n",
      "loss: 1.181295  [134400/525306]\n",
      "loss: 0.879260  [136000/525306]\n",
      "loss: 0.814643  [137600/525306]\n",
      "loss: 1.077030  [139200/525306]\n",
      "loss: 0.875965  [140800/525306]\n",
      "loss: 1.423580  [142400/525306]\n",
      "loss: 1.006859  [144000/525306]\n",
      "loss: 0.955736  [145600/525306]\n",
      "loss: 0.732900  [147200/525306]\n",
      "loss: 1.116567  [148800/525306]\n",
      "loss: 1.183617  [150400/525306]\n",
      "loss: 1.031271  [152000/525306]\n",
      "loss: 0.501869  [153600/525306]\n",
      "loss: 0.802562  [155200/525306]\n",
      "loss: 0.903772  [156800/525306]\n",
      "loss: 0.785520  [158400/525306]\n",
      "loss: 0.939229  [160000/525306]\n",
      "loss: 0.834716  [161600/525306]\n",
      "loss: 0.746260  [163200/525306]\n",
      "loss: 0.653322  [164800/525306]\n",
      "loss: 1.041211  [166400/525306]\n",
      "loss: 0.444107  [168000/525306]\n",
      "loss: 1.167000  [169600/525306]\n",
      "loss: 0.850718  [171200/525306]\n",
      "loss: 0.894304  [172800/525306]\n",
      "loss: 1.162268  [174400/525306]\n",
      "loss: 1.284726  [176000/525306]\n",
      "loss: 1.163148  [177600/525306]\n",
      "loss: 0.678788  [179200/525306]\n",
      "loss: 0.659826  [180800/525306]\n",
      "loss: 0.731904  [182400/525306]\n",
      "loss: 0.853459  [184000/525306]\n",
      "loss: 0.805902  [185600/525306]\n",
      "loss: 0.864126  [187200/525306]\n",
      "loss: 0.602273  [188800/525306]\n",
      "loss: 0.922429  [190400/525306]\n",
      "loss: 0.594908  [192000/525306]\n",
      "loss: 0.810904  [193600/525306]\n",
      "loss: 1.211149  [195200/525306]\n",
      "loss: 0.455360  [196800/525306]\n",
      "loss: 1.304284  [198400/525306]\n",
      "loss: 0.914550  [200000/525306]\n",
      "loss: 0.756281  [201600/525306]\n",
      "loss: 0.444186  [203200/525306]\n",
      "loss: 0.405364  [204800/525306]\n",
      "loss: 0.595640  [206400/525306]\n",
      "loss: 0.934245  [208000/525306]\n",
      "loss: 0.922431  [209600/525306]\n",
      "loss: 0.966702  [211200/525306]\n",
      "loss: 0.816142  [212800/525306]\n",
      "loss: 0.686174  [214400/525306]\n",
      "loss: 1.248713  [216000/525306]\n",
      "loss: 0.829253  [217600/525306]\n",
      "loss: 0.698161  [219200/525306]\n",
      "loss: 0.511681  [220800/525306]\n",
      "loss: 0.867617  [222400/525306]\n",
      "loss: 1.282355  [224000/525306]\n",
      "loss: 0.772020  [225600/525306]\n",
      "loss: 0.791833  [227200/525306]\n",
      "loss: 0.625007  [228800/525306]\n",
      "loss: 0.507599  [230400/525306]\n",
      "loss: 0.434786  [232000/525306]\n",
      "loss: 0.904928  [233600/525306]\n",
      "loss: 0.958782  [235200/525306]\n",
      "loss: 1.185791  [236800/525306]\n",
      "loss: 0.862961  [238400/525306]\n",
      "loss: 0.744178  [240000/525306]\n",
      "loss: 0.806108  [241600/525306]\n",
      "loss: 0.471639  [243200/525306]\n",
      "loss: 0.691340  [244800/525306]\n",
      "loss: 0.867537  [246400/525306]\n",
      "loss: 0.751460  [248000/525306]\n",
      "loss: 1.157213  [249600/525306]\n",
      "loss: 0.779146  [251200/525306]\n",
      "loss: 0.778898  [252800/525306]\n",
      "loss: 0.677859  [254400/525306]\n",
      "loss: 1.056360  [256000/525306]\n",
      "loss: 0.390124  [257600/525306]\n",
      "loss: 0.624607  [259200/525306]\n",
      "loss: 1.402836  [260800/525306]\n",
      "loss: 1.032233  [262400/525306]\n",
      "loss: 1.101987  [264000/525306]\n",
      "loss: 0.709662  [265600/525306]\n",
      "loss: 0.763436  [267200/525306]\n",
      "loss: 1.500743  [268800/525306]\n",
      "loss: 1.294483  [270400/525306]\n",
      "loss: 0.944113  [272000/525306]\n",
      "loss: 0.707722  [273600/525306]\n",
      "loss: 0.749999  [275200/525306]\n",
      "loss: 0.840060  [276800/525306]\n",
      "loss: 0.821964  [278400/525306]\n",
      "loss: 1.245459  [280000/525306]\n",
      "loss: 1.104745  [281600/525306]\n",
      "loss: 0.806452  [283200/525306]\n",
      "loss: 0.783522  [284800/525306]\n",
      "loss: 1.285087  [286400/525306]\n",
      "loss: 1.029411  [288000/525306]\n",
      "loss: 0.991032  [289600/525306]\n",
      "loss: 0.390157  [291200/525306]\n",
      "loss: 0.684357  [292800/525306]\n",
      "loss: 0.977598  [294400/525306]\n",
      "loss: 1.076426  [296000/525306]\n",
      "loss: 1.092005  [297600/525306]\n",
      "loss: 0.709337  [299200/525306]\n",
      "loss: 0.751799  [300800/525306]\n",
      "loss: 0.464989  [302400/525306]\n",
      "loss: 0.856362  [304000/525306]\n",
      "loss: 1.198577  [305600/525306]\n",
      "loss: 1.347207  [307200/525306]\n",
      "loss: 1.024617  [308800/525306]\n",
      "loss: 0.920687  [310400/525306]\n",
      "loss: 0.655773  [312000/525306]\n",
      "loss: 0.955660  [313600/525306]\n",
      "loss: 0.730757  [315200/525306]\n",
      "loss: 1.167852  [316800/525306]\n",
      "loss: 1.166705  [318400/525306]\n",
      "loss: 0.999093  [320000/525306]\n",
      "loss: 0.593831  [321600/525306]\n",
      "loss: 1.225636  [323200/525306]\n",
      "loss: 0.845064  [324800/525306]\n",
      "loss: 1.054459  [326400/525306]\n",
      "loss: 0.991142  [328000/525306]\n",
      "loss: 0.899182  [329600/525306]\n",
      "loss: 1.052959  [331200/525306]\n",
      "loss: 1.136873  [332800/525306]\n",
      "loss: 1.338985  [334400/525306]\n",
      "loss: 0.944088  [336000/525306]\n",
      "loss: 0.840007  [337600/525306]\n",
      "loss: 1.049372  [339200/525306]\n",
      "loss: 0.644307  [340800/525306]\n",
      "loss: 1.234853  [342400/525306]\n",
      "loss: 1.139508  [344000/525306]\n",
      "loss: 1.253954  [345600/525306]\n",
      "loss: 0.834756  [347200/525306]\n",
      "loss: 1.053192  [348800/525306]\n",
      "loss: 0.784993  [350400/525306]\n",
      "loss: 0.818131  [352000/525306]\n",
      "loss: 1.245234  [353600/525306]\n",
      "loss: 0.661029  [355200/525306]\n",
      "loss: 0.491879  [356800/525306]\n",
      "loss: 0.664250  [358400/525306]\n",
      "loss: 0.812272  [360000/525306]\n",
      "loss: 0.736207  [361600/525306]\n",
      "loss: 0.686970  [363200/525306]\n",
      "loss: 1.522996  [364800/525306]\n",
      "loss: 0.720304  [366400/525306]\n",
      "loss: 0.958633  [368000/525306]\n",
      "loss: 0.918334  [369600/525306]\n",
      "loss: 0.723122  [371200/525306]\n",
      "loss: 0.907395  [372800/525306]\n",
      "loss: 0.815270  [374400/525306]\n",
      "loss: 0.688594  [376000/525306]\n",
      "loss: 1.046035  [377600/525306]\n",
      "loss: 0.762057  [379200/525306]\n",
      "loss: 1.224139  [380800/525306]\n",
      "loss: 0.766755  [382400/525306]\n",
      "loss: 0.906565  [384000/525306]\n",
      "loss: 0.393218  [385600/525306]\n",
      "loss: 1.119328  [387200/525306]\n",
      "loss: 0.606705  [388800/525306]\n",
      "loss: 1.180052  [390400/525306]\n",
      "loss: 0.977189  [392000/525306]\n",
      "loss: 0.859109  [393600/525306]\n",
      "loss: 0.834816  [395200/525306]\n",
      "loss: 0.677154  [396800/525306]\n",
      "loss: 0.549649  [398400/525306]\n",
      "loss: 0.428351  [400000/525306]\n",
      "loss: 1.149498  [401600/525306]\n",
      "loss: 1.174120  [403200/525306]\n",
      "loss: 1.239410  [404800/525306]\n",
      "loss: 0.330220  [406400/525306]\n",
      "loss: 0.955634  [408000/525306]\n",
      "loss: 1.193600  [409600/525306]\n",
      "loss: 0.909988  [411200/525306]\n",
      "loss: 1.294186  [412800/525306]\n",
      "loss: 0.446968  [414400/525306]\n",
      "loss: 0.488242  [416000/525306]\n",
      "loss: 0.772746  [417600/525306]\n",
      "loss: 0.924835  [419200/525306]\n",
      "loss: 0.800906  [420800/525306]\n",
      "loss: 1.009764  [422400/525306]\n",
      "loss: 0.554939  [424000/525306]\n",
      "loss: 0.661233  [425600/525306]\n",
      "loss: 0.709776  [427200/525306]\n",
      "loss: 0.592867  [428800/525306]\n",
      "loss: 0.760104  [430400/525306]\n",
      "loss: 1.083538  [432000/525306]\n",
      "loss: 0.940353  [433600/525306]\n",
      "loss: 0.947755  [435200/525306]\n",
      "loss: 0.622278  [436800/525306]\n",
      "loss: 0.549241  [438400/525306]\n",
      "loss: 0.877447  [440000/525306]\n",
      "loss: 0.593281  [441600/525306]\n",
      "loss: 0.757155  [443200/525306]\n",
      "loss: 1.179887  [444800/525306]\n",
      "loss: 0.920054  [446400/525306]\n",
      "loss: 0.901449  [448000/525306]\n",
      "loss: 1.211670  [449600/525306]\n",
      "loss: 0.962547  [451200/525306]\n",
      "loss: 0.670093  [452800/525306]\n",
      "loss: 0.658823  [454400/525306]\n",
      "loss: 1.052536  [456000/525306]\n",
      "loss: 1.073127  [457600/525306]\n",
      "loss: 0.333491  [459200/525306]\n",
      "loss: 1.024082  [460800/525306]\n",
      "loss: 1.221899  [462400/525306]\n",
      "loss: 0.651344  [464000/525306]\n",
      "loss: 0.539803  [465600/525306]\n",
      "loss: 0.674089  [467200/525306]\n",
      "loss: 0.861821  [468800/525306]\n",
      "loss: 0.937103  [470400/525306]\n",
      "loss: 0.891061  [472000/525306]\n",
      "loss: 0.781214  [473600/525306]\n",
      "loss: 0.472694  [475200/525306]\n",
      "loss: 0.963341  [476800/525306]\n",
      "loss: 0.770014  [478400/525306]\n",
      "loss: 0.299461  [480000/525306]\n",
      "loss: 0.724890  [481600/525306]\n",
      "loss: 1.222264  [483200/525306]\n",
      "loss: 1.066130  [484800/525306]\n",
      "loss: 1.051372  [486400/525306]\n",
      "loss: 0.792980  [488000/525306]\n",
      "loss: 0.832113  [489600/525306]\n",
      "loss: 1.001002  [491200/525306]\n",
      "loss: 0.841807  [492800/525306]\n",
      "loss: 0.450451  [494400/525306]\n",
      "loss: 0.900778  [496000/525306]\n",
      "loss: 0.517294  [497600/525306]\n",
      "loss: 0.883450  [499200/525306]\n",
      "loss: 0.702910  [500800/525306]\n",
      "loss: 0.924972  [502400/525306]\n",
      "loss: 0.894413  [504000/525306]\n",
      "loss: 0.714659  [505600/525306]\n",
      "loss: 0.886292  [507200/525306]\n",
      "loss: 0.991407  [508800/525306]\n",
      "loss: 0.901222  [510400/525306]\n",
      "loss: 0.533335  [512000/525306]\n",
      "loss: 0.796095  [513600/525306]\n",
      "loss: 1.085158  [515200/525306]\n",
      "loss: 0.924138  [516800/525306]\n",
      "loss: 0.626276  [518400/525306]\n",
      "loss: 0.781264  [520000/525306]\n",
      "loss: 0.611745  [521600/525306]\n",
      "loss: 0.682511  [523200/525306]\n",
      "loss: 0.733292  [524800/525306]\n",
      "Train Accuracy: 67.7932%\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.918547, F1-score: 69.88%, Macro_F1-Score:  37.89%  \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.854215  [    0/525306]\n",
      "loss: 1.041021  [ 1600/525306]\n",
      "loss: 0.783039  [ 3200/525306]\n",
      "loss: 0.924936  [ 4800/525306]\n",
      "loss: 1.279831  [ 6400/525306]\n",
      "loss: 0.605054  [ 8000/525306]\n",
      "loss: 0.488726  [ 9600/525306]\n",
      "loss: 1.270789  [11200/525306]\n",
      "loss: 1.025947  [12800/525306]\n",
      "loss: 1.014786  [14400/525306]\n",
      "loss: 0.945019  [16000/525306]\n",
      "loss: 0.969718  [17600/525306]\n",
      "loss: 0.847118  [19200/525306]\n",
      "loss: 0.995844  [20800/525306]\n",
      "loss: 0.610013  [22400/525306]\n",
      "loss: 1.063854  [24000/525306]\n",
      "loss: 0.699628  [25600/525306]\n",
      "loss: 0.962598  [27200/525306]\n",
      "loss: 0.599839  [28800/525306]\n",
      "loss: 1.499794  [30400/525306]\n",
      "loss: 0.783450  [32000/525306]\n",
      "loss: 0.765562  [33600/525306]\n",
      "loss: 0.410325  [35200/525306]\n",
      "loss: 0.521858  [36800/525306]\n",
      "loss: 0.526962  [38400/525306]\n",
      "loss: 0.523045  [40000/525306]\n",
      "loss: 0.825912  [41600/525306]\n",
      "loss: 0.905313  [43200/525306]\n",
      "loss: 0.611135  [44800/525306]\n",
      "loss: 0.633852  [46400/525306]\n",
      "loss: 1.149530  [48000/525306]\n",
      "loss: 0.831093  [49600/525306]\n",
      "loss: 0.708082  [51200/525306]\n",
      "loss: 0.467432  [52800/525306]\n",
      "loss: 0.626860  [54400/525306]\n",
      "loss: 0.320747  [56000/525306]\n",
      "loss: 0.814259  [57600/525306]\n",
      "loss: 0.713796  [59200/525306]\n",
      "loss: 0.992924  [60800/525306]\n",
      "loss: 0.491550  [62400/525306]\n",
      "loss: 0.505617  [64000/525306]\n",
      "loss: 0.598827  [65600/525306]\n",
      "loss: 0.870390  [67200/525306]\n",
      "loss: 0.721266  [68800/525306]\n",
      "loss: 1.084516  [70400/525306]\n",
      "loss: 1.128589  [72000/525306]\n",
      "loss: 1.012820  [73600/525306]\n",
      "loss: 0.623225  [75200/525306]\n",
      "loss: 0.899035  [76800/525306]\n",
      "loss: 0.469515  [78400/525306]\n",
      "loss: 0.576450  [80000/525306]\n",
      "loss: 1.024955  [81600/525306]\n",
      "loss: 0.536005  [83200/525306]\n",
      "loss: 0.593234  [84800/525306]\n",
      "loss: 0.269377  [86400/525306]\n",
      "loss: 0.602729  [88000/525306]\n",
      "loss: 1.110631  [89600/525306]\n",
      "loss: 0.936090  [91200/525306]\n",
      "loss: 0.831141  [92800/525306]\n",
      "loss: 0.272742  [94400/525306]\n",
      "loss: 0.333500  [96000/525306]\n",
      "loss: 0.545646  [97600/525306]\n",
      "loss: 0.846647  [99200/525306]\n",
      "loss: 0.536746  [100800/525306]\n",
      "loss: 0.769260  [102400/525306]\n",
      "loss: 0.840468  [104000/525306]\n",
      "loss: 0.845171  [105600/525306]\n",
      "loss: 0.753246  [107200/525306]\n",
      "loss: 0.612017  [108800/525306]\n",
      "loss: 1.122253  [110400/525306]\n",
      "loss: 0.824857  [112000/525306]\n",
      "loss: 0.884791  [113600/525306]\n",
      "loss: 0.816182  [115200/525306]\n",
      "loss: 0.733628  [116800/525306]\n",
      "loss: 0.863631  [118400/525306]\n",
      "loss: 1.194633  [120000/525306]\n",
      "loss: 0.860242  [121600/525306]\n",
      "loss: 0.701264  [123200/525306]\n",
      "loss: 1.037545  [124800/525306]\n",
      "loss: 1.152111  [126400/525306]\n",
      "loss: 1.283091  [128000/525306]\n",
      "loss: 0.577053  [129600/525306]\n",
      "loss: 0.754928  [131200/525306]\n",
      "loss: 0.742426  [132800/525306]\n",
      "loss: 0.915061  [134400/525306]\n",
      "loss: 0.606602  [136000/525306]\n",
      "loss: 0.782382  [137600/525306]\n",
      "loss: 0.603291  [139200/525306]\n",
      "loss: 1.050698  [140800/525306]\n",
      "loss: 0.930848  [142400/525306]\n",
      "loss: 1.271049  [144000/525306]\n",
      "loss: 0.672598  [145600/525306]\n",
      "loss: 1.110169  [147200/525306]\n",
      "loss: 0.858885  [148800/525306]\n",
      "loss: 1.050910  [150400/525306]\n",
      "loss: 0.766154  [152000/525306]\n",
      "loss: 0.833321  [153600/525306]\n",
      "loss: 0.759576  [155200/525306]\n",
      "loss: 1.148872  [156800/525306]\n",
      "loss: 0.427854  [158400/525306]\n",
      "loss: 0.972308  [160000/525306]\n",
      "loss: 1.056371  [161600/525306]\n",
      "loss: 0.612294  [163200/525306]\n",
      "loss: 0.626872  [164800/525306]\n",
      "loss: 0.629057  [166400/525306]\n",
      "loss: 0.969366  [168000/525306]\n",
      "loss: 0.989594  [169600/525306]\n",
      "loss: 0.974075  [171200/525306]\n",
      "loss: 0.833880  [172800/525306]\n",
      "loss: 1.086514  [174400/525306]\n",
      "loss: 0.899909  [176000/525306]\n",
      "loss: 0.902355  [177600/525306]\n",
      "loss: 1.147246  [179200/525306]\n",
      "loss: 0.923575  [180800/525306]\n",
      "loss: 0.648701  [182400/525306]\n",
      "loss: 0.647846  [184000/525306]\n",
      "loss: 0.878873  [185600/525306]\n",
      "loss: 0.610004  [187200/525306]\n",
      "loss: 1.317911  [188800/525306]\n",
      "loss: 0.667816  [190400/525306]\n",
      "loss: 0.846965  [192000/525306]\n",
      "loss: 1.032203  [193600/525306]\n",
      "loss: 0.559073  [195200/525306]\n",
      "loss: 1.392390  [196800/525306]\n",
      "loss: 1.000143  [198400/525306]\n",
      "loss: 0.661557  [200000/525306]\n",
      "loss: 0.641292  [201600/525306]\n",
      "loss: 0.649935  [203200/525306]\n",
      "loss: 0.682105  [204800/525306]\n",
      "loss: 0.872243  [206400/525306]\n",
      "loss: 0.356237  [208000/525306]\n",
      "loss: 0.872972  [209600/525306]\n",
      "loss: 1.032463  [211200/525306]\n",
      "loss: 0.879207  [212800/525306]\n",
      "loss: 1.140989  [214400/525306]\n",
      "loss: 0.760656  [216000/525306]\n",
      "loss: 0.649173  [217600/525306]\n",
      "loss: 0.821250  [219200/525306]\n",
      "loss: 0.603510  [220800/525306]\n",
      "loss: 0.670761  [222400/525306]\n",
      "loss: 0.665950  [224000/525306]\n",
      "loss: 0.611063  [225600/525306]\n",
      "loss: 0.754373  [227200/525306]\n",
      "loss: 0.703184  [228800/525306]\n",
      "loss: 0.632118  [230400/525306]\n",
      "loss: 0.895636  [232000/525306]\n",
      "loss: 0.817229  [233600/525306]\n",
      "loss: 0.786040  [235200/525306]\n",
      "loss: 0.679561  [236800/525306]\n",
      "loss: 0.635671  [238400/525306]\n",
      "loss: 1.368094  [240000/525306]\n",
      "loss: 1.058440  [241600/525306]\n",
      "loss: 0.821733  [243200/525306]\n",
      "loss: 0.593807  [244800/525306]\n",
      "loss: 0.984728  [246400/525306]\n",
      "loss: 0.667579  [248000/525306]\n",
      "loss: 0.999113  [249600/525306]\n",
      "loss: 0.649913  [251200/525306]\n",
      "loss: 0.744226  [252800/525306]\n",
      "loss: 0.498143  [254400/525306]\n",
      "loss: 0.645450  [256000/525306]\n",
      "loss: 1.140012  [257600/525306]\n",
      "loss: 0.734509  [259200/525306]\n",
      "loss: 0.540437  [260800/525306]\n",
      "loss: 0.733997  [262400/525306]\n",
      "loss: 0.714013  [264000/525306]\n",
      "loss: 0.643016  [265600/525306]\n",
      "loss: 0.618894  [267200/525306]\n",
      "loss: 0.736008  [268800/525306]\n",
      "loss: 0.496885  [270400/525306]\n",
      "loss: 1.597812  [272000/525306]\n",
      "loss: 0.920009  [273600/525306]\n",
      "loss: 0.529508  [275200/525306]\n",
      "loss: 1.064907  [276800/525306]\n",
      "loss: 0.955909  [278400/525306]\n",
      "loss: 0.854838  [280000/525306]\n",
      "loss: 0.752538  [281600/525306]\n",
      "loss: 1.035628  [283200/525306]\n",
      "loss: 0.362069  [284800/525306]\n",
      "loss: 0.546975  [286400/525306]\n",
      "loss: 0.461838  [288000/525306]\n",
      "loss: 0.747223  [289600/525306]\n",
      "loss: 0.817222  [291200/525306]\n",
      "loss: 1.036972  [292800/525306]\n",
      "loss: 0.626951  [294400/525306]\n",
      "loss: 0.697896  [296000/525306]\n",
      "loss: 0.508134  [297600/525306]\n",
      "loss: 0.751906  [299200/525306]\n",
      "loss: 0.791972  [300800/525306]\n",
      "loss: 0.485157  [302400/525306]\n",
      "loss: 1.016712  [304000/525306]\n",
      "loss: 0.844370  [305600/525306]\n",
      "loss: 0.764936  [307200/525306]\n",
      "loss: 0.771488  [308800/525306]\n",
      "loss: 0.954211  [310400/525306]\n",
      "loss: 0.602988  [312000/525306]\n",
      "loss: 0.721960  [313600/525306]\n",
      "loss: 0.791617  [315200/525306]\n",
      "loss: 0.700265  [316800/525306]\n",
      "loss: 0.660598  [318400/525306]\n",
      "loss: 0.486664  [320000/525306]\n",
      "loss: 0.474562  [321600/525306]\n",
      "loss: 1.260570  [323200/525306]\n",
      "loss: 0.568024  [324800/525306]\n",
      "loss: 0.686938  [326400/525306]\n",
      "loss: 1.154394  [328000/525306]\n",
      "loss: 0.896406  [329600/525306]\n",
      "loss: 0.772793  [331200/525306]\n",
      "loss: 1.100784  [332800/525306]\n",
      "loss: 0.722694  [334400/525306]\n",
      "loss: 1.008209  [336000/525306]\n",
      "loss: 1.009272  [337600/525306]\n",
      "loss: 0.654915  [339200/525306]\n",
      "loss: 0.438512  [340800/525306]\n",
      "loss: 0.753904  [342400/525306]\n",
      "loss: 0.744322  [344000/525306]\n",
      "loss: 1.520524  [345600/525306]\n",
      "loss: 0.739905  [347200/525306]\n",
      "loss: 0.923930  [348800/525306]\n",
      "loss: 0.937382  [350400/525306]\n",
      "loss: 0.638406  [352000/525306]\n",
      "loss: 0.681485  [353600/525306]\n",
      "loss: 1.128839  [355200/525306]\n",
      "loss: 1.105004  [356800/525306]\n",
      "loss: 0.698863  [358400/525306]\n",
      "loss: 0.776753  [360000/525306]\n",
      "loss: 1.027108  [361600/525306]\n",
      "loss: 0.845186  [363200/525306]\n",
      "loss: 1.311565  [364800/525306]\n",
      "loss: 0.876628  [366400/525306]\n",
      "loss: 0.799453  [368000/525306]\n",
      "loss: 0.990595  [369600/525306]\n",
      "loss: 0.831591  [371200/525306]\n",
      "loss: 0.599903  [372800/525306]\n",
      "loss: 0.469537  [374400/525306]\n",
      "loss: 0.874442  [376000/525306]\n",
      "loss: 0.541489  [377600/525306]\n",
      "loss: 0.974984  [379200/525306]\n",
      "loss: 0.480263  [380800/525306]\n",
      "loss: 0.917316  [382400/525306]\n",
      "loss: 0.931855  [384000/525306]\n",
      "loss: 1.570749  [385600/525306]\n",
      "loss: 0.771555  [387200/525306]\n",
      "loss: 0.546773  [388800/525306]\n",
      "loss: 0.545964  [390400/525306]\n",
      "loss: 1.055863  [392000/525306]\n",
      "loss: 0.923295  [393600/525306]\n",
      "loss: 0.931972  [395200/525306]\n",
      "loss: 0.646817  [396800/525306]\n",
      "loss: 0.785976  [398400/525306]\n",
      "loss: 0.580087  [400000/525306]\n",
      "loss: 0.919416  [401600/525306]\n",
      "loss: 0.655211  [403200/525306]\n",
      "loss: 0.918875  [404800/525306]\n",
      "loss: 0.519470  [406400/525306]\n",
      "loss: 0.710867  [408000/525306]\n",
      "loss: 0.496839  [409600/525306]\n",
      "loss: 0.618656  [411200/525306]\n",
      "loss: 0.577857  [412800/525306]\n",
      "loss: 1.256804  [414400/525306]\n",
      "loss: 0.581092  [416000/525306]\n",
      "loss: 0.796773  [417600/525306]\n",
      "loss: 1.173253  [419200/525306]\n",
      "loss: 0.712169  [420800/525306]\n",
      "loss: 1.014828  [422400/525306]\n",
      "loss: 0.424653  [424000/525306]\n",
      "loss: 0.761575  [425600/525306]\n",
      "loss: 0.879548  [427200/525306]\n",
      "loss: 0.922351  [428800/525306]\n",
      "loss: 0.736901  [430400/525306]\n",
      "loss: 0.601983  [432000/525306]\n",
      "loss: 0.722230  [433600/525306]\n",
      "loss: 0.974696  [435200/525306]\n",
      "loss: 0.790447  [436800/525306]\n",
      "loss: 0.545146  [438400/525306]\n",
      "loss: 0.466299  [440000/525306]\n",
      "loss: 1.149353  [441600/525306]\n",
      "loss: 0.802401  [443200/525306]\n",
      "loss: 1.031705  [444800/525306]\n",
      "loss: 0.593434  [446400/525306]\n",
      "loss: 0.715077  [448000/525306]\n",
      "loss: 0.822068  [449600/525306]\n",
      "loss: 0.568060  [451200/525306]\n",
      "loss: 0.880805  [452800/525306]\n",
      "loss: 0.851782  [454400/525306]\n",
      "loss: 0.699983  [456000/525306]\n",
      "loss: 1.014801  [457600/525306]\n",
      "loss: 0.900349  [459200/525306]\n",
      "loss: 0.998147  [460800/525306]\n",
      "loss: 0.599053  [462400/525306]\n",
      "loss: 0.779517  [464000/525306]\n",
      "loss: 1.078639  [465600/525306]\n",
      "loss: 0.616361  [467200/525306]\n",
      "loss: 0.517452  [468800/525306]\n",
      "loss: 0.668728  [470400/525306]\n",
      "loss: 1.279118  [472000/525306]\n",
      "loss: 1.116432  [473600/525306]\n",
      "loss: 0.719767  [475200/525306]\n",
      "loss: 0.685448  [476800/525306]\n",
      "loss: 0.558058  [478400/525306]\n",
      "loss: 0.792005  [480000/525306]\n",
      "loss: 0.751630  [481600/525306]\n",
      "loss: 1.250847  [483200/525306]\n",
      "loss: 0.567444  [484800/525306]\n",
      "loss: 0.715634  [486400/525306]\n",
      "loss: 0.823929  [488000/525306]\n",
      "loss: 0.657327  [489600/525306]\n",
      "loss: 0.567264  [491200/525306]\n",
      "loss: 0.429249  [492800/525306]\n",
      "loss: 0.805932  [494400/525306]\n",
      "loss: 0.515712  [496000/525306]\n",
      "loss: 0.617165  [497600/525306]\n",
      "loss: 0.890042  [499200/525306]\n",
      "loss: 0.802747  [500800/525306]\n",
      "loss: 0.871694  [502400/525306]\n",
      "loss: 0.364796  [504000/525306]\n",
      "loss: 0.715531  [505600/525306]\n",
      "loss: 1.096131  [507200/525306]\n",
      "loss: 0.737230  [508800/525306]\n",
      "loss: 0.509978  [510400/525306]\n",
      "loss: 1.016379  [512000/525306]\n",
      "loss: 0.759719  [513600/525306]\n",
      "loss: 0.852097  [515200/525306]\n",
      "loss: 1.034667  [516800/525306]\n",
      "loss: 0.430723  [518400/525306]\n",
      "loss: 0.610553  [520000/525306]\n",
      "loss: 0.887545  [521600/525306]\n",
      "loss: 0.769186  [523200/525306]\n",
      "loss: 0.663436  [524800/525306]\n",
      "Train Accuracy: 69.3223%\n",
      "Test Error: \n",
      " Accuracy: 63.5%, Avg loss: 0.958921, F1-score: 69.68%, Macro_F1-Score:  38.00%  \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.766182  [    0/525306]\n",
      "loss: 0.485260  [ 1600/525306]\n",
      "loss: 0.742049  [ 3200/525306]\n",
      "loss: 0.875558  [ 4800/525306]\n",
      "loss: 0.746720  [ 6400/525306]\n",
      "loss: 0.633714  [ 8000/525306]\n",
      "loss: 0.571537  [ 9600/525306]\n",
      "loss: 0.827167  [11200/525306]\n",
      "loss: 0.800039  [12800/525306]\n",
      "loss: 0.919316  [14400/525306]\n",
      "loss: 0.882699  [16000/525306]\n",
      "loss: 0.743750  [17600/525306]\n",
      "loss: 0.856177  [19200/525306]\n",
      "loss: 0.583376  [20800/525306]\n",
      "loss: 0.655457  [22400/525306]\n",
      "loss: 0.893382  [24000/525306]\n",
      "loss: 0.872566  [25600/525306]\n",
      "loss: 1.180574  [27200/525306]\n",
      "loss: 1.078316  [28800/525306]\n",
      "loss: 0.902144  [30400/525306]\n",
      "loss: 0.999062  [32000/525306]\n",
      "loss: 0.869119  [33600/525306]\n",
      "loss: 1.184546  [35200/525306]\n",
      "loss: 0.583107  [36800/525306]\n",
      "loss: 0.631419  [38400/525306]\n",
      "loss: 0.672738  [40000/525306]\n",
      "loss: 0.628977  [41600/525306]\n",
      "loss: 0.908828  [43200/525306]\n",
      "loss: 0.958676  [44800/525306]\n",
      "loss: 0.911114  [46400/525306]\n",
      "loss: 0.793915  [48000/525306]\n",
      "loss: 0.737991  [49600/525306]\n",
      "loss: 0.448054  [51200/525306]\n",
      "loss: 0.512339  [52800/525306]\n",
      "loss: 0.654757  [54400/525306]\n",
      "loss: 0.697660  [56000/525306]\n",
      "loss: 1.503328  [57600/525306]\n",
      "loss: 0.904032  [59200/525306]\n",
      "loss: 0.732627  [60800/525306]\n",
      "loss: 0.561186  [62400/525306]\n",
      "loss: 1.209258  [64000/525306]\n",
      "loss: 0.573948  [65600/525306]\n",
      "loss: 0.791341  [67200/525306]\n",
      "loss: 0.965222  [68800/525306]\n",
      "loss: 0.816391  [70400/525306]\n",
      "loss: 1.221426  [72000/525306]\n",
      "loss: 0.610731  [73600/525306]\n",
      "loss: 0.804637  [75200/525306]\n",
      "loss: 1.162672  [76800/525306]\n",
      "loss: 0.865456  [78400/525306]\n",
      "loss: 1.227651  [80000/525306]\n",
      "loss: 0.550012  [81600/525306]\n",
      "loss: 0.807884  [83200/525306]\n",
      "loss: 0.865174  [84800/525306]\n",
      "loss: 0.577500  [86400/525306]\n",
      "loss: 0.857082  [88000/525306]\n",
      "loss: 1.041975  [89600/525306]\n",
      "loss: 0.712654  [91200/525306]\n",
      "loss: 0.486623  [92800/525306]\n",
      "loss: 0.403293  [94400/525306]\n",
      "loss: 0.774039  [96000/525306]\n",
      "loss: 0.900379  [97600/525306]\n",
      "loss: 0.681693  [99200/525306]\n",
      "loss: 0.629254  [100800/525306]\n",
      "loss: 0.639957  [102400/525306]\n",
      "loss: 0.716972  [104000/525306]\n",
      "loss: 0.953528  [105600/525306]\n",
      "loss: 0.867391  [107200/525306]\n",
      "loss: 0.709766  [108800/525306]\n",
      "loss: 0.600563  [110400/525306]\n",
      "loss: 0.861705  [112000/525306]\n",
      "loss: 0.651580  [113600/525306]\n",
      "loss: 0.731246  [115200/525306]\n",
      "loss: 0.649353  [116800/525306]\n",
      "loss: 0.705140  [118400/525306]\n",
      "loss: 0.633774  [120000/525306]\n",
      "loss: 0.443134  [121600/525306]\n",
      "loss: 0.853519  [123200/525306]\n",
      "loss: 0.876196  [124800/525306]\n",
      "loss: 1.200878  [126400/525306]\n",
      "loss: 0.768590  [128000/525306]\n",
      "loss: 1.363467  [129600/525306]\n",
      "loss: 0.622370  [131200/525306]\n",
      "loss: 0.631795  [132800/525306]\n",
      "loss: 0.643572  [134400/525306]\n",
      "loss: 0.410317  [136000/525306]\n",
      "loss: 1.087073  [137600/525306]\n",
      "loss: 0.627771  [139200/525306]\n",
      "loss: 1.049286  [140800/525306]\n",
      "loss: 0.815980  [142400/525306]\n",
      "loss: 1.190228  [144000/525306]\n",
      "loss: 0.906968  [145600/525306]\n",
      "loss: 0.530360  [147200/525306]\n",
      "loss: 0.828938  [148800/525306]\n",
      "loss: 0.620072  [150400/525306]\n",
      "loss: 0.439436  [152000/525306]\n",
      "loss: 0.483997  [153600/525306]\n",
      "loss: 0.907842  [155200/525306]\n",
      "loss: 0.603844  [156800/525306]\n",
      "loss: 0.252640  [158400/525306]\n",
      "loss: 0.636312  [160000/525306]\n",
      "loss: 0.736653  [161600/525306]\n",
      "loss: 1.235362  [163200/525306]\n",
      "loss: 1.010656  [164800/525306]\n",
      "loss: 0.383719  [166400/525306]\n",
      "loss: 0.576440  [168000/525306]\n",
      "loss: 1.000902  [169600/525306]\n",
      "loss: 0.744693  [171200/525306]\n",
      "loss: 0.313517  [172800/525306]\n",
      "loss: 0.622909  [174400/525306]\n",
      "loss: 1.489450  [176000/525306]\n",
      "loss: 1.137938  [177600/525306]\n",
      "loss: 0.746063  [179200/525306]\n",
      "loss: 0.708975  [180800/525306]\n",
      "loss: 0.824451  [182400/525306]\n",
      "loss: 0.653791  [184000/525306]\n",
      "loss: 1.156539  [185600/525306]\n",
      "loss: 0.931439  [187200/525306]\n",
      "loss: 0.671469  [188800/525306]\n",
      "loss: 1.337447  [190400/525306]\n",
      "loss: 0.372517  [192000/525306]\n",
      "loss: 0.756018  [193600/525306]\n",
      "loss: 1.120946  [195200/525306]\n",
      "loss: 0.893256  [196800/525306]\n",
      "loss: 0.577199  [198400/525306]\n",
      "loss: 0.860720  [200000/525306]\n",
      "loss: 1.108384  [201600/525306]\n",
      "loss: 0.868015  [203200/525306]\n",
      "loss: 0.709712  [204800/525306]\n",
      "loss: 0.730501  [206400/525306]\n",
      "loss: 0.828085  [208000/525306]\n",
      "loss: 0.712084  [209600/525306]\n",
      "loss: 1.031875  [211200/525306]\n",
      "loss: 0.613704  [212800/525306]\n",
      "loss: 0.628166  [214400/525306]\n",
      "loss: 0.848491  [216000/525306]\n",
      "loss: 0.576567  [217600/525306]\n",
      "loss: 0.717617  [219200/525306]\n",
      "loss: 0.376224  [220800/525306]\n",
      "loss: 0.465599  [222400/525306]\n",
      "loss: 0.637506  [224000/525306]\n",
      "loss: 0.891638  [225600/525306]\n",
      "loss: 0.740654  [227200/525306]\n",
      "loss: 0.758740  [228800/525306]\n",
      "loss: 0.720701  [230400/525306]\n",
      "loss: 0.623792  [232000/525306]\n",
      "loss: 0.417645  [233600/525306]\n",
      "loss: 0.629444  [235200/525306]\n",
      "loss: 0.733276  [236800/525306]\n",
      "loss: 1.111506  [238400/525306]\n",
      "loss: 0.499682  [240000/525306]\n",
      "loss: 0.781636  [241600/525306]\n",
      "loss: 0.995162  [243200/525306]\n",
      "loss: 1.235415  [244800/525306]\n",
      "loss: 1.413978  [246400/525306]\n",
      "loss: 0.939622  [248000/525306]\n",
      "loss: 0.832878  [249600/525306]\n",
      "loss: 1.147535  [251200/525306]\n",
      "loss: 0.863097  [252800/525306]\n",
      "loss: 0.657504  [254400/525306]\n",
      "loss: 0.518951  [256000/525306]\n",
      "loss: 0.813810  [257600/525306]\n",
      "loss: 0.998974  [259200/525306]\n",
      "loss: 0.323442  [260800/525306]\n",
      "loss: 1.105876  [262400/525306]\n",
      "loss: 0.980411  [264000/525306]\n",
      "loss: 0.808298  [265600/525306]\n",
      "loss: 0.912143  [267200/525306]\n",
      "loss: 0.848510  [268800/525306]\n",
      "loss: 1.088282  [270400/525306]\n",
      "loss: 0.579661  [272000/525306]\n",
      "loss: 0.514354  [273600/525306]\n",
      "loss: 0.753881  [275200/525306]\n",
      "loss: 0.677343  [276800/525306]\n",
      "loss: 0.415863  [278400/525306]\n",
      "loss: 0.774882  [280000/525306]\n",
      "loss: 0.788117  [281600/525306]\n",
      "loss: 0.722731  [283200/525306]\n",
      "loss: 1.126777  [284800/525306]\n",
      "loss: 1.119599  [286400/525306]\n",
      "loss: 0.862441  [288000/525306]\n",
      "loss: 0.431037  [289600/525306]\n",
      "loss: 0.880420  [291200/525306]\n",
      "loss: 1.091835  [292800/525306]\n",
      "loss: 0.918449  [294400/525306]\n",
      "loss: 0.530143  [296000/525306]\n",
      "loss: 0.808451  [297600/525306]\n",
      "loss: 0.925212  [299200/525306]\n",
      "loss: 1.084062  [300800/525306]\n",
      "loss: 1.246548  [302400/525306]\n",
      "loss: 0.857551  [304000/525306]\n",
      "loss: 0.347493  [305600/525306]\n",
      "loss: 0.695405  [307200/525306]\n",
      "loss: 0.202352  [308800/525306]\n",
      "loss: 0.558251  [310400/525306]\n",
      "loss: 0.619671  [312000/525306]\n",
      "loss: 0.880187  [313600/525306]\n",
      "loss: 0.822402  [315200/525306]\n",
      "loss: 1.189269  [316800/525306]\n",
      "loss: 0.772476  [318400/525306]\n",
      "loss: 0.851010  [320000/525306]\n",
      "loss: 1.296398  [321600/525306]\n",
      "loss: 1.167663  [323200/525306]\n",
      "loss: 0.846305  [324800/525306]\n",
      "loss: 0.858571  [326400/525306]\n",
      "loss: 0.936858  [328000/525306]\n",
      "loss: 0.716553  [329600/525306]\n",
      "loss: 0.954160  [331200/525306]\n",
      "loss: 1.013667  [332800/525306]\n",
      "loss: 0.993102  [334400/525306]\n",
      "loss: 0.845432  [336000/525306]\n",
      "loss: 1.029167  [337600/525306]\n",
      "loss: 0.921103  [339200/525306]\n",
      "loss: 0.455561  [340800/525306]\n",
      "loss: 0.795078  [342400/525306]\n",
      "loss: 1.185323  [344000/525306]\n",
      "loss: 0.571348  [345600/525306]\n",
      "loss: 0.746427  [347200/525306]\n",
      "loss: 1.092398  [348800/525306]\n",
      "loss: 0.542673  [350400/525306]\n",
      "loss: 1.429720  [352000/525306]\n",
      "loss: 0.985911  [353600/525306]\n",
      "loss: 0.637186  [355200/525306]\n",
      "loss: 1.270707  [356800/525306]\n",
      "loss: 0.764870  [358400/525306]\n",
      "loss: 0.993519  [360000/525306]\n",
      "loss: 0.910683  [361600/525306]\n",
      "loss: 1.006506  [363200/525306]\n",
      "loss: 0.903541  [364800/525306]\n",
      "loss: 0.780240  [366400/525306]\n",
      "loss: 0.954198  [368000/525306]\n",
      "loss: 0.630268  [369600/525306]\n",
      "loss: 0.661226  [371200/525306]\n",
      "loss: 0.537507  [372800/525306]\n",
      "loss: 0.842561  [374400/525306]\n",
      "loss: 1.097542  [376000/525306]\n",
      "loss: 0.344136  [377600/525306]\n",
      "loss: 0.854785  [379200/525306]\n",
      "loss: 1.834095  [380800/525306]\n",
      "loss: 0.810242  [382400/525306]\n",
      "loss: 0.568884  [384000/525306]\n",
      "loss: 0.531441  [385600/525306]\n",
      "loss: 0.350112  [387200/525306]\n",
      "loss: 1.386812  [388800/525306]\n",
      "loss: 0.896299  [390400/525306]\n",
      "loss: 0.829444  [392000/525306]\n",
      "loss: 0.531111  [393600/525306]\n",
      "loss: 1.153649  [395200/525306]\n",
      "loss: 1.327399  [396800/525306]\n",
      "loss: 0.618100  [398400/525306]\n",
      "loss: 0.589901  [400000/525306]\n",
      "loss: 0.851231  [401600/525306]\n",
      "loss: 0.565987  [403200/525306]\n",
      "loss: 0.778431  [404800/525306]\n",
      "loss: 0.816646  [406400/525306]\n",
      "loss: 0.866971  [408000/525306]\n",
      "loss: 0.388782  [409600/525306]\n",
      "loss: 1.214278  [411200/525306]\n",
      "loss: 0.827191  [412800/525306]\n",
      "loss: 0.803640  [414400/525306]\n",
      "loss: 0.759781  [416000/525306]\n",
      "loss: 1.153975  [417600/525306]\n",
      "loss: 0.800703  [419200/525306]\n",
      "loss: 0.882640  [420800/525306]\n",
      "loss: 0.757438  [422400/525306]\n",
      "loss: 0.444620  [424000/525306]\n",
      "loss: 0.782654  [425600/525306]\n",
      "loss: 0.414637  [427200/525306]\n",
      "loss: 0.896925  [428800/525306]\n",
      "loss: 0.878456  [430400/525306]\n",
      "loss: 0.701797  [432000/525306]\n",
      "loss: 0.813176  [433600/525306]\n",
      "loss: 0.812138  [435200/525306]\n",
      "loss: 1.095250  [436800/525306]\n",
      "loss: 0.460110  [438400/525306]\n",
      "loss: 0.640547  [440000/525306]\n",
      "loss: 0.904834  [441600/525306]\n",
      "loss: 0.961001  [443200/525306]\n",
      "loss: 0.918376  [444800/525306]\n",
      "loss: 1.298991  [446400/525306]\n",
      "loss: 0.580941  [448000/525306]\n",
      "loss: 0.692851  [449600/525306]\n",
      "loss: 0.425865  [451200/525306]\n",
      "loss: 0.332826  [452800/525306]\n",
      "loss: 0.844209  [454400/525306]\n",
      "loss: 0.598348  [456000/525306]\n",
      "loss: 0.615819  [457600/525306]\n",
      "loss: 0.513356  [459200/525306]\n",
      "loss: 0.666203  [460800/525306]\n",
      "loss: 0.667856  [462400/525306]\n",
      "loss: 0.862694  [464000/525306]\n",
      "loss: 0.569831  [465600/525306]\n",
      "loss: 0.635019  [467200/525306]\n",
      "loss: 0.833407  [468800/525306]\n",
      "loss: 0.827366  [470400/525306]\n",
      "loss: 0.784465  [472000/525306]\n",
      "loss: 1.109149  [473600/525306]\n",
      "loss: 1.029279  [475200/525306]\n",
      "loss: 0.691915  [476800/525306]\n",
      "loss: 0.386309  [478400/525306]\n",
      "loss: 1.062615  [480000/525306]\n",
      "loss: 0.404716  [481600/525306]\n",
      "loss: 0.861356  [483200/525306]\n",
      "loss: 0.749772  [484800/525306]\n",
      "loss: 0.477885  [486400/525306]\n",
      "loss: 0.653768  [488000/525306]\n",
      "loss: 0.514972  [489600/525306]\n",
      "loss: 0.594913  [491200/525306]\n",
      "loss: 0.992129  [492800/525306]\n",
      "loss: 0.857285  [494400/525306]\n",
      "loss: 0.649274  [496000/525306]\n",
      "loss: 0.618407  [497600/525306]\n",
      "loss: 0.833482  [499200/525306]\n",
      "loss: 1.556612  [500800/525306]\n",
      "loss: 1.021834  [502400/525306]\n",
      "loss: 0.314407  [504000/525306]\n",
      "loss: 0.835210  [505600/525306]\n",
      "loss: 0.457717  [507200/525306]\n",
      "loss: 0.352673  [508800/525306]\n",
      "loss: 0.827844  [510400/525306]\n",
      "loss: 0.943547  [512000/525306]\n",
      "loss: 0.940114  [513600/525306]\n",
      "loss: 0.707656  [515200/525306]\n",
      "loss: 0.719557  [516800/525306]\n",
      "loss: 0.383110  [518400/525306]\n",
      "loss: 1.002362  [520000/525306]\n",
      "loss: 0.585812  [521600/525306]\n",
      "loss: 1.431868  [523200/525306]\n",
      "loss: 0.848731  [524800/525306]\n",
      "Train Accuracy: 70.1444%\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.922019, F1-score: 69.85%, Macro_F1-Score:  38.59%  \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.972799  [    0/525306]\n",
      "loss: 1.463418  [ 1600/525306]\n",
      "loss: 1.033363  [ 3200/525306]\n",
      "loss: 0.713223  [ 4800/525306]\n",
      "loss: 0.473868  [ 6400/525306]\n",
      "loss: 0.376660  [ 8000/525306]\n",
      "loss: 0.940783  [ 9600/525306]\n",
      "loss: 0.719279  [11200/525306]\n",
      "loss: 0.976084  [12800/525306]\n",
      "loss: 0.450716  [14400/525306]\n",
      "loss: 0.374273  [16000/525306]\n",
      "loss: 0.941262  [17600/525306]\n",
      "loss: 1.198132  [19200/525306]\n",
      "loss: 1.204430  [20800/525306]\n",
      "loss: 0.674905  [22400/525306]\n",
      "loss: 1.136738  [24000/525306]\n",
      "loss: 0.409358  [25600/525306]\n",
      "loss: 1.147869  [27200/525306]\n",
      "loss: 0.738668  [28800/525306]\n",
      "loss: 0.567080  [30400/525306]\n",
      "loss: 0.891131  [32000/525306]\n",
      "loss: 0.607056  [33600/525306]\n",
      "loss: 0.472285  [35200/525306]\n",
      "loss: 0.524834  [36800/525306]\n",
      "loss: 0.284967  [38400/525306]\n",
      "loss: 0.642911  [40000/525306]\n",
      "loss: 0.720386  [41600/525306]\n",
      "loss: 0.827340  [43200/525306]\n",
      "loss: 0.661539  [44800/525306]\n",
      "loss: 0.775024  [46400/525306]\n",
      "loss: 0.635074  [48000/525306]\n",
      "loss: 0.846992  [49600/525306]\n",
      "loss: 0.737047  [51200/525306]\n",
      "loss: 0.444973  [52800/525306]\n",
      "loss: 1.149570  [54400/525306]\n",
      "loss: 1.002474  [56000/525306]\n",
      "loss: 0.920895  [57600/525306]\n",
      "loss: 0.815308  [59200/525306]\n",
      "loss: 0.548081  [60800/525306]\n",
      "loss: 1.434261  [62400/525306]\n",
      "loss: 0.736277  [64000/525306]\n",
      "loss: 1.093175  [65600/525306]\n",
      "loss: 0.893270  [67200/525306]\n",
      "loss: 0.685385  [68800/525306]\n",
      "loss: 0.423253  [70400/525306]\n",
      "loss: 0.723035  [72000/525306]\n",
      "loss: 0.828193  [73600/525306]\n",
      "loss: 0.672442  [75200/525306]\n",
      "loss: 0.393006  [76800/525306]\n",
      "loss: 0.867009  [78400/525306]\n",
      "loss: 1.070832  [80000/525306]\n",
      "loss: 0.914381  [81600/525306]\n",
      "loss: 0.707379  [83200/525306]\n",
      "loss: 1.041932  [84800/525306]\n",
      "loss: 0.502404  [86400/525306]\n",
      "loss: 0.872447  [88000/525306]\n",
      "loss: 1.008190  [89600/525306]\n",
      "loss: 1.163177  [91200/525306]\n",
      "loss: 0.622681  [92800/525306]\n",
      "loss: 0.992087  [94400/525306]\n",
      "loss: 0.879887  [96000/525306]\n",
      "loss: 1.138555  [97600/525306]\n",
      "loss: 0.768491  [99200/525306]\n",
      "loss: 0.526305  [100800/525306]\n",
      "loss: 0.610061  [102400/525306]\n",
      "loss: 0.574603  [104000/525306]\n",
      "loss: 0.929472  [105600/525306]\n",
      "loss: 0.801886  [107200/525306]\n",
      "loss: 0.682670  [108800/525306]\n",
      "loss: 0.701874  [110400/525306]\n",
      "loss: 0.446680  [112000/525306]\n",
      "loss: 0.680015  [113600/525306]\n",
      "loss: 0.498808  [115200/525306]\n",
      "loss: 0.798444  [116800/525306]\n",
      "loss: 0.935891  [118400/525306]\n",
      "loss: 0.978684  [120000/525306]\n",
      "loss: 0.730940  [121600/525306]\n",
      "loss: 0.920831  [123200/525306]\n",
      "loss: 0.674070  [124800/525306]\n",
      "loss: 1.262468  [126400/525306]\n",
      "loss: 0.789469  [128000/525306]\n",
      "loss: 0.435075  [129600/525306]\n",
      "loss: 0.939182  [131200/525306]\n",
      "loss: 0.772648  [132800/525306]\n",
      "loss: 0.624244  [134400/525306]\n",
      "loss: 1.209914  [136000/525306]\n",
      "loss: 0.642190  [137600/525306]\n",
      "loss: 0.957613  [139200/525306]\n",
      "loss: 0.559736  [140800/525306]\n",
      "loss: 1.283150  [142400/525306]\n",
      "loss: 0.668662  [144000/525306]\n",
      "loss: 0.684226  [145600/525306]\n",
      "loss: 0.760158  [147200/525306]\n",
      "loss: 0.718561  [148800/525306]\n",
      "loss: 0.933539  [150400/525306]\n",
      "loss: 0.560873  [152000/525306]\n",
      "loss: 0.506812  [153600/525306]\n",
      "loss: 0.931910  [155200/525306]\n",
      "loss: 0.813810  [156800/525306]\n",
      "loss: 0.894675  [158400/525306]\n",
      "loss: 0.771655  [160000/525306]\n",
      "loss: 0.892706  [161600/525306]\n",
      "loss: 0.746740  [163200/525306]\n",
      "loss: 0.833743  [164800/525306]\n",
      "loss: 0.728143  [166400/525306]\n",
      "loss: 0.913074  [168000/525306]\n",
      "loss: 0.772273  [169600/525306]\n",
      "loss: 0.552386  [171200/525306]\n",
      "loss: 0.559421  [172800/525306]\n",
      "loss: 0.704862  [174400/525306]\n",
      "loss: 1.170398  [176000/525306]\n",
      "loss: 0.603944  [177600/525306]\n",
      "loss: 0.503763  [179200/525306]\n",
      "loss: 0.789435  [180800/525306]\n",
      "loss: 0.959618  [182400/525306]\n",
      "loss: 1.320458  [184000/525306]\n",
      "loss: 1.128322  [185600/525306]\n",
      "loss: 1.011573  [187200/525306]\n",
      "loss: 0.421782  [188800/525306]\n",
      "loss: 0.458332  [190400/525306]\n",
      "loss: 1.489534  [192000/525306]\n",
      "loss: 1.156851  [193600/525306]\n",
      "loss: 0.797760  [195200/525306]\n",
      "loss: 0.443893  [196800/525306]\n",
      "loss: 0.854503  [198400/525306]\n",
      "loss: 0.403553  [200000/525306]\n",
      "loss: 0.861614  [201600/525306]\n",
      "loss: 0.626112  [203200/525306]\n",
      "loss: 0.762738  [204800/525306]\n",
      "loss: 0.610710  [206400/525306]\n",
      "loss: 0.871208  [208000/525306]\n",
      "loss: 0.827845  [209600/525306]\n",
      "loss: 0.526736  [211200/525306]\n",
      "loss: 0.767484  [212800/525306]\n",
      "loss: 0.456942  [214400/525306]\n",
      "loss: 0.813802  [216000/525306]\n",
      "loss: 0.515092  [217600/525306]\n",
      "loss: 0.502163  [219200/525306]\n",
      "loss: 0.986686  [220800/525306]\n",
      "loss: 0.587937  [222400/525306]\n",
      "loss: 0.434394  [224000/525306]\n",
      "loss: 0.766540  [225600/525306]\n",
      "loss: 0.679387  [227200/525306]\n",
      "loss: 1.263094  [228800/525306]\n",
      "loss: 1.276138  [230400/525306]\n",
      "loss: 0.728918  [232000/525306]\n",
      "loss: 0.968159  [233600/525306]\n",
      "loss: 0.710381  [235200/525306]\n",
      "loss: 0.788018  [236800/525306]\n",
      "loss: 0.528593  [238400/525306]\n",
      "loss: 0.800669  [240000/525306]\n",
      "loss: 0.575228  [241600/525306]\n",
      "loss: 1.073142  [243200/525306]\n",
      "loss: 1.033851  [244800/525306]\n",
      "loss: 0.648130  [246400/525306]\n",
      "loss: 0.708306  [248000/525306]\n",
      "loss: 0.691170  [249600/525306]\n",
      "loss: 0.984929  [251200/525306]\n",
      "loss: 0.868612  [252800/525306]\n",
      "loss: 0.676703  [254400/525306]\n",
      "loss: 0.639112  [256000/525306]\n",
      "loss: 0.438027  [257600/525306]\n",
      "loss: 1.108475  [259200/525306]\n",
      "loss: 0.723489  [260800/525306]\n",
      "loss: 0.908659  [262400/525306]\n",
      "loss: 0.895459  [264000/525306]\n",
      "loss: 0.298970  [265600/525306]\n",
      "loss: 0.979550  [267200/525306]\n",
      "loss: 0.754112  [268800/525306]\n",
      "loss: 1.034389  [270400/525306]\n",
      "loss: 1.043687  [272000/525306]\n",
      "loss: 0.898761  [273600/525306]\n",
      "loss: 0.611705  [275200/525306]\n",
      "loss: 0.597478  [276800/525306]\n",
      "loss: 0.531339  [278400/525306]\n",
      "loss: 0.842097  [280000/525306]\n",
      "loss: 0.959023  [281600/525306]\n",
      "loss: 0.541102  [283200/525306]\n",
      "loss: 0.880989  [284800/525306]\n",
      "loss: 0.970748  [286400/525306]\n",
      "loss: 0.609267  [288000/525306]\n",
      "loss: 0.824035  [289600/525306]\n",
      "loss: 0.737260  [291200/525306]\n",
      "loss: 0.863041  [292800/525306]\n",
      "loss: 0.501274  [294400/525306]\n",
      "loss: 0.939041  [296000/525306]\n",
      "loss: 0.821664  [297600/525306]\n",
      "loss: 0.864720  [299200/525306]\n",
      "loss: 0.679637  [300800/525306]\n",
      "loss: 0.716633  [302400/525306]\n",
      "loss: 0.424606  [304000/525306]\n",
      "loss: 1.155653  [305600/525306]\n",
      "loss: 0.671124  [307200/525306]\n",
      "loss: 0.554305  [308800/525306]\n",
      "loss: 1.026195  [310400/525306]\n",
      "loss: 0.954384  [312000/525306]\n",
      "loss: 1.356468  [313600/525306]\n",
      "loss: 0.504099  [315200/525306]\n",
      "loss: 0.682647  [316800/525306]\n",
      "loss: 0.956758  [318400/525306]\n",
      "loss: 0.635839  [320000/525306]\n",
      "loss: 0.802507  [321600/525306]\n",
      "loss: 0.514556  [323200/525306]\n",
      "loss: 0.979193  [324800/525306]\n",
      "loss: 0.753055  [326400/525306]\n",
      "loss: 0.589942  [328000/525306]\n",
      "loss: 0.664281  [329600/525306]\n",
      "loss: 0.776383  [331200/525306]\n",
      "loss: 0.894884  [332800/525306]\n",
      "loss: 0.647541  [334400/525306]\n",
      "loss: 0.613273  [336000/525306]\n",
      "loss: 0.764500  [337600/525306]\n",
      "loss: 1.039363  [339200/525306]\n",
      "loss: 0.670854  [340800/525306]\n",
      "loss: 1.110490  [342400/525306]\n",
      "loss: 0.705276  [344000/525306]\n",
      "loss: 1.164866  [345600/525306]\n",
      "loss: 0.671546  [347200/525306]\n",
      "loss: 0.755706  [348800/525306]\n",
      "loss: 0.588006  [350400/525306]\n",
      "loss: 0.645452  [352000/525306]\n",
      "loss: 0.661820  [353600/525306]\n",
      "loss: 0.664784  [355200/525306]\n",
      "loss: 1.059009  [356800/525306]\n",
      "loss: 0.864588  [358400/525306]\n",
      "loss: 0.748210  [360000/525306]\n",
      "loss: 0.932329  [361600/525306]\n",
      "loss: 0.855569  [363200/525306]\n",
      "loss: 0.408312  [364800/525306]\n",
      "loss: 0.618743  [366400/525306]\n",
      "loss: 0.813191  [368000/525306]\n",
      "loss: 0.623373  [369600/525306]\n",
      "loss: 0.729098  [371200/525306]\n",
      "loss: 0.739759  [372800/525306]\n",
      "loss: 0.731300  [374400/525306]\n",
      "loss: 0.908905  [376000/525306]\n",
      "loss: 0.428870  [377600/525306]\n",
      "loss: 0.810353  [379200/525306]\n",
      "loss: 0.957264  [380800/525306]\n",
      "loss: 0.943606  [382400/525306]\n",
      "loss: 0.549001  [384000/525306]\n",
      "loss: 0.417787  [385600/525306]\n",
      "loss: 0.730733  [387200/525306]\n",
      "loss: 0.704419  [388800/525306]\n",
      "loss: 0.533656  [390400/525306]\n",
      "loss: 1.297364  [392000/525306]\n",
      "loss: 0.767748  [393600/525306]\n",
      "loss: 0.581710  [395200/525306]\n",
      "loss: 0.840031  [396800/525306]\n",
      "loss: 0.647510  [398400/525306]\n",
      "loss: 1.010394  [400000/525306]\n",
      "loss: 1.435853  [401600/525306]\n",
      "loss: 0.331214  [403200/525306]\n",
      "loss: 0.701887  [404800/525306]\n",
      "loss: 0.813630  [406400/525306]\n",
      "loss: 0.981095  [408000/525306]\n",
      "loss: 0.737665  [409600/525306]\n",
      "loss: 0.408748  [411200/525306]\n",
      "loss: 0.559942  [412800/525306]\n",
      "loss: 0.987491  [414400/525306]\n",
      "loss: 0.924436  [416000/525306]\n",
      "loss: 0.503071  [417600/525306]\n",
      "loss: 1.067381  [419200/525306]\n",
      "loss: 0.993687  [420800/525306]\n",
      "loss: 0.516986  [422400/525306]\n",
      "loss: 0.566850  [424000/525306]\n",
      "loss: 0.872278  [425600/525306]\n",
      "loss: 0.688102  [427200/525306]\n",
      "loss: 0.795083  [428800/525306]\n",
      "loss: 0.251789  [430400/525306]\n",
      "loss: 0.531779  [432000/525306]\n",
      "loss: 0.633379  [433600/525306]\n",
      "loss: 0.963981  [435200/525306]\n",
      "loss: 0.536587  [436800/525306]\n",
      "loss: 0.778903  [438400/525306]\n",
      "loss: 1.277696  [440000/525306]\n",
      "loss: 0.784799  [441600/525306]\n",
      "loss: 0.664373  [443200/525306]\n",
      "loss: 0.712627  [444800/525306]\n",
      "loss: 0.536071  [446400/525306]\n",
      "loss: 0.525249  [448000/525306]\n",
      "loss: 0.489298  [449600/525306]\n",
      "loss: 0.765198  [451200/525306]\n",
      "loss: 0.906493  [452800/525306]\n",
      "loss: 0.461230  [454400/525306]\n",
      "loss: 0.697854  [456000/525306]\n",
      "loss: 0.528089  [457600/525306]\n",
      "loss: 0.892610  [459200/525306]\n",
      "loss: 0.778580  [460800/525306]\n",
      "loss: 0.622427  [462400/525306]\n",
      "loss: 0.743716  [464000/525306]\n",
      "loss: 0.458954  [465600/525306]\n",
      "loss: 0.298475  [467200/525306]\n",
      "loss: 0.712288  [468800/525306]\n",
      "loss: 0.683639  [470400/525306]\n",
      "loss: 0.559260  [472000/525306]\n",
      "loss: 1.233335  [473600/525306]\n",
      "loss: 0.911464  [475200/525306]\n",
      "loss: 0.779814  [476800/525306]\n",
      "loss: 0.324010  [478400/525306]\n",
      "loss: 0.584423  [480000/525306]\n",
      "loss: 0.957511  [481600/525306]\n",
      "loss: 1.072989  [483200/525306]\n",
      "loss: 0.864219  [484800/525306]\n",
      "loss: 1.105130  [486400/525306]\n",
      "loss: 1.030684  [488000/525306]\n",
      "loss: 0.601272  [489600/525306]\n",
      "loss: 0.519489  [491200/525306]\n",
      "loss: 1.023167  [492800/525306]\n",
      "loss: 0.547149  [494400/525306]\n",
      "loss: 0.691883  [496000/525306]\n",
      "loss: 0.875122  [497600/525306]\n",
      "loss: 0.670757  [499200/525306]\n",
      "loss: 0.691981  [500800/525306]\n",
      "loss: 0.849868  [502400/525306]\n",
      "loss: 0.532998  [504000/525306]\n",
      "loss: 0.615836  [505600/525306]\n",
      "loss: 1.372858  [507200/525306]\n",
      "loss: 0.694395  [508800/525306]\n",
      "loss: 1.047718  [510400/525306]\n",
      "loss: 0.364625  [512000/525306]\n",
      "loss: 0.822462  [513600/525306]\n",
      "loss: 0.559587  [515200/525306]\n",
      "loss: 0.512693  [516800/525306]\n",
      "loss: 0.341435  [518400/525306]\n",
      "loss: 1.262315  [520000/525306]\n",
      "loss: 0.647307  [521600/525306]\n",
      "loss: 0.886741  [523200/525306]\n",
      "loss: 1.312578  [524800/525306]\n",
      "Train Accuracy: 70.9617%\n",
      "Test Error: \n",
      " Accuracy: 64.7%, Avg loss: 0.881963, F1-score: 70.71%, Macro_F1-Score:  40.27%  \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.926889  [    0/525306]\n",
      "loss: 0.492056  [ 1600/525306]\n",
      "loss: 0.920615  [ 3200/525306]\n",
      "loss: 0.423291  [ 4800/525306]\n",
      "loss: 0.773443  [ 6400/525306]\n",
      "loss: 0.707930  [ 8000/525306]\n",
      "loss: 0.711036  [ 9600/525306]\n",
      "loss: 0.464125  [11200/525306]\n",
      "loss: 0.915003  [12800/525306]\n",
      "loss: 0.731966  [14400/525306]\n",
      "loss: 0.476233  [16000/525306]\n",
      "loss: 0.775327  [17600/525306]\n",
      "loss: 0.513933  [19200/525306]\n",
      "loss: 0.670882  [20800/525306]\n",
      "loss: 1.012080  [22400/525306]\n",
      "loss: 0.722306  [24000/525306]\n",
      "loss: 1.011107  [25600/525306]\n",
      "loss: 1.029541  [27200/525306]\n",
      "loss: 0.569303  [28800/525306]\n",
      "loss: 0.759307  [30400/525306]\n",
      "loss: 0.728718  [32000/525306]\n",
      "loss: 0.544167  [33600/525306]\n",
      "loss: 0.975245  [35200/525306]\n",
      "loss: 0.854048  [36800/525306]\n",
      "loss: 0.710142  [38400/525306]\n",
      "loss: 0.780171  [40000/525306]\n",
      "loss: 0.886282  [41600/525306]\n",
      "loss: 0.625398  [43200/525306]\n",
      "loss: 1.182479  [44800/525306]\n",
      "loss: 0.834820  [46400/525306]\n",
      "loss: 0.939765  [48000/525306]\n",
      "loss: 0.587078  [49600/525306]\n",
      "loss: 0.681862  [51200/525306]\n",
      "loss: 0.473718  [52800/525306]\n",
      "loss: 0.509331  [54400/525306]\n",
      "loss: 0.536497  [56000/525306]\n",
      "loss: 0.505333  [57600/525306]\n",
      "loss: 0.619594  [59200/525306]\n",
      "loss: 0.922165  [60800/525306]\n",
      "loss: 1.558282  [62400/525306]\n",
      "loss: 1.031063  [64000/525306]\n",
      "loss: 0.965940  [65600/525306]\n",
      "loss: 1.209049  [67200/525306]\n",
      "loss: 0.832637  [68800/525306]\n",
      "loss: 0.513316  [70400/525306]\n",
      "loss: 0.756259  [72000/525306]\n",
      "loss: 0.545059  [73600/525306]\n",
      "loss: 0.734393  [75200/525306]\n",
      "loss: 0.648002  [76800/525306]\n",
      "loss: 0.646052  [78400/525306]\n",
      "loss: 0.657530  [80000/525306]\n",
      "loss: 0.382968  [81600/525306]\n",
      "loss: 1.169685  [83200/525306]\n",
      "loss: 0.804539  [84800/525306]\n",
      "loss: 1.023507  [86400/525306]\n",
      "loss: 1.025278  [88000/525306]\n",
      "loss: 0.968291  [89600/525306]\n",
      "loss: 1.075571  [91200/525306]\n",
      "loss: 0.706604  [92800/525306]\n",
      "loss: 0.419000  [94400/525306]\n",
      "loss: 0.471729  [96000/525306]\n",
      "loss: 0.567693  [97600/525306]\n",
      "loss: 0.894372  [99200/525306]\n",
      "loss: 0.720588  [100800/525306]\n",
      "loss: 0.574113  [102400/525306]\n",
      "loss: 0.770275  [104000/525306]\n",
      "loss: 0.716643  [105600/525306]\n",
      "loss: 1.064902  [107200/525306]\n",
      "loss: 0.901540  [108800/525306]\n",
      "loss: 0.696996  [110400/525306]\n",
      "loss: 0.669818  [112000/525306]\n",
      "loss: 0.761043  [113600/525306]\n",
      "loss: 1.197710  [115200/525306]\n",
      "loss: 0.638769  [116800/525306]\n",
      "loss: 0.838437  [118400/525306]\n",
      "loss: 0.878624  [120000/525306]\n",
      "loss: 0.751138  [121600/525306]\n",
      "loss: 0.489116  [123200/525306]\n",
      "loss: 0.672146  [124800/525306]\n",
      "loss: 0.580458  [126400/525306]\n",
      "loss: 1.137761  [128000/525306]\n",
      "loss: 0.407831  [129600/525306]\n",
      "loss: 0.648552  [131200/525306]\n",
      "loss: 0.877151  [132800/525306]\n",
      "loss: 0.357818  [134400/525306]\n",
      "loss: 1.112371  [136000/525306]\n",
      "loss: 0.873598  [137600/525306]\n",
      "loss: 0.701701  [139200/525306]\n",
      "loss: 0.657047  [140800/525306]\n",
      "loss: 0.513073  [142400/525306]\n",
      "loss: 1.082528  [144000/525306]\n",
      "loss: 0.941072  [145600/525306]\n",
      "loss: 0.814103  [147200/525306]\n",
      "loss: 0.705313  [148800/525306]\n",
      "loss: 1.262807  [150400/525306]\n",
      "loss: 0.696206  [152000/525306]\n",
      "loss: 0.309201  [153600/525306]\n",
      "loss: 1.037236  [155200/525306]\n",
      "loss: 0.395060  [156800/525306]\n",
      "loss: 0.449641  [158400/525306]\n",
      "loss: 0.330915  [160000/525306]\n",
      "loss: 0.849362  [161600/525306]\n",
      "loss: 0.819274  [163200/525306]\n",
      "loss: 0.667703  [164800/525306]\n",
      "loss: 1.063475  [166400/525306]\n",
      "loss: 0.589407  [168000/525306]\n",
      "loss: 0.812962  [169600/525306]\n",
      "loss: 0.595632  [171200/525306]\n",
      "loss: 0.629076  [172800/525306]\n",
      "loss: 0.792035  [174400/525306]\n",
      "loss: 1.022893  [176000/525306]\n",
      "loss: 1.267836  [177600/525306]\n",
      "loss: 0.728642  [179200/525306]\n",
      "loss: 1.037331  [180800/525306]\n",
      "loss: 0.979857  [182400/525306]\n",
      "loss: 0.701548  [184000/525306]\n",
      "loss: 0.814181  [185600/525306]\n",
      "loss: 0.737206  [187200/525306]\n",
      "loss: 0.959523  [188800/525306]\n",
      "loss: 0.630081  [190400/525306]\n",
      "loss: 1.056458  [192000/525306]\n",
      "loss: 1.196487  [193600/525306]\n",
      "loss: 0.444315  [195200/525306]\n",
      "loss: 0.546308  [196800/525306]\n",
      "loss: 0.998060  [198400/525306]\n",
      "loss: 0.545215  [200000/525306]\n",
      "loss: 0.677444  [201600/525306]\n",
      "loss: 0.727443  [203200/525306]\n",
      "loss: 1.064770  [204800/525306]\n",
      "loss: 0.811389  [206400/525306]\n",
      "loss: 0.610600  [208000/525306]\n",
      "loss: 0.357604  [209600/525306]\n",
      "loss: 0.963992  [211200/525306]\n",
      "loss: 0.707163  [212800/525306]\n",
      "loss: 0.392921  [214400/525306]\n",
      "loss: 0.632480  [216000/525306]\n",
      "loss: 0.590649  [217600/525306]\n",
      "loss: 0.773566  [219200/525306]\n",
      "loss: 0.764644  [220800/525306]\n",
      "loss: 0.554476  [222400/525306]\n",
      "loss: 0.494150  [224000/525306]\n",
      "loss: 0.793027  [225600/525306]\n",
      "loss: 1.147353  [227200/525306]\n",
      "loss: 0.823417  [228800/525306]\n",
      "loss: 0.456537  [230400/525306]\n",
      "loss: 0.600840  [232000/525306]\n",
      "loss: 0.569935  [233600/525306]\n",
      "loss: 0.823865  [235200/525306]\n",
      "loss: 0.993032  [236800/525306]\n",
      "loss: 0.553595  [238400/525306]\n",
      "loss: 0.778177  [240000/525306]\n",
      "loss: 0.709051  [241600/525306]\n",
      "loss: 0.788744  [243200/525306]\n",
      "loss: 0.528825  [244800/525306]\n",
      "loss: 0.448623  [246400/525306]\n",
      "loss: 0.814439  [248000/525306]\n",
      "loss: 0.352059  [249600/525306]\n",
      "loss: 0.881942  [251200/525306]\n",
      "loss: 0.873256  [252800/525306]\n",
      "loss: 0.649510  [254400/525306]\n",
      "loss: 0.715746  [256000/525306]\n",
      "loss: 0.403093  [257600/525306]\n",
      "loss: 0.720648  [259200/525306]\n",
      "loss: 0.744091  [260800/525306]\n",
      "loss: 0.806237  [262400/525306]\n",
      "loss: 0.612268  [264000/525306]\n",
      "loss: 0.573172  [265600/525306]\n",
      "loss: 0.555250  [267200/525306]\n",
      "loss: 0.742707  [268800/525306]\n",
      "loss: 0.555852  [270400/525306]\n",
      "loss: 0.701490  [272000/525306]\n",
      "loss: 0.515376  [273600/525306]\n",
      "loss: 0.630041  [275200/525306]\n",
      "loss: 0.627539  [276800/525306]\n",
      "loss: 0.564850  [278400/525306]\n",
      "loss: 1.190076  [280000/525306]\n",
      "loss: 0.923124  [281600/525306]\n",
      "loss: 1.252620  [283200/525306]\n",
      "loss: 0.699494  [284800/525306]\n",
      "loss: 0.645105  [286400/525306]\n",
      "loss: 1.016719  [288000/525306]\n",
      "loss: 0.957209  [289600/525306]\n",
      "loss: 0.692412  [291200/525306]\n",
      "loss: 0.901972  [292800/525306]\n",
      "loss: 0.674158  [294400/525306]\n",
      "loss: 0.536536  [296000/525306]\n",
      "loss: 0.692091  [297600/525306]\n",
      "loss: 0.402330  [299200/525306]\n",
      "loss: 0.710757  [300800/525306]\n",
      "loss: 0.496887  [302400/525306]\n",
      "loss: 1.361600  [304000/525306]\n",
      "loss: 1.014911  [305600/525306]\n",
      "loss: 1.701348  [307200/525306]\n",
      "loss: 1.015065  [308800/525306]\n",
      "loss: 0.681331  [310400/525306]\n",
      "loss: 0.571737  [312000/525306]\n",
      "loss: 0.987207  [313600/525306]\n",
      "loss: 0.586441  [315200/525306]\n",
      "loss: 0.961867  [316800/525306]\n",
      "loss: 0.604863  [318400/525306]\n",
      "loss: 1.020782  [320000/525306]\n",
      "loss: 0.928584  [321600/525306]\n",
      "loss: 0.612477  [323200/525306]\n",
      "loss: 0.876288  [324800/525306]\n",
      "loss: 0.661109  [326400/525306]\n",
      "loss: 1.152179  [328000/525306]\n",
      "loss: 0.667419  [329600/525306]\n",
      "loss: 0.784117  [331200/525306]\n",
      "loss: 0.490331  [332800/525306]\n",
      "loss: 0.894560  [334400/525306]\n",
      "loss: 0.978628  [336000/525306]\n",
      "loss: 0.604830  [337600/525306]\n",
      "loss: 0.725819  [339200/525306]\n",
      "loss: 0.868031  [340800/525306]\n",
      "loss: 0.820455  [342400/525306]\n",
      "loss: 0.597428  [344000/525306]\n",
      "loss: 0.725133  [345600/525306]\n",
      "loss: 0.817122  [347200/525306]\n",
      "loss: 0.645360  [348800/525306]\n",
      "loss: 1.042530  [350400/525306]\n",
      "loss: 0.751638  [352000/525306]\n",
      "loss: 0.462932  [353600/525306]\n",
      "loss: 1.295924  [355200/525306]\n",
      "loss: 1.106071  [356800/525306]\n",
      "loss: 0.419036  [358400/525306]\n",
      "loss: 0.415145  [360000/525306]\n",
      "loss: 0.821988  [361600/525306]\n",
      "loss: 0.812486  [363200/525306]\n",
      "loss: 0.615156  [364800/525306]\n",
      "loss: 0.673177  [366400/525306]\n",
      "loss: 0.516228  [368000/525306]\n",
      "loss: 0.419657  [369600/525306]\n",
      "loss: 0.704710  [371200/525306]\n",
      "loss: 0.525216  [372800/525306]\n",
      "loss: 0.647210  [374400/525306]\n",
      "loss: 0.608525  [376000/525306]\n",
      "loss: 1.071668  [377600/525306]\n",
      "loss: 0.548883  [379200/525306]\n",
      "loss: 0.757795  [380800/525306]\n",
      "loss: 0.627127  [382400/525306]\n",
      "loss: 0.635076  [384000/525306]\n",
      "loss: 1.057324  [385600/525306]\n",
      "loss: 0.677307  [387200/525306]\n",
      "loss: 0.500484  [388800/525306]\n",
      "loss: 0.511366  [390400/525306]\n",
      "loss: 0.843909  [392000/525306]\n",
      "loss: 0.948372  [393600/525306]\n",
      "loss: 1.058537  [395200/525306]\n",
      "loss: 0.976707  [396800/525306]\n",
      "loss: 0.500380  [398400/525306]\n",
      "loss: 0.693671  [400000/525306]\n",
      "loss: 0.847363  [401600/525306]\n",
      "loss: 0.225298  [403200/525306]\n",
      "loss: 0.715526  [404800/525306]\n",
      "loss: 0.978170  [406400/525306]\n",
      "loss: 0.730052  [408000/525306]\n",
      "loss: 0.715800  [409600/525306]\n",
      "loss: 0.654133  [411200/525306]\n",
      "loss: 1.264206  [412800/525306]\n",
      "loss: 0.543575  [414400/525306]\n",
      "loss: 1.488212  [416000/525306]\n",
      "loss: 0.720654  [417600/525306]\n",
      "loss: 0.800803  [419200/525306]\n",
      "loss: 0.692427  [420800/525306]\n",
      "loss: 0.852931  [422400/525306]\n",
      "loss: 0.728949  [424000/525306]\n",
      "loss: 1.072910  [425600/525306]\n",
      "loss: 1.102902  [427200/525306]\n",
      "loss: 0.899632  [428800/525306]\n",
      "loss: 0.828171  [430400/525306]\n",
      "loss: 0.840492  [432000/525306]\n",
      "loss: 0.838881  [433600/525306]\n",
      "loss: 0.479625  [435200/525306]\n",
      "loss: 0.257821  [436800/525306]\n",
      "loss: 0.650022  [438400/525306]\n",
      "loss: 0.823099  [440000/525306]\n",
      "loss: 0.885366  [441600/525306]\n",
      "loss: 0.567296  [443200/525306]\n",
      "loss: 0.334140  [444800/525306]\n",
      "loss: 0.363942  [446400/525306]\n",
      "loss: 0.686583  [448000/525306]\n",
      "loss: 0.517030  [449600/525306]\n",
      "loss: 0.835367  [451200/525306]\n",
      "loss: 0.864456  [452800/525306]\n",
      "loss: 0.941657  [454400/525306]\n",
      "loss: 0.586418  [456000/525306]\n",
      "loss: 0.834538  [457600/525306]\n",
      "loss: 0.893144  [459200/525306]\n",
      "loss: 0.916602  [460800/525306]\n",
      "loss: 0.759329  [462400/525306]\n",
      "loss: 0.649012  [464000/525306]\n",
      "loss: 0.207000  [465600/525306]\n",
      "loss: 0.860366  [467200/525306]\n",
      "loss: 0.877674  [468800/525306]\n",
      "loss: 0.555078  [470400/525306]\n",
      "loss: 0.904286  [472000/525306]\n",
      "loss: 1.020127  [473600/525306]\n",
      "loss: 1.026369  [475200/525306]\n",
      "loss: 0.523854  [476800/525306]\n",
      "loss: 0.678790  [478400/525306]\n",
      "loss: 0.868744  [480000/525306]\n",
      "loss: 0.490883  [481600/525306]\n",
      "loss: 0.935034  [483200/525306]\n",
      "loss: 0.629530  [484800/525306]\n",
      "loss: 0.791095  [486400/525306]\n",
      "loss: 0.475614  [488000/525306]\n",
      "loss: 0.621890  [489600/525306]\n",
      "loss: 0.505692  [491200/525306]\n",
      "loss: 0.818965  [492800/525306]\n",
      "loss: 0.849344  [494400/525306]\n",
      "loss: 0.602662  [496000/525306]\n",
      "loss: 1.019041  [497600/525306]\n",
      "loss: 0.317644  [499200/525306]\n",
      "loss: 0.771658  [500800/525306]\n",
      "loss: 0.538140  [502400/525306]\n",
      "loss: 0.688845  [504000/525306]\n",
      "loss: 1.027128  [505600/525306]\n",
      "loss: 0.937144  [507200/525306]\n",
      "loss: 0.714521  [508800/525306]\n",
      "loss: 1.056611  [510400/525306]\n",
      "loss: 0.683559  [512000/525306]\n",
      "loss: 0.678839  [513600/525306]\n",
      "loss: 0.557637  [515200/525306]\n",
      "loss: 0.908235  [516800/525306]\n",
      "loss: 0.966993  [518400/525306]\n",
      "loss: 0.424210  [520000/525306]\n",
      "loss: 0.788626  [521600/525306]\n",
      "loss: 0.628370  [523200/525306]\n",
      "loss: 1.004260  [524800/525306]\n",
      "Train Accuracy: 71.5387%\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 0.970141, F1-score: 69.98%, Macro_F1-Score:  38.01%  \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.327847  [    0/525306]\n",
      "loss: 0.746597  [ 1600/525306]\n",
      "loss: 0.742964  [ 3200/525306]\n",
      "loss: 0.910260  [ 4800/525306]\n",
      "loss: 0.618206  [ 6400/525306]\n",
      "loss: 0.865537  [ 8000/525306]\n",
      "loss: 0.902323  [ 9600/525306]\n",
      "loss: 0.570485  [11200/525306]\n",
      "loss: 0.318464  [12800/525306]\n",
      "loss: 0.592419  [14400/525306]\n",
      "loss: 0.576911  [16000/525306]\n",
      "loss: 0.514717  [17600/525306]\n",
      "loss: 0.807925  [19200/525306]\n",
      "loss: 0.951560  [20800/525306]\n",
      "loss: 0.641709  [22400/525306]\n",
      "loss: 0.767963  [24000/525306]\n",
      "loss: 1.206560  [25600/525306]\n",
      "loss: 0.774987  [27200/525306]\n",
      "loss: 0.758013  [28800/525306]\n",
      "loss: 0.459688  [30400/525306]\n",
      "loss: 0.814754  [32000/525306]\n",
      "loss: 0.413559  [33600/525306]\n",
      "loss: 1.124596  [35200/525306]\n",
      "loss: 0.822373  [36800/525306]\n",
      "loss: 0.669310  [38400/525306]\n",
      "loss: 0.589398  [40000/525306]\n",
      "loss: 1.270508  [41600/525306]\n",
      "loss: 0.887166  [43200/525306]\n",
      "loss: 0.871675  [44800/525306]\n",
      "loss: 0.532455  [46400/525306]\n",
      "loss: 0.832256  [48000/525306]\n",
      "loss: 0.615345  [49600/525306]\n",
      "loss: 0.726384  [51200/525306]\n",
      "loss: 0.705975  [52800/525306]\n",
      "loss: 0.290159  [54400/525306]\n",
      "loss: 0.410056  [56000/525306]\n",
      "loss: 0.529541  [57600/525306]\n",
      "loss: 1.064460  [59200/525306]\n",
      "loss: 0.821252  [60800/525306]\n",
      "loss: 1.132050  [62400/525306]\n",
      "loss: 0.548770  [64000/525306]\n",
      "loss: 0.563829  [65600/525306]\n",
      "loss: 1.014649  [67200/525306]\n",
      "loss: 0.785092  [68800/525306]\n",
      "loss: 0.646510  [70400/525306]\n",
      "loss: 0.885280  [72000/525306]\n",
      "loss: 0.787771  [73600/525306]\n",
      "loss: 0.722801  [75200/525306]\n",
      "loss: 0.357831  [76800/525306]\n",
      "loss: 0.448085  [78400/525306]\n",
      "loss: 0.878068  [80000/525306]\n",
      "loss: 0.912317  [81600/525306]\n",
      "loss: 0.856704  [83200/525306]\n",
      "loss: 0.454746  [84800/525306]\n",
      "loss: 0.433547  [86400/525306]\n",
      "loss: 0.614436  [88000/525306]\n",
      "loss: 0.801514  [89600/525306]\n",
      "loss: 0.426243  [91200/525306]\n",
      "loss: 0.214957  [92800/525306]\n",
      "loss: 0.370800  [94400/525306]\n",
      "loss: 0.932449  [96000/525306]\n",
      "loss: 0.371295  [97600/525306]\n",
      "loss: 0.897026  [99200/525306]\n",
      "loss: 0.772815  [100800/525306]\n",
      "loss: 0.366016  [102400/525306]\n",
      "loss: 0.372292  [104000/525306]\n",
      "loss: 1.194742  [105600/525306]\n",
      "loss: 0.450270  [107200/525306]\n",
      "loss: 0.927048  [108800/525306]\n",
      "loss: 0.274785  [110400/525306]\n",
      "loss: 0.376981  [112000/525306]\n",
      "loss: 0.793149  [113600/525306]\n",
      "loss: 0.610487  [115200/525306]\n",
      "loss: 0.482115  [116800/525306]\n",
      "loss: 0.459097  [118400/525306]\n",
      "loss: 0.935249  [120000/525306]\n",
      "loss: 0.583097  [121600/525306]\n",
      "loss: 1.131433  [123200/525306]\n",
      "loss: 0.492652  [124800/525306]\n",
      "loss: 0.893101  [126400/525306]\n",
      "loss: 0.658114  [128000/525306]\n",
      "loss: 0.994970  [129600/525306]\n",
      "loss: 0.806229  [131200/525306]\n",
      "loss: 1.066706  [132800/525306]\n",
      "loss: 0.806303  [134400/525306]\n",
      "loss: 0.919981  [136000/525306]\n",
      "loss: 0.559145  [137600/525306]\n",
      "loss: 0.968801  [139200/525306]\n",
      "loss: 0.583766  [140800/525306]\n",
      "loss: 1.026299  [142400/525306]\n",
      "loss: 0.738942  [144000/525306]\n",
      "loss: 0.675772  [145600/525306]\n",
      "loss: 0.869373  [147200/525306]\n",
      "loss: 0.760540  [148800/525306]\n",
      "loss: 0.629435  [150400/525306]\n",
      "loss: 0.848814  [152000/525306]\n",
      "loss: 0.461249  [153600/525306]\n",
      "loss: 0.754221  [155200/525306]\n",
      "loss: 0.886823  [156800/525306]\n",
      "loss: 0.584000  [158400/525306]\n",
      "loss: 0.709389  [160000/525306]\n",
      "loss: 1.032047  [161600/525306]\n",
      "loss: 0.437050  [163200/525306]\n",
      "loss: 0.645433  [164800/525306]\n",
      "loss: 0.778112  [166400/525306]\n",
      "loss: 1.004790  [168000/525306]\n",
      "loss: 0.874001  [169600/525306]\n",
      "loss: 0.710903  [171200/525306]\n",
      "loss: 0.950355  [172800/525306]\n",
      "loss: 0.535447  [174400/525306]\n",
      "loss: 0.761631  [176000/525306]\n",
      "loss: 0.711464  [177600/525306]\n",
      "loss: 0.238665  [179200/525306]\n",
      "loss: 0.722903  [180800/525306]\n",
      "loss: 1.193194  [182400/525306]\n",
      "loss: 0.542124  [184000/525306]\n",
      "loss: 0.904878  [185600/525306]\n",
      "loss: 0.792453  [187200/525306]\n",
      "loss: 0.859627  [188800/525306]\n",
      "loss: 0.723935  [190400/525306]\n",
      "loss: 0.674448  [192000/525306]\n",
      "loss: 0.634087  [193600/525306]\n",
      "loss: 0.826426  [195200/525306]\n",
      "loss: 0.695092  [196800/525306]\n",
      "loss: 0.468096  [198400/525306]\n",
      "loss: 0.929247  [200000/525306]\n",
      "loss: 0.547447  [201600/525306]\n",
      "loss: 0.875030  [203200/525306]\n",
      "loss: 1.130673  [204800/525306]\n",
      "loss: 0.588301  [206400/525306]\n",
      "loss: 0.548819  [208000/525306]\n",
      "loss: 0.819864  [209600/525306]\n",
      "loss: 0.871892  [211200/525306]\n",
      "loss: 1.410919  [212800/525306]\n",
      "loss: 0.880248  [214400/525306]\n",
      "loss: 0.321230  [216000/525306]\n",
      "loss: 0.781160  [217600/525306]\n",
      "loss: 0.632945  [219200/525306]\n",
      "loss: 0.802353  [220800/525306]\n",
      "loss: 0.535763  [222400/525306]\n",
      "loss: 0.858222  [224000/525306]\n",
      "loss: 0.727378  [225600/525306]\n",
      "loss: 0.328627  [227200/525306]\n",
      "loss: 0.655329  [228800/525306]\n",
      "loss: 0.346405  [230400/525306]\n",
      "loss: 0.627074  [232000/525306]\n",
      "loss: 0.806406  [233600/525306]\n",
      "loss: 0.672446  [235200/525306]\n",
      "loss: 0.787582  [236800/525306]\n",
      "loss: 0.670236  [238400/525306]\n",
      "loss: 0.556860  [240000/525306]\n",
      "loss: 0.442424  [241600/525306]\n",
      "loss: 0.900857  [243200/525306]\n",
      "loss: 0.967824  [244800/525306]\n",
      "loss: 0.682569  [246400/525306]\n",
      "loss: 1.283375  [248000/525306]\n",
      "loss: 1.579068  [249600/525306]\n",
      "loss: 0.847503  [251200/525306]\n",
      "loss: 0.971161  [252800/525306]\n",
      "loss: 0.513028  [254400/525306]\n",
      "loss: 0.506349  [256000/525306]\n",
      "loss: 0.792549  [257600/525306]\n",
      "loss: 0.723431  [259200/525306]\n",
      "loss: 0.987101  [260800/525306]\n",
      "loss: 0.938879  [262400/525306]\n",
      "loss: 0.412260  [264000/525306]\n",
      "loss: 0.516737  [265600/525306]\n",
      "loss: 0.893127  [267200/525306]\n",
      "loss: 1.048897  [268800/525306]\n",
      "loss: 0.845309  [270400/525306]\n",
      "loss: 1.134811  [272000/525306]\n",
      "loss: 1.053282  [273600/525306]\n",
      "loss: 0.645677  [275200/525306]\n",
      "loss: 0.705059  [276800/525306]\n",
      "loss: 0.889836  [278400/525306]\n",
      "loss: 0.335628  [280000/525306]\n",
      "loss: 0.811438  [281600/525306]\n",
      "loss: 0.698117  [283200/525306]\n",
      "loss: 0.563959  [284800/525306]\n",
      "loss: 0.654516  [286400/525306]\n",
      "loss: 0.588491  [288000/525306]\n",
      "loss: 0.585385  [289600/525306]\n",
      "loss: 0.857123  [291200/525306]\n",
      "loss: 0.675092  [292800/525306]\n",
      "loss: 0.735836  [294400/525306]\n",
      "loss: 0.513419  [296000/525306]\n",
      "loss: 0.696048  [297600/525306]\n",
      "loss: 1.020840  [299200/525306]\n",
      "loss: 0.656392  [300800/525306]\n",
      "loss: 0.691412  [302400/525306]\n",
      "loss: 1.082183  [304000/525306]\n",
      "loss: 0.942136  [305600/525306]\n",
      "loss: 0.869703  [307200/525306]\n",
      "loss: 0.635292  [308800/525306]\n",
      "loss: 0.715348  [310400/525306]\n",
      "loss: 1.053302  [312000/525306]\n",
      "loss: 0.837745  [313600/525306]\n",
      "loss: 0.411405  [315200/525306]\n",
      "loss: 0.337531  [316800/525306]\n",
      "loss: 0.516241  [318400/525306]\n",
      "loss: 0.572586  [320000/525306]\n",
      "loss: 0.558852  [321600/525306]\n",
      "loss: 0.717260  [323200/525306]\n",
      "loss: 0.767914  [324800/525306]\n",
      "loss: 0.426001  [326400/525306]\n",
      "loss: 0.737259  [328000/525306]\n",
      "loss: 0.689868  [329600/525306]\n",
      "loss: 0.524462  [331200/525306]\n",
      "loss: 0.605278  [332800/525306]\n",
      "loss: 1.130237  [334400/525306]\n",
      "loss: 0.644826  [336000/525306]\n",
      "loss: 0.828526  [337600/525306]\n",
      "loss: 0.519152  [339200/525306]\n",
      "loss: 0.833063  [340800/525306]\n",
      "loss: 0.567487  [342400/525306]\n",
      "loss: 0.335949  [344000/525306]\n",
      "loss: 0.807793  [345600/525306]\n",
      "loss: 0.921267  [347200/525306]\n",
      "loss: 1.300283  [348800/525306]\n",
      "loss: 0.871127  [350400/525306]\n",
      "loss: 1.161756  [352000/525306]\n",
      "loss: 0.914995  [353600/525306]\n",
      "loss: 0.611732  [355200/525306]\n",
      "loss: 0.623338  [356800/525306]\n",
      "loss: 1.466426  [358400/525306]\n",
      "loss: 0.777970  [360000/525306]\n",
      "loss: 0.473445  [361600/525306]\n",
      "loss: 0.707068  [363200/525306]\n",
      "loss: 0.621447  [364800/525306]\n",
      "loss: 0.572889  [366400/525306]\n",
      "loss: 0.621504  [368000/525306]\n",
      "loss: 0.655405  [369600/525306]\n",
      "loss: 0.846233  [371200/525306]\n",
      "loss: 0.855488  [372800/525306]\n",
      "loss: 0.672976  [374400/525306]\n",
      "loss: 0.642847  [376000/525306]\n",
      "loss: 1.004318  [377600/525306]\n",
      "loss: 0.986747  [379200/525306]\n",
      "loss: 0.339662  [380800/525306]\n",
      "loss: 0.989465  [382400/525306]\n",
      "loss: 0.751642  [384000/525306]\n",
      "loss: 0.713292  [385600/525306]\n",
      "loss: 0.942876  [387200/525306]\n",
      "loss: 0.444299  [388800/525306]\n",
      "loss: 0.511136  [390400/525306]\n",
      "loss: 0.627616  [392000/525306]\n",
      "loss: 0.944941  [393600/525306]\n",
      "loss: 0.547364  [395200/525306]\n",
      "loss: 0.736821  [396800/525306]\n",
      "loss: 0.695238  [398400/525306]\n",
      "loss: 0.586376  [400000/525306]\n",
      "loss: 0.717286  [401600/525306]\n",
      "loss: 0.366545  [403200/525306]\n",
      "loss: 0.543556  [404800/525306]\n",
      "loss: 0.927723  [406400/525306]\n",
      "loss: 0.982626  [408000/525306]\n",
      "loss: 1.081085  [409600/525306]\n",
      "loss: 0.501251  [411200/525306]\n",
      "loss: 0.770191  [412800/525306]\n",
      "loss: 0.896325  [414400/525306]\n",
      "loss: 1.278475  [416000/525306]\n",
      "loss: 0.657229  [417600/525306]\n",
      "loss: 0.591058  [419200/525306]\n",
      "loss: 1.022786  [420800/525306]\n",
      "loss: 0.821636  [422400/525306]\n",
      "loss: 0.976492  [424000/525306]\n",
      "loss: 0.458517  [425600/525306]\n",
      "loss: 0.997973  [427200/525306]\n",
      "loss: 0.376322  [428800/525306]\n",
      "loss: 1.266513  [430400/525306]\n",
      "loss: 0.975737  [432000/525306]\n",
      "loss: 0.663956  [433600/525306]\n",
      "loss: 0.988246  [435200/525306]\n",
      "loss: 0.896150  [436800/525306]\n",
      "loss: 1.007144  [438400/525306]\n",
      "loss: 1.164672  [440000/525306]\n",
      "loss: 0.401736  [441600/525306]\n",
      "loss: 0.636367  [443200/525306]\n",
      "loss: 0.822886  [444800/525306]\n",
      "loss: 0.953655  [446400/525306]\n",
      "loss: 0.582075  [448000/525306]\n",
      "loss: 0.655170  [449600/525306]\n",
      "loss: 0.922802  [451200/525306]\n",
      "loss: 0.347134  [452800/525306]\n",
      "loss: 0.708994  [454400/525306]\n",
      "loss: 0.433750  [456000/525306]\n",
      "loss: 0.704800  [457600/525306]\n",
      "loss: 0.957241  [459200/525306]\n",
      "loss: 1.276537  [460800/525306]\n",
      "loss: 0.448998  [462400/525306]\n",
      "loss: 0.636779  [464000/525306]\n",
      "loss: 0.794016  [465600/525306]\n",
      "loss: 0.989062  [467200/525306]\n",
      "loss: 0.265339  [468800/525306]\n",
      "loss: 0.829388  [470400/525306]\n",
      "loss: 0.820306  [472000/525306]\n",
      "loss: 0.802077  [473600/525306]\n",
      "loss: 0.569009  [475200/525306]\n",
      "loss: 0.953559  [476800/525306]\n",
      "loss: 0.359713  [478400/525306]\n",
      "loss: 0.986422  [480000/525306]\n",
      "loss: 0.551249  [481600/525306]\n",
      "loss: 0.721439  [483200/525306]\n",
      "loss: 0.821852  [484800/525306]\n",
      "loss: 0.661158  [486400/525306]\n",
      "loss: 0.798508  [488000/525306]\n",
      "loss: 0.866477  [489600/525306]\n",
      "loss: 0.547761  [491200/525306]\n",
      "loss: 1.266888  [492800/525306]\n",
      "loss: 1.273248  [494400/525306]\n",
      "loss: 0.452489  [496000/525306]\n",
      "loss: 0.931300  [497600/525306]\n",
      "loss: 0.369391  [499200/525306]\n",
      "loss: 0.733696  [500800/525306]\n",
      "loss: 0.397283  [502400/525306]\n",
      "loss: 0.584903  [504000/525306]\n",
      "loss: 1.025054  [505600/525306]\n",
      "loss: 0.835341  [507200/525306]\n",
      "loss: 0.431234  [508800/525306]\n",
      "loss: 0.527015  [510400/525306]\n",
      "loss: 0.733498  [512000/525306]\n",
      "loss: 0.291132  [513600/525306]\n",
      "loss: 1.018111  [515200/525306]\n",
      "loss: 0.534039  [516800/525306]\n",
      "loss: 0.517607  [518400/525306]\n",
      "loss: 0.546211  [520000/525306]\n",
      "loss: 1.257864  [521600/525306]\n",
      "loss: 0.774941  [523200/525306]\n",
      "loss: 0.615022  [524800/525306]\n",
      "Train Accuracy: 71.9760%\n",
      "Test Error: \n",
      " Accuracy: 65.4%, Avg loss: 0.907182, F1-score: 71.04%, Macro_F1-Score:  40.68%  \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.449938  [    0/525306]\n",
      "loss: 0.699977  [ 1600/525306]\n",
      "loss: 0.731829  [ 3200/525306]\n",
      "loss: 0.745789  [ 4800/525306]\n",
      "loss: 0.614935  [ 6400/525306]\n",
      "loss: 0.447688  [ 8000/525306]\n",
      "loss: 0.647840  [ 9600/525306]\n",
      "loss: 0.465103  [11200/525306]\n",
      "loss: 0.766103  [12800/525306]\n",
      "loss: 0.726762  [14400/525306]\n",
      "loss: 0.596652  [16000/525306]\n",
      "loss: 0.519066  [17600/525306]\n",
      "loss: 0.986637  [19200/525306]\n",
      "loss: 0.785172  [20800/525306]\n",
      "loss: 0.742919  [22400/525306]\n",
      "loss: 0.951211  [24000/525306]\n",
      "loss: 0.639545  [25600/525306]\n",
      "loss: 0.938670  [27200/525306]\n",
      "loss: 1.228141  [28800/525306]\n",
      "loss: 0.849240  [30400/525306]\n",
      "loss: 0.404385  [32000/525306]\n",
      "loss: 0.563660  [33600/525306]\n",
      "loss: 0.977736  [35200/525306]\n",
      "loss: 0.818698  [36800/525306]\n",
      "loss: 0.744333  [38400/525306]\n",
      "loss: 0.604428  [40000/525306]\n",
      "loss: 0.707467  [41600/525306]\n",
      "loss: 0.809080  [43200/525306]\n",
      "loss: 0.478265  [44800/525306]\n",
      "loss: 1.036190  [46400/525306]\n",
      "loss: 1.044490  [48000/525306]\n",
      "loss: 0.673000  [49600/525306]\n",
      "loss: 0.772666  [51200/525306]\n",
      "loss: 0.685192  [52800/525306]\n",
      "loss: 0.584177  [54400/525306]\n",
      "loss: 0.630998  [56000/525306]\n",
      "loss: 0.710289  [57600/525306]\n",
      "loss: 0.816771  [59200/525306]\n",
      "loss: 0.575368  [60800/525306]\n",
      "loss: 1.063238  [62400/525306]\n",
      "loss: 0.663468  [64000/525306]\n",
      "loss: 1.069405  [65600/525306]\n",
      "loss: 0.553308  [67200/525306]\n",
      "loss: 0.426448  [68800/525306]\n",
      "loss: 0.731357  [70400/525306]\n",
      "loss: 0.655915  [72000/525306]\n",
      "loss: 0.412952  [73600/525306]\n",
      "loss: 0.753710  [75200/525306]\n",
      "loss: 0.806330  [76800/525306]\n",
      "loss: 0.715504  [78400/525306]\n",
      "loss: 0.611403  [80000/525306]\n",
      "loss: 0.556849  [81600/525306]\n",
      "loss: 0.694555  [83200/525306]\n",
      "loss: 0.853564  [84800/525306]\n",
      "loss: 0.956588  [86400/525306]\n",
      "loss: 0.747633  [88000/525306]\n",
      "loss: 0.656660  [89600/525306]\n",
      "loss: 0.741799  [91200/525306]\n",
      "loss: 0.941293  [92800/525306]\n",
      "loss: 0.540285  [94400/525306]\n",
      "loss: 0.546776  [96000/525306]\n",
      "loss: 0.990822  [97600/525306]\n",
      "loss: 0.500995  [99200/525306]\n",
      "loss: 0.842180  [100800/525306]\n",
      "loss: 0.527911  [102400/525306]\n",
      "loss: 0.727719  [104000/525306]\n",
      "loss: 0.803521  [105600/525306]\n",
      "loss: 0.934631  [107200/525306]\n",
      "loss: 0.878026  [108800/525306]\n",
      "loss: 0.692638  [110400/525306]\n",
      "loss: 0.696194  [112000/525306]\n",
      "loss: 0.800805  [113600/525306]\n",
      "loss: 1.164216  [115200/525306]\n",
      "loss: 0.844796  [116800/525306]\n",
      "loss: 0.550598  [118400/525306]\n",
      "loss: 0.709375  [120000/525306]\n",
      "loss: 0.655851  [121600/525306]\n",
      "loss: 0.595346  [123200/525306]\n",
      "loss: 0.593147  [124800/525306]\n",
      "loss: 0.651704  [126400/525306]\n",
      "loss: 0.270087  [128000/525306]\n",
      "loss: 0.523258  [129600/525306]\n",
      "loss: 0.574569  [131200/525306]\n",
      "loss: 0.879840  [132800/525306]\n",
      "loss: 0.485263  [134400/525306]\n",
      "loss: 0.726224  [136000/525306]\n",
      "loss: 0.522414  [137600/525306]\n",
      "loss: 1.216909  [139200/525306]\n",
      "loss: 0.737947  [140800/525306]\n",
      "loss: 0.869968  [142400/525306]\n",
      "loss: 0.497806  [144000/525306]\n",
      "loss: 0.732620  [145600/525306]\n",
      "loss: 0.596267  [147200/525306]\n",
      "loss: 1.106017  [148800/525306]\n",
      "loss: 0.370037  [150400/525306]\n",
      "loss: 0.500075  [152000/525306]\n",
      "loss: 0.366663  [153600/525306]\n",
      "loss: 0.801733  [155200/525306]\n",
      "loss: 0.515390  [156800/525306]\n",
      "loss: 0.487424  [158400/525306]\n",
      "loss: 0.846740  [160000/525306]\n",
      "loss: 1.074539  [161600/525306]\n",
      "loss: 0.963967  [163200/525306]\n",
      "loss: 0.884990  [164800/525306]\n",
      "loss: 0.405681  [166400/525306]\n",
      "loss: 0.825173  [168000/525306]\n",
      "loss: 0.651036  [169600/525306]\n",
      "loss: 0.650260  [171200/525306]\n",
      "loss: 0.877967  [172800/525306]\n",
      "loss: 0.755214  [174400/525306]\n",
      "loss: 0.679986  [176000/525306]\n",
      "loss: 0.594904  [177600/525306]\n",
      "loss: 1.069056  [179200/525306]\n",
      "loss: 0.580944  [180800/525306]\n",
      "loss: 1.060394  [182400/525306]\n",
      "loss: 0.384638  [184000/525306]\n",
      "loss: 0.437090  [185600/525306]\n",
      "loss: 0.759272  [187200/525306]\n",
      "loss: 0.634560  [188800/525306]\n",
      "loss: 1.112052  [190400/525306]\n",
      "loss: 0.561550  [192000/525306]\n",
      "loss: 0.660222  [193600/525306]\n",
      "loss: 0.760829  [195200/525306]\n",
      "loss: 0.691848  [196800/525306]\n",
      "loss: 0.467246  [198400/525306]\n",
      "loss: 0.821359  [200000/525306]\n",
      "loss: 0.743114  [201600/525306]\n",
      "loss: 0.691494  [203200/525306]\n",
      "loss: 0.775987  [204800/525306]\n",
      "loss: 1.097602  [206400/525306]\n",
      "loss: 0.816862  [208000/525306]\n",
      "loss: 0.662514  [209600/525306]\n",
      "loss: 0.745733  [211200/525306]\n",
      "loss: 1.160751  [212800/525306]\n",
      "loss: 0.569722  [214400/525306]\n",
      "loss: 0.621962  [216000/525306]\n",
      "loss: 0.614222  [217600/525306]\n",
      "loss: 0.863283  [219200/525306]\n",
      "loss: 1.099652  [220800/525306]\n",
      "loss: 0.593957  [222400/525306]\n",
      "loss: 0.409654  [224000/525306]\n",
      "loss: 0.724813  [225600/525306]\n",
      "loss: 0.824817  [227200/525306]\n",
      "loss: 0.560370  [228800/525306]\n",
      "loss: 0.672493  [230400/525306]\n",
      "loss: 0.947855  [232000/525306]\n",
      "loss: 0.474533  [233600/525306]\n",
      "loss: 0.566800  [235200/525306]\n",
      "loss: 0.676531  [236800/525306]\n",
      "loss: 0.679372  [238400/525306]\n",
      "loss: 0.770865  [240000/525306]\n",
      "loss: 0.511793  [241600/525306]\n",
      "loss: 0.998863  [243200/525306]\n",
      "loss: 0.870300  [244800/525306]\n",
      "loss: 0.586541  [246400/525306]\n",
      "loss: 0.978316  [248000/525306]\n",
      "loss: 1.057803  [249600/525306]\n",
      "loss: 0.747041  [251200/525306]\n",
      "loss: 1.158116  [252800/525306]\n",
      "loss: 0.981694  [254400/525306]\n",
      "loss: 0.689968  [256000/525306]\n",
      "loss: 1.018629  [257600/525306]\n",
      "loss: 0.910469  [259200/525306]\n",
      "loss: 0.736315  [260800/525306]\n",
      "loss: 0.923121  [262400/525306]\n",
      "loss: 0.650150  [264000/525306]\n",
      "loss: 0.725587  [265600/525306]\n",
      "loss: 0.820327  [267200/525306]\n",
      "loss: 1.129565  [268800/525306]\n",
      "loss: 0.522168  [270400/525306]\n",
      "loss: 0.772403  [272000/525306]\n",
      "loss: 0.670169  [273600/525306]\n",
      "loss: 0.933694  [275200/525306]\n",
      "loss: 0.841876  [276800/525306]\n",
      "loss: 1.173674  [278400/525306]\n",
      "loss: 0.874373  [280000/525306]\n",
      "loss: 1.071170  [281600/525306]\n",
      "loss: 0.429106  [283200/525306]\n",
      "loss: 0.842332  [284800/525306]\n",
      "loss: 0.737124  [286400/525306]\n",
      "loss: 0.865320  [288000/525306]\n",
      "loss: 0.605912  [289600/525306]\n",
      "loss: 0.998554  [291200/525306]\n",
      "loss: 0.476280  [292800/525306]\n",
      "loss: 1.334264  [294400/525306]\n",
      "loss: 0.587990  [296000/525306]\n",
      "loss: 0.864016  [297600/525306]\n",
      "loss: 0.518047  [299200/525306]\n",
      "loss: 0.687000  [300800/525306]\n",
      "loss: 0.318712  [302400/525306]\n",
      "loss: 0.629904  [304000/525306]\n",
      "loss: 0.956700  [305600/525306]\n",
      "loss: 0.619480  [307200/525306]\n",
      "loss: 0.471871  [308800/525306]\n",
      "loss: 0.639943  [310400/525306]\n",
      "loss: 0.884696  [312000/525306]\n",
      "loss: 0.700455  [313600/525306]\n",
      "loss: 0.694425  [315200/525306]\n",
      "loss: 0.658824  [316800/525306]\n",
      "loss: 0.770911  [318400/525306]\n",
      "loss: 0.871575  [320000/525306]\n",
      "loss: 0.711844  [321600/525306]\n",
      "loss: 0.932801  [323200/525306]\n",
      "loss: 0.729757  [324800/525306]\n",
      "loss: 0.656953  [326400/525306]\n",
      "loss: 0.853740  [328000/525306]\n",
      "loss: 0.857656  [329600/525306]\n",
      "loss: 0.467669  [331200/525306]\n",
      "loss: 0.317463  [332800/525306]\n",
      "loss: 1.193053  [334400/525306]\n",
      "loss: 0.513929  [336000/525306]\n",
      "loss: 0.581498  [337600/525306]\n",
      "loss: 0.651265  [339200/525306]\n",
      "loss: 0.590162  [340800/525306]\n",
      "loss: 0.487468  [342400/525306]\n",
      "loss: 0.697109  [344000/525306]\n",
      "loss: 0.625986  [345600/525306]\n",
      "loss: 0.782591  [347200/525306]\n",
      "loss: 0.911511  [348800/525306]\n",
      "loss: 1.021849  [350400/525306]\n",
      "loss: 0.332312  [352000/525306]\n",
      "loss: 0.460899  [353600/525306]\n",
      "loss: 1.232049  [355200/525306]\n",
      "loss: 0.470229  [356800/525306]\n",
      "loss: 0.732843  [358400/525306]\n",
      "loss: 1.289472  [360000/525306]\n",
      "loss: 0.649308  [361600/525306]\n",
      "loss: 1.042217  [363200/525306]\n",
      "loss: 0.779833  [364800/525306]\n",
      "loss: 0.461774  [366400/525306]\n",
      "loss: 0.647562  [368000/525306]\n",
      "loss: 0.241027  [369600/525306]\n",
      "loss: 0.678835  [371200/525306]\n",
      "loss: 0.457046  [372800/525306]\n",
      "loss: 0.692693  [374400/525306]\n",
      "loss: 0.365160  [376000/525306]\n",
      "loss: 0.824916  [377600/525306]\n",
      "loss: 1.095138  [379200/525306]\n",
      "loss: 0.738592  [380800/525306]\n",
      "loss: 0.760042  [382400/525306]\n",
      "loss: 1.301386  [384000/525306]\n",
      "loss: 0.747269  [385600/525306]\n",
      "loss: 0.911530  [387200/525306]\n",
      "loss: 0.979126  [388800/525306]\n",
      "loss: 0.606427  [390400/525306]\n",
      "loss: 0.616746  [392000/525306]\n",
      "loss: 0.646293  [393600/525306]\n",
      "loss: 1.103014  [395200/525306]\n",
      "loss: 0.726169  [396800/525306]\n",
      "loss: 0.632295  [398400/525306]\n",
      "loss: 0.586232  [400000/525306]\n",
      "loss: 0.592763  [401600/525306]\n",
      "loss: 0.833817  [403200/525306]\n",
      "loss: 1.080246  [404800/525306]\n",
      "loss: 0.488173  [406400/525306]\n",
      "loss: 0.774586  [408000/525306]\n",
      "loss: 0.673192  [409600/525306]\n",
      "loss: 0.721503  [411200/525306]\n",
      "loss: 0.334176  [412800/525306]\n",
      "loss: 0.439704  [414400/525306]\n",
      "loss: 0.641219  [416000/525306]\n",
      "loss: 0.668116  [417600/525306]\n",
      "loss: 1.377950  [419200/525306]\n",
      "loss: 0.377671  [420800/525306]\n",
      "loss: 0.660790  [422400/525306]\n",
      "loss: 0.438690  [424000/525306]\n",
      "loss: 0.810962  [425600/525306]\n",
      "loss: 0.914267  [427200/525306]\n",
      "loss: 0.641772  [428800/525306]\n",
      "loss: 0.437080  [430400/525306]\n",
      "loss: 0.945767  [432000/525306]\n",
      "loss: 1.083532  [433600/525306]\n",
      "loss: 1.382204  [435200/525306]\n",
      "loss: 0.861950  [436800/525306]\n",
      "loss: 0.331923  [438400/525306]\n",
      "loss: 0.720614  [440000/525306]\n",
      "loss: 0.579655  [441600/525306]\n",
      "loss: 0.267883  [443200/525306]\n",
      "loss: 0.533520  [444800/525306]\n",
      "loss: 0.431307  [446400/525306]\n",
      "loss: 0.911373  [448000/525306]\n",
      "loss: 0.852640  [449600/525306]\n",
      "loss: 0.692812  [451200/525306]\n",
      "loss: 0.866525  [452800/525306]\n",
      "loss: 0.806729  [454400/525306]\n",
      "loss: 0.649903  [456000/525306]\n",
      "loss: 0.834471  [457600/525306]\n",
      "loss: 0.896074  [459200/525306]\n",
      "loss: 0.875085  [460800/525306]\n",
      "loss: 0.616094  [462400/525306]\n",
      "loss: 0.392536  [464000/525306]\n",
      "loss: 1.141263  [465600/525306]\n",
      "loss: 0.616508  [467200/525306]\n",
      "loss: 0.444137  [468800/525306]\n",
      "loss: 0.394178  [470400/525306]\n",
      "loss: 0.472167  [472000/525306]\n",
      "loss: 1.059198  [473600/525306]\n",
      "loss: 1.107844  [475200/525306]\n",
      "loss: 0.708491  [476800/525306]\n",
      "loss: 0.704195  [478400/525306]\n",
      "loss: 0.289281  [480000/525306]\n",
      "loss: 0.533177  [481600/525306]\n",
      "loss: 1.280036  [483200/525306]\n",
      "loss: 0.925628  [484800/525306]\n",
      "loss: 0.608364  [486400/525306]\n",
      "loss: 1.091776  [488000/525306]\n",
      "loss: 0.909798  [489600/525306]\n",
      "loss: 0.781468  [491200/525306]\n",
      "loss: 0.726041  [492800/525306]\n",
      "loss: 0.452334  [494400/525306]\n",
      "loss: 0.522760  [496000/525306]\n",
      "loss: 0.859622  [497600/525306]\n",
      "loss: 1.054423  [499200/525306]\n",
      "loss: 0.907108  [500800/525306]\n",
      "loss: 0.701972  [502400/525306]\n",
      "loss: 0.908069  [504000/525306]\n",
      "loss: 0.901483  [505600/525306]\n",
      "loss: 0.775921  [507200/525306]\n",
      "loss: 1.318386  [508800/525306]\n",
      "loss: 0.649045  [510400/525306]\n",
      "loss: 0.791213  [512000/525306]\n",
      "loss: 1.125585  [513600/525306]\n",
      "loss: 0.479258  [515200/525306]\n",
      "loss: 0.560208  [516800/525306]\n",
      "loss: 0.695477  [518400/525306]\n",
      "loss: 0.801926  [520000/525306]\n",
      "loss: 0.450300  [521600/525306]\n",
      "loss: 0.542024  [523200/525306]\n",
      "loss: 1.064999  [524800/525306]\n",
      "Train Accuracy: 72.2592%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.896939, F1-score: 71.39%, Macro_F1-Score:  41.34%  \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.618196  [    0/525306]\n",
      "loss: 0.485888  [ 1600/525306]\n",
      "loss: 0.872019  [ 3200/525306]\n",
      "loss: 0.476954  [ 4800/525306]\n",
      "loss: 0.247856  [ 6400/525306]\n",
      "loss: 0.754772  [ 8000/525306]\n",
      "loss: 0.430344  [ 9600/525306]\n",
      "loss: 0.883889  [11200/525306]\n",
      "loss: 0.744611  [12800/525306]\n",
      "loss: 0.763483  [14400/525306]\n",
      "loss: 0.395886  [16000/525306]\n",
      "loss: 0.575691  [17600/525306]\n",
      "loss: 0.796773  [19200/525306]\n",
      "loss: 0.526260  [20800/525306]\n",
      "loss: 0.999225  [22400/525306]\n",
      "loss: 0.805320  [24000/525306]\n",
      "loss: 1.098722  [25600/525306]\n",
      "loss: 0.688244  [27200/525306]\n",
      "loss: 0.420255  [28800/525306]\n",
      "loss: 0.543153  [30400/525306]\n",
      "loss: 0.571249  [32000/525306]\n",
      "loss: 0.665444  [33600/525306]\n",
      "loss: 0.981755  [35200/525306]\n",
      "loss: 0.571246  [36800/525306]\n",
      "loss: 0.611625  [38400/525306]\n",
      "loss: 0.745550  [40000/525306]\n",
      "loss: 0.852087  [41600/525306]\n",
      "loss: 0.819231  [43200/525306]\n",
      "loss: 0.485540  [44800/525306]\n",
      "loss: 1.034570  [46400/525306]\n",
      "loss: 1.436866  [48000/525306]\n",
      "loss: 1.031083  [49600/525306]\n",
      "loss: 0.561155  [51200/525306]\n",
      "loss: 0.891526  [52800/525306]\n",
      "loss: 0.682012  [54400/525306]\n",
      "loss: 0.532823  [56000/525306]\n",
      "loss: 0.681680  [57600/525306]\n",
      "loss: 0.741451  [59200/525306]\n",
      "loss: 1.236641  [60800/525306]\n",
      "loss: 0.582860  [62400/525306]\n",
      "loss: 0.807318  [64000/525306]\n",
      "loss: 0.732861  [65600/525306]\n",
      "loss: 0.805517  [67200/525306]\n",
      "loss: 0.692583  [68800/525306]\n",
      "loss: 0.660533  [70400/525306]\n",
      "loss: 0.453741  [72000/525306]\n",
      "loss: 0.840520  [73600/525306]\n",
      "loss: 0.772293  [75200/525306]\n",
      "loss: 0.920199  [76800/525306]\n",
      "loss: 0.867020  [78400/525306]\n",
      "loss: 0.659972  [80000/525306]\n",
      "loss: 0.876464  [81600/525306]\n",
      "loss: 0.745021  [83200/525306]\n",
      "loss: 0.613047  [84800/525306]\n",
      "loss: 0.568435  [86400/525306]\n",
      "loss: 0.531801  [88000/525306]\n",
      "loss: 0.668691  [89600/525306]\n",
      "loss: 0.481324  [91200/525306]\n",
      "loss: 0.838005  [92800/525306]\n",
      "loss: 0.587230  [94400/525306]\n",
      "loss: 0.319515  [96000/525306]\n",
      "loss: 1.301427  [97600/525306]\n",
      "loss: 0.680335  [99200/525306]\n",
      "loss: 0.541036  [100800/525306]\n",
      "loss: 0.605295  [102400/525306]\n",
      "loss: 0.706184  [104000/525306]\n",
      "loss: 0.858924  [105600/525306]\n",
      "loss: 0.420883  [107200/525306]\n",
      "loss: 0.455369  [108800/525306]\n",
      "loss: 0.622235  [110400/525306]\n",
      "loss: 0.549849  [112000/525306]\n",
      "loss: 0.716488  [113600/525306]\n",
      "loss: 0.684269  [115200/525306]\n",
      "loss: 0.753138  [116800/525306]\n",
      "loss: 0.457162  [118400/525306]\n",
      "loss: 0.298519  [120000/525306]\n",
      "loss: 0.479699  [121600/525306]\n",
      "loss: 0.425300  [123200/525306]\n",
      "loss: 0.589572  [124800/525306]\n",
      "loss: 0.907719  [126400/525306]\n",
      "loss: 0.894333  [128000/525306]\n",
      "loss: 1.162733  [129600/525306]\n",
      "loss: 0.757108  [131200/525306]\n",
      "loss: 0.668340  [132800/525306]\n",
      "loss: 0.507660  [134400/525306]\n",
      "loss: 0.836154  [136000/525306]\n",
      "loss: 0.578364  [137600/525306]\n",
      "loss: 0.264255  [139200/525306]\n",
      "loss: 0.641292  [140800/525306]\n",
      "loss: 1.238219  [142400/525306]\n",
      "loss: 0.575063  [144000/525306]\n",
      "loss: 0.200430  [145600/525306]\n",
      "loss: 0.700419  [147200/525306]\n",
      "loss: 0.995959  [148800/525306]\n",
      "loss: 0.299292  [150400/525306]\n",
      "loss: 0.411640  [152000/525306]\n",
      "loss: 0.718667  [153600/525306]\n",
      "loss: 0.754490  [155200/525306]\n",
      "loss: 1.103046  [156800/525306]\n",
      "loss: 0.785933  [158400/525306]\n",
      "loss: 0.382141  [160000/525306]\n",
      "loss: 0.503337  [161600/525306]\n",
      "loss: 0.726046  [163200/525306]\n",
      "loss: 1.196599  [164800/525306]\n",
      "loss: 0.750770  [166400/525306]\n",
      "loss: 0.578340  [168000/525306]\n",
      "loss: 0.277589  [169600/525306]\n",
      "loss: 0.528988  [171200/525306]\n",
      "loss: 0.921838  [172800/525306]\n",
      "loss: 0.854813  [174400/525306]\n",
      "loss: 1.209651  [176000/525306]\n",
      "loss: 0.848963  [177600/525306]\n",
      "loss: 0.347944  [179200/525306]\n",
      "loss: 0.345340  [180800/525306]\n",
      "loss: 0.603478  [182400/525306]\n",
      "loss: 0.683094  [184000/525306]\n",
      "loss: 0.908952  [185600/525306]\n",
      "loss: 0.906824  [187200/525306]\n",
      "loss: 0.813011  [188800/525306]\n",
      "loss: 0.872363  [190400/525306]\n",
      "loss: 0.375482  [192000/525306]\n",
      "loss: 1.038020  [193600/525306]\n",
      "loss: 0.618861  [195200/525306]\n",
      "loss: 1.098607  [196800/525306]\n",
      "loss: 0.812234  [198400/525306]\n",
      "loss: 0.788682  [200000/525306]\n",
      "loss: 0.911584  [201600/525306]\n",
      "loss: 0.620104  [203200/525306]\n",
      "loss: 0.928270  [204800/525306]\n",
      "loss: 0.576134  [206400/525306]\n",
      "loss: 1.242180  [208000/525306]\n",
      "loss: 0.405479  [209600/525306]\n",
      "loss: 0.941397  [211200/525306]\n",
      "loss: 0.929109  [212800/525306]\n",
      "loss: 0.671032  [214400/525306]\n",
      "loss: 0.371020  [216000/525306]\n",
      "loss: 0.912474  [217600/525306]\n",
      "loss: 0.450482  [219200/525306]\n",
      "loss: 0.525583  [220800/525306]\n",
      "loss: 1.195540  [222400/525306]\n",
      "loss: 0.973596  [224000/525306]\n",
      "loss: 1.125926  [225600/525306]\n",
      "loss: 1.084733  [227200/525306]\n",
      "loss: 1.133816  [228800/525306]\n",
      "loss: 0.418263  [230400/525306]\n",
      "loss: 0.668621  [232000/525306]\n",
      "loss: 0.831323  [233600/525306]\n",
      "loss: 0.779296  [235200/525306]\n",
      "loss: 1.341086  [236800/525306]\n",
      "loss: 1.328822  [238400/525306]\n",
      "loss: 0.665393  [240000/525306]\n",
      "loss: 0.991480  [241600/525306]\n",
      "loss: 0.556186  [243200/525306]\n",
      "loss: 0.692004  [244800/525306]\n",
      "loss: 1.051782  [246400/525306]\n",
      "loss: 0.939236  [248000/525306]\n",
      "loss: 1.001079  [249600/525306]\n",
      "loss: 0.705935  [251200/525306]\n",
      "loss: 0.652707  [252800/525306]\n",
      "loss: 0.444124  [254400/525306]\n",
      "loss: 0.607835  [256000/525306]\n",
      "loss: 0.862795  [257600/525306]\n",
      "loss: 0.532017  [259200/525306]\n",
      "loss: 0.531577  [260800/525306]\n",
      "loss: 0.570355  [262400/525306]\n",
      "loss: 1.165265  [264000/525306]\n",
      "loss: 0.190484  [265600/525306]\n",
      "loss: 0.565313  [267200/525306]\n",
      "loss: 0.940820  [268800/525306]\n",
      "loss: 1.199836  [270400/525306]\n",
      "loss: 0.868495  [272000/525306]\n",
      "loss: 0.358089  [273600/525306]\n",
      "loss: 0.593639  [275200/525306]\n",
      "loss: 0.398829  [276800/525306]\n",
      "loss: 0.654916  [278400/525306]\n",
      "loss: 0.986962  [280000/525306]\n",
      "loss: 0.708476  [281600/525306]\n",
      "loss: 0.434210  [283200/525306]\n",
      "loss: 0.778719  [284800/525306]\n",
      "loss: 0.707311  [286400/525306]\n",
      "loss: 0.852547  [288000/525306]\n",
      "loss: 0.691751  [289600/525306]\n",
      "loss: 0.646068  [291200/525306]\n",
      "loss: 0.635189  [292800/525306]\n",
      "loss: 0.563040  [294400/525306]\n",
      "loss: 0.889731  [296000/525306]\n",
      "loss: 0.543895  [297600/525306]\n",
      "loss: 0.421885  [299200/525306]\n",
      "loss: 1.089042  [300800/525306]\n",
      "loss: 1.127455  [302400/525306]\n",
      "loss: 0.908714  [304000/525306]\n",
      "loss: 1.209606  [305600/525306]\n",
      "loss: 0.967696  [307200/525306]\n",
      "loss: 0.388249  [308800/525306]\n",
      "loss: 0.734581  [310400/525306]\n",
      "loss: 0.702140  [312000/525306]\n",
      "loss: 0.612035  [313600/525306]\n",
      "loss: 0.732956  [315200/525306]\n",
      "loss: 0.706839  [316800/525306]\n",
      "loss: 0.971613  [318400/525306]\n",
      "loss: 0.954961  [320000/525306]\n",
      "loss: 0.537485  [321600/525306]\n",
      "loss: 0.388028  [323200/525306]\n",
      "loss: 0.638092  [324800/525306]\n",
      "loss: 0.792792  [326400/525306]\n",
      "loss: 0.616271  [328000/525306]\n",
      "loss: 0.400652  [329600/525306]\n",
      "loss: 0.906324  [331200/525306]\n",
      "loss: 0.836986  [332800/525306]\n",
      "loss: 0.496734  [334400/525306]\n",
      "loss: 0.718561  [336000/525306]\n",
      "loss: 0.816620  [337600/525306]\n",
      "loss: 0.440075  [339200/525306]\n",
      "loss: 0.986586  [340800/525306]\n",
      "loss: 0.517662  [342400/525306]\n",
      "loss: 0.982844  [344000/525306]\n",
      "loss: 0.677222  [345600/525306]\n",
      "loss: 0.638664  [347200/525306]\n",
      "loss: 0.749705  [348800/525306]\n",
      "loss: 0.324276  [350400/525306]\n",
      "loss: 0.918158  [352000/525306]\n",
      "loss: 0.152602  [353600/525306]\n",
      "loss: 0.469903  [355200/525306]\n",
      "loss: 0.684510  [356800/525306]\n",
      "loss: 0.875872  [358400/525306]\n",
      "loss: 0.515786  [360000/525306]\n",
      "loss: 0.760815  [361600/525306]\n",
      "loss: 0.703218  [363200/525306]\n",
      "loss: 1.026243  [364800/525306]\n",
      "loss: 0.864785  [366400/525306]\n",
      "loss: 0.653665  [368000/525306]\n",
      "loss: 0.308121  [369600/525306]\n",
      "loss: 1.165941  [371200/525306]\n",
      "loss: 0.376887  [372800/525306]\n",
      "loss: 0.771308  [374400/525306]\n",
      "loss: 0.770346  [376000/525306]\n",
      "loss: 0.617989  [377600/525306]\n",
      "loss: 0.523479  [379200/525306]\n",
      "loss: 0.740316  [380800/525306]\n",
      "loss: 0.840910  [382400/525306]\n",
      "loss: 0.731657  [384000/525306]\n",
      "loss: 0.332688  [385600/525306]\n",
      "loss: 0.625575  [387200/525306]\n",
      "loss: 0.634020  [388800/525306]\n",
      "loss: 0.734996  [390400/525306]\n",
      "loss: 0.885206  [392000/525306]\n",
      "loss: 1.050047  [393600/525306]\n",
      "loss: 0.627080  [395200/525306]\n",
      "loss: 0.562606  [396800/525306]\n",
      "loss: 0.858198  [398400/525306]\n",
      "loss: 0.993131  [400000/525306]\n",
      "loss: 0.724821  [401600/525306]\n",
      "loss: 0.492264  [403200/525306]\n",
      "loss: 0.759891  [404800/525306]\n",
      "loss: 0.550995  [406400/525306]\n",
      "loss: 1.046397  [408000/525306]\n",
      "loss: 0.710145  [409600/525306]\n",
      "loss: 0.723618  [411200/525306]\n",
      "loss: 0.513251  [412800/525306]\n",
      "loss: 0.833220  [414400/525306]\n",
      "loss: 0.790344  [416000/525306]\n",
      "loss: 1.207654  [417600/525306]\n",
      "loss: 1.263855  [419200/525306]\n",
      "loss: 0.888936  [420800/525306]\n",
      "loss: 0.782039  [422400/525306]\n",
      "loss: 0.324440  [424000/525306]\n",
      "loss: 0.313732  [425600/525306]\n",
      "loss: 0.613853  [427200/525306]\n",
      "loss: 0.345734  [428800/525306]\n",
      "loss: 0.386085  [430400/525306]\n",
      "loss: 0.467881  [432000/525306]\n",
      "loss: 1.016454  [433600/525306]\n",
      "loss: 0.314580  [435200/525306]\n",
      "loss: 0.889752  [436800/525306]\n",
      "loss: 0.438266  [438400/525306]\n",
      "loss: 0.379250  [440000/525306]\n",
      "loss: 0.461294  [441600/525306]\n",
      "loss: 0.849982  [443200/525306]\n",
      "loss: 0.474887  [444800/525306]\n",
      "loss: 0.450724  [446400/525306]\n",
      "loss: 0.455456  [448000/525306]\n",
      "loss: 0.558630  [449600/525306]\n",
      "loss: 0.848393  [451200/525306]\n",
      "loss: 0.783397  [452800/525306]\n",
      "loss: 0.715875  [454400/525306]\n",
      "loss: 0.934885  [456000/525306]\n",
      "loss: 0.868394  [457600/525306]\n",
      "loss: 0.767650  [459200/525306]\n",
      "loss: 0.726499  [460800/525306]\n",
      "loss: 0.862472  [462400/525306]\n",
      "loss: 1.251396  [464000/525306]\n",
      "loss: 0.719333  [465600/525306]\n",
      "loss: 0.610624  [467200/525306]\n",
      "loss: 1.274964  [468800/525306]\n",
      "loss: 0.694684  [470400/525306]\n",
      "loss: 0.990703  [472000/525306]\n",
      "loss: 0.522859  [473600/525306]\n",
      "loss: 0.632069  [475200/525306]\n",
      "loss: 0.821126  [476800/525306]\n",
      "loss: 0.403236  [478400/525306]\n",
      "loss: 0.803353  [480000/525306]\n",
      "loss: 0.612323  [481600/525306]\n",
      "loss: 0.629902  [483200/525306]\n",
      "loss: 1.073797  [484800/525306]\n",
      "loss: 0.986325  [486400/525306]\n",
      "loss: 0.812550  [488000/525306]\n",
      "loss: 0.686403  [489600/525306]\n",
      "loss: 0.668833  [491200/525306]\n",
      "loss: 0.600275  [492800/525306]\n",
      "loss: 0.852732  [494400/525306]\n",
      "loss: 0.607117  [496000/525306]\n",
      "loss: 0.739363  [497600/525306]\n",
      "loss: 0.718633  [499200/525306]\n",
      "loss: 0.711176  [500800/525306]\n",
      "loss: 0.381742  [502400/525306]\n",
      "loss: 1.111298  [504000/525306]\n",
      "loss: 1.211469  [505600/525306]\n",
      "loss: 0.890172  [507200/525306]\n",
      "loss: 0.721849  [508800/525306]\n",
      "loss: 0.734906  [510400/525306]\n",
      "loss: 0.398166  [512000/525306]\n",
      "loss: 1.113172  [513600/525306]\n",
      "loss: 0.751709  [515200/525306]\n",
      "loss: 1.077572  [516800/525306]\n",
      "loss: 0.827837  [518400/525306]\n",
      "loss: 0.961634  [520000/525306]\n",
      "loss: 0.385604  [521600/525306]\n",
      "loss: 0.821132  [523200/525306]\n",
      "loss: 0.302978  [524800/525306]\n",
      "Train Accuracy: 72.5316%\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.899492, F1-score: 70.57%, Macro_F1-Score:  39.88%  \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.853371  [    0/525306]\n",
      "loss: 0.527008  [ 1600/525306]\n",
      "loss: 1.100149  [ 3200/525306]\n",
      "loss: 1.021028  [ 4800/525306]\n",
      "loss: 0.543415  [ 6400/525306]\n",
      "loss: 0.478840  [ 8000/525306]\n",
      "loss: 0.737483  [ 9600/525306]\n",
      "loss: 0.682943  [11200/525306]\n",
      "loss: 0.508746  [12800/525306]\n",
      "loss: 1.068292  [14400/525306]\n",
      "loss: 0.936637  [16000/525306]\n",
      "loss: 1.004052  [17600/525306]\n",
      "loss: 0.566778  [19200/525306]\n",
      "loss: 0.408021  [20800/525306]\n",
      "loss: 0.590962  [22400/525306]\n",
      "loss: 0.611954  [24000/525306]\n",
      "loss: 0.592162  [25600/525306]\n",
      "loss: 0.446634  [27200/525306]\n",
      "loss: 0.908503  [28800/525306]\n",
      "loss: 0.493740  [30400/525306]\n",
      "loss: 0.649580  [32000/525306]\n",
      "loss: 0.822047  [33600/525306]\n",
      "loss: 0.597729  [35200/525306]\n",
      "loss: 0.748951  [36800/525306]\n",
      "loss: 1.065881  [38400/525306]\n",
      "loss: 1.036172  [40000/525306]\n",
      "loss: 0.697378  [41600/525306]\n",
      "loss: 0.627840  [43200/525306]\n",
      "loss: 0.431447  [44800/525306]\n",
      "loss: 0.779642  [46400/525306]\n",
      "loss: 0.830140  [48000/525306]\n",
      "loss: 0.367681  [49600/525306]\n",
      "loss: 0.621846  [51200/525306]\n",
      "loss: 0.606134  [52800/525306]\n",
      "loss: 0.619683  [54400/525306]\n",
      "loss: 0.710618  [56000/525306]\n",
      "loss: 0.505808  [57600/525306]\n",
      "loss: 0.916930  [59200/525306]\n",
      "loss: 0.544074  [60800/525306]\n",
      "loss: 0.917924  [62400/525306]\n",
      "loss: 1.067042  [64000/525306]\n",
      "loss: 0.440602  [65600/525306]\n",
      "loss: 0.783772  [67200/525306]\n",
      "loss: 0.670618  [68800/525306]\n",
      "loss: 0.992178  [70400/525306]\n",
      "loss: 0.279066  [72000/525306]\n",
      "loss: 0.351400  [73600/525306]\n",
      "loss: 0.700272  [75200/525306]\n",
      "loss: 0.682686  [76800/525306]\n",
      "loss: 0.991013  [78400/525306]\n",
      "loss: 0.820004  [80000/525306]\n",
      "loss: 0.772437  [81600/525306]\n",
      "loss: 0.742647  [83200/525306]\n",
      "loss: 0.449503  [84800/525306]\n",
      "loss: 0.974534  [86400/525306]\n",
      "loss: 0.861508  [88000/525306]\n",
      "loss: 0.557872  [89600/525306]\n",
      "loss: 0.661857  [91200/525306]\n",
      "loss: 0.591225  [92800/525306]\n",
      "loss: 0.840647  [94400/525306]\n",
      "loss: 0.839419  [96000/525306]\n",
      "loss: 0.891153  [97600/525306]\n",
      "loss: 1.006782  [99200/525306]\n",
      "loss: 0.651198  [100800/525306]\n",
      "loss: 0.610598  [102400/525306]\n",
      "loss: 1.012608  [104000/525306]\n",
      "loss: 0.426660  [105600/525306]\n",
      "loss: 0.542101  [107200/525306]\n",
      "loss: 0.772149  [108800/525306]\n",
      "loss: 1.024386  [110400/525306]\n",
      "loss: 0.384400  [112000/525306]\n",
      "loss: 0.930159  [113600/525306]\n",
      "loss: 0.531761  [115200/525306]\n",
      "loss: 0.971048  [116800/525306]\n",
      "loss: 0.603950  [118400/525306]\n",
      "loss: 0.548286  [120000/525306]\n",
      "loss: 0.823490  [121600/525306]\n",
      "loss: 0.737558  [123200/525306]\n",
      "loss: 0.624851  [124800/525306]\n",
      "loss: 0.897533  [126400/525306]\n",
      "loss: 0.385811  [128000/525306]\n",
      "loss: 1.340853  [129600/525306]\n",
      "loss: 1.175931  [131200/525306]\n",
      "loss: 0.646589  [132800/525306]\n",
      "loss: 0.739435  [134400/525306]\n",
      "loss: 1.044694  [136000/525306]\n",
      "loss: 0.766377  [137600/525306]\n",
      "loss: 1.017979  [139200/525306]\n",
      "loss: 0.405802  [140800/525306]\n",
      "loss: 0.951851  [142400/525306]\n",
      "loss: 0.992128  [144000/525306]\n",
      "loss: 0.393150  [145600/525306]\n",
      "loss: 0.403899  [147200/525306]\n",
      "loss: 0.427059  [148800/525306]\n",
      "loss: 0.436552  [150400/525306]\n",
      "loss: 0.294715  [152000/525306]\n",
      "loss: 0.561216  [153600/525306]\n",
      "loss: 0.825985  [155200/525306]\n",
      "loss: 0.940662  [156800/525306]\n",
      "loss: 0.849423  [158400/525306]\n",
      "loss: 0.648138  [160000/525306]\n",
      "loss: 0.878011  [161600/525306]\n",
      "loss: 1.334268  [163200/525306]\n",
      "loss: 0.316623  [164800/525306]\n",
      "loss: 0.519387  [166400/525306]\n",
      "loss: 0.834456  [168000/525306]\n",
      "loss: 0.625316  [169600/525306]\n",
      "loss: 0.389428  [171200/525306]\n",
      "loss: 0.764402  [172800/525306]\n",
      "loss: 0.583465  [174400/525306]\n",
      "loss: 0.429971  [176000/525306]\n",
      "loss: 0.767445  [177600/525306]\n",
      "loss: 0.925154  [179200/525306]\n",
      "loss: 0.708560  [180800/525306]\n",
      "loss: 0.411014  [182400/525306]\n",
      "loss: 0.861484  [184000/525306]\n",
      "loss: 1.045529  [185600/525306]\n",
      "loss: 0.788962  [187200/525306]\n",
      "loss: 0.526741  [188800/525306]\n",
      "loss: 0.864065  [190400/525306]\n",
      "loss: 0.721963  [192000/525306]\n",
      "loss: 0.830500  [193600/525306]\n",
      "loss: 0.758259  [195200/525306]\n",
      "loss: 0.787561  [196800/525306]\n",
      "loss: 0.894005  [198400/525306]\n",
      "loss: 0.718836  [200000/525306]\n",
      "loss: 0.373065  [201600/525306]\n",
      "loss: 0.758233  [203200/525306]\n",
      "loss: 0.629648  [204800/525306]\n",
      "loss: 0.741890  [206400/525306]\n",
      "loss: 0.725791  [208000/525306]\n",
      "loss: 1.019518  [209600/525306]\n",
      "loss: 0.885687  [211200/525306]\n",
      "loss: 0.693388  [212800/525306]\n",
      "loss: 0.989532  [214400/525306]\n",
      "loss: 0.754180  [216000/525306]\n",
      "loss: 0.915509  [217600/525306]\n",
      "loss: 0.828531  [219200/525306]\n",
      "loss: 0.841357  [220800/525306]\n",
      "loss: 1.135683  [222400/525306]\n",
      "loss: 0.744885  [224000/525306]\n",
      "loss: 0.753609  [225600/525306]\n",
      "loss: 0.378052  [227200/525306]\n",
      "loss: 0.533730  [228800/525306]\n",
      "loss: 0.699089  [230400/525306]\n",
      "loss: 0.388185  [232000/525306]\n",
      "loss: 0.490211  [233600/525306]\n",
      "loss: 0.697451  [235200/525306]\n",
      "loss: 0.459894  [236800/525306]\n",
      "loss: 0.759513  [238400/525306]\n",
      "loss: 0.566449  [240000/525306]\n",
      "loss: 0.504957  [241600/525306]\n",
      "loss: 0.862583  [243200/525306]\n",
      "loss: 0.513972  [244800/525306]\n",
      "loss: 0.504719  [246400/525306]\n",
      "loss: 0.883164  [248000/525306]\n",
      "loss: 0.835299  [249600/525306]\n",
      "loss: 0.373219  [251200/525306]\n",
      "loss: 0.848605  [252800/525306]\n",
      "loss: 0.696010  [254400/525306]\n",
      "loss: 1.027909  [256000/525306]\n",
      "loss: 0.582405  [257600/525306]\n",
      "loss: 0.650010  [259200/525306]\n",
      "loss: 0.919425  [260800/525306]\n",
      "loss: 0.617711  [262400/525306]\n",
      "loss: 0.984507  [264000/525306]\n",
      "loss: 0.627020  [265600/525306]\n",
      "loss: 0.646444  [267200/525306]\n",
      "loss: 0.868819  [268800/525306]\n",
      "loss: 0.829776  [270400/525306]\n",
      "loss: 0.493881  [272000/525306]\n",
      "loss: 0.403098  [273600/525306]\n",
      "loss: 0.686494  [275200/525306]\n",
      "loss: 1.296422  [276800/525306]\n",
      "loss: 0.361908  [278400/525306]\n",
      "loss: 0.616412  [280000/525306]\n",
      "loss: 0.419079  [281600/525306]\n",
      "loss: 0.697178  [283200/525306]\n",
      "loss: 0.529403  [284800/525306]\n",
      "loss: 0.905994  [286400/525306]\n",
      "loss: 0.705717  [288000/525306]\n",
      "loss: 0.529411  [289600/525306]\n",
      "loss: 0.926203  [291200/525306]\n",
      "loss: 0.522837  [292800/525306]\n",
      "loss: 0.764909  [294400/525306]\n",
      "loss: 0.458631  [296000/525306]\n",
      "loss: 0.233649  [297600/525306]\n",
      "loss: 0.975512  [299200/525306]\n",
      "loss: 0.808105  [300800/525306]\n",
      "loss: 0.459096  [302400/525306]\n",
      "loss: 0.466334  [304000/525306]\n",
      "loss: 0.612600  [305600/525306]\n",
      "loss: 0.469136  [307200/525306]\n",
      "loss: 0.777284  [308800/525306]\n",
      "loss: 0.786957  [310400/525306]\n",
      "loss: 0.388003  [312000/525306]\n",
      "loss: 0.796036  [313600/525306]\n",
      "loss: 0.715567  [315200/525306]\n",
      "loss: 0.856369  [316800/525306]\n",
      "loss: 0.730575  [318400/525306]\n",
      "loss: 0.878989  [320000/525306]\n",
      "loss: 0.561389  [321600/525306]\n",
      "loss: 1.396404  [323200/525306]\n",
      "loss: 0.466395  [324800/525306]\n",
      "loss: 0.923600  [326400/525306]\n",
      "loss: 0.699141  [328000/525306]\n",
      "loss: 0.572922  [329600/525306]\n",
      "loss: 0.497485  [331200/525306]\n",
      "loss: 1.088970  [332800/525306]\n",
      "loss: 0.885492  [334400/525306]\n",
      "loss: 0.511320  [336000/525306]\n",
      "loss: 0.506421  [337600/525306]\n",
      "loss: 0.922625  [339200/525306]\n",
      "loss: 1.232171  [340800/525306]\n",
      "loss: 0.607204  [342400/525306]\n",
      "loss: 0.566873  [344000/525306]\n",
      "loss: 0.760144  [345600/525306]\n",
      "loss: 0.475236  [347200/525306]\n",
      "loss: 0.490722  [348800/525306]\n",
      "loss: 0.540694  [350400/525306]\n",
      "loss: 0.700689  [352000/525306]\n",
      "loss: 0.882607  [353600/525306]\n",
      "loss: 0.939136  [355200/525306]\n",
      "loss: 0.794626  [356800/525306]\n",
      "loss: 0.543423  [358400/525306]\n",
      "loss: 0.657231  [360000/525306]\n",
      "loss: 0.518470  [361600/525306]\n",
      "loss: 0.807688  [363200/525306]\n",
      "loss: 1.011530  [364800/525306]\n",
      "loss: 0.420062  [366400/525306]\n",
      "loss: 0.457579  [368000/525306]\n",
      "loss: 0.762850  [369600/525306]\n",
      "loss: 0.730900  [371200/525306]\n",
      "loss: 0.975679  [372800/525306]\n",
      "loss: 0.786269  [374400/525306]\n",
      "loss: 0.911478  [376000/525306]\n",
      "loss: 0.285321  [377600/525306]\n",
      "loss: 0.438053  [379200/525306]\n",
      "loss: 0.913546  [380800/525306]\n",
      "loss: 0.770645  [382400/525306]\n",
      "loss: 0.570967  [384000/525306]\n",
      "loss: 0.925851  [385600/525306]\n",
      "loss: 0.343975  [387200/525306]\n",
      "loss: 0.663964  [388800/525306]\n",
      "loss: 0.929552  [390400/525306]\n",
      "loss: 1.038144  [392000/525306]\n",
      "loss: 0.843404  [393600/525306]\n",
      "loss: 1.156584  [395200/525306]\n",
      "loss: 1.040718  [396800/525306]\n",
      "loss: 0.730199  [398400/525306]\n",
      "loss: 0.860845  [400000/525306]\n",
      "loss: 0.539716  [401600/525306]\n",
      "loss: 0.758906  [403200/525306]\n",
      "loss: 0.701710  [404800/525306]\n",
      "loss: 0.451900  [406400/525306]\n",
      "loss: 1.008147  [408000/525306]\n",
      "loss: 0.422994  [409600/525306]\n",
      "loss: 0.619845  [411200/525306]\n",
      "loss: 0.692059  [412800/525306]\n",
      "loss: 0.646548  [414400/525306]\n",
      "loss: 1.518882  [416000/525306]\n",
      "loss: 0.254381  [417600/525306]\n",
      "loss: 0.838714  [419200/525306]\n",
      "loss: 0.910202  [420800/525306]\n",
      "loss: 1.135065  [422400/525306]\n",
      "loss: 0.368079  [424000/525306]\n",
      "loss: 0.519867  [425600/525306]\n",
      "loss: 1.051459  [427200/525306]\n",
      "loss: 0.868743  [428800/525306]\n",
      "loss: 0.553403  [430400/525306]\n",
      "loss: 1.239889  [432000/525306]\n",
      "loss: 0.737465  [433600/525306]\n",
      "loss: 0.548833  [435200/525306]\n",
      "loss: 1.297644  [436800/525306]\n",
      "loss: 0.567343  [438400/525306]\n",
      "loss: 0.921821  [440000/525306]\n",
      "loss: 0.716241  [441600/525306]\n",
      "loss: 1.186331  [443200/525306]\n",
      "loss: 0.876948  [444800/525306]\n",
      "loss: 1.286730  [446400/525306]\n",
      "loss: 0.693972  [448000/525306]\n",
      "loss: 0.538623  [449600/525306]\n",
      "loss: 0.529330  [451200/525306]\n",
      "loss: 0.596688  [452800/525306]\n",
      "loss: 0.536012  [454400/525306]\n",
      "loss: 0.877246  [456000/525306]\n",
      "loss: 0.953133  [457600/525306]\n",
      "loss: 1.052875  [459200/525306]\n",
      "loss: 0.864096  [460800/525306]\n",
      "loss: 0.650086  [462400/525306]\n",
      "loss: 0.777725  [464000/525306]\n",
      "loss: 0.822125  [465600/525306]\n",
      "loss: 0.641673  [467200/525306]\n",
      "loss: 0.779201  [468800/525306]\n",
      "loss: 0.684654  [470400/525306]\n",
      "loss: 0.802169  [472000/525306]\n",
      "loss: 0.779032  [473600/525306]\n",
      "loss: 0.340769  [475200/525306]\n",
      "loss: 0.865622  [476800/525306]\n",
      "loss: 0.844367  [478400/525306]\n",
      "loss: 0.451949  [480000/525306]\n",
      "loss: 0.941229  [481600/525306]\n",
      "loss: 0.445878  [483200/525306]\n",
      "loss: 0.855588  [484800/525306]\n",
      "loss: 0.660444  [486400/525306]\n",
      "loss: 1.077293  [488000/525306]\n",
      "loss: 0.560014  [489600/525306]\n",
      "loss: 0.391989  [491200/525306]\n",
      "loss: 0.814633  [492800/525306]\n",
      "loss: 1.226768  [494400/525306]\n",
      "loss: 0.594724  [496000/525306]\n",
      "loss: 0.421586  [497600/525306]\n",
      "loss: 0.546075  [499200/525306]\n",
      "loss: 0.525531  [500800/525306]\n",
      "loss: 0.960475  [502400/525306]\n",
      "loss: 0.662192  [504000/525306]\n",
      "loss: 0.701954  [505600/525306]\n",
      "loss: 0.689393  [507200/525306]\n",
      "loss: 1.139337  [508800/525306]\n",
      "loss: 1.439629  [510400/525306]\n",
      "loss: 0.520104  [512000/525306]\n",
      "loss: 0.618944  [513600/525306]\n",
      "loss: 0.619697  [515200/525306]\n",
      "loss: 0.760904  [516800/525306]\n",
      "loss: 0.462547  [518400/525306]\n",
      "loss: 0.952097  [520000/525306]\n",
      "loss: 1.093428  [521600/525306]\n",
      "loss: 0.528385  [523200/525306]\n",
      "loss: 0.816874  [524800/525306]\n",
      "Train Accuracy: 72.6931%\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.910601, F1-score: 70.17%, Macro_F1-Score:  38.98%  \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 1.015561  [    0/525306]\n",
      "loss: 0.765422  [ 1600/525306]\n",
      "loss: 1.006450  [ 3200/525306]\n",
      "loss: 1.196672  [ 4800/525306]\n",
      "loss: 0.459388  [ 6400/525306]\n",
      "loss: 0.894156  [ 8000/525306]\n",
      "loss: 0.819989  [ 9600/525306]\n",
      "loss: 0.950968  [11200/525306]\n",
      "loss: 0.785971  [12800/525306]\n",
      "loss: 1.157440  [14400/525306]\n",
      "loss: 0.886424  [16000/525306]\n",
      "loss: 0.634981  [17600/525306]\n",
      "loss: 0.754078  [19200/525306]\n",
      "loss: 0.542997  [20800/525306]\n",
      "loss: 0.726494  [22400/525306]\n",
      "loss: 0.892126  [24000/525306]\n",
      "loss: 0.609186  [25600/525306]\n",
      "loss: 0.929135  [27200/525306]\n",
      "loss: 0.924427  [28800/525306]\n",
      "loss: 0.739415  [30400/525306]\n",
      "loss: 0.520271  [32000/525306]\n",
      "loss: 0.285927  [33600/525306]\n",
      "loss: 0.862213  [35200/525306]\n",
      "loss: 0.770024  [36800/525306]\n",
      "loss: 0.749802  [38400/525306]\n",
      "loss: 1.019044  [40000/525306]\n",
      "loss: 0.846871  [41600/525306]\n",
      "loss: 0.510259  [43200/525306]\n",
      "loss: 0.608263  [44800/525306]\n",
      "loss: 0.503493  [46400/525306]\n",
      "loss: 0.693048  [48000/525306]\n",
      "loss: 0.820667  [49600/525306]\n",
      "loss: 0.263101  [51200/525306]\n",
      "loss: 0.766112  [52800/525306]\n",
      "loss: 0.305960  [54400/525306]\n",
      "loss: 1.178584  [56000/525306]\n",
      "loss: 0.166527  [57600/525306]\n",
      "loss: 0.406137  [59200/525306]\n",
      "loss: 0.240871  [60800/525306]\n",
      "loss: 0.508953  [62400/525306]\n",
      "loss: 0.721608  [64000/525306]\n",
      "loss: 0.378684  [65600/525306]\n",
      "loss: 0.680917  [67200/525306]\n",
      "loss: 0.772900  [68800/525306]\n",
      "loss: 0.556629  [70400/525306]\n",
      "loss: 0.689057  [72000/525306]\n",
      "loss: 0.641539  [73600/525306]\n",
      "loss: 0.611018  [75200/525306]\n",
      "loss: 1.014752  [76800/525306]\n",
      "loss: 0.311465  [78400/525306]\n",
      "loss: 0.755101  [80000/525306]\n",
      "loss: 0.706772  [81600/525306]\n",
      "loss: 0.337258  [83200/525306]\n",
      "loss: 0.663518  [84800/525306]\n",
      "loss: 0.553166  [86400/525306]\n",
      "loss: 0.654821  [88000/525306]\n",
      "loss: 0.575284  [89600/525306]\n",
      "loss: 0.450994  [91200/525306]\n",
      "loss: 0.852793  [92800/525306]\n",
      "loss: 0.667332  [94400/525306]\n",
      "loss: 0.829912  [96000/525306]\n",
      "loss: 0.881166  [97600/525306]\n",
      "loss: 0.392349  [99200/525306]\n",
      "loss: 0.984832  [100800/525306]\n",
      "loss: 1.342544  [102400/525306]\n",
      "loss: 0.856052  [104000/525306]\n",
      "loss: 0.751090  [105600/525306]\n",
      "loss: 0.830973  [107200/525306]\n",
      "loss: 0.689050  [108800/525306]\n",
      "loss: 0.262096  [110400/525306]\n",
      "loss: 0.532580  [112000/525306]\n",
      "loss: 1.385461  [113600/525306]\n",
      "loss: 0.384007  [115200/525306]\n",
      "loss: 0.896118  [116800/525306]\n",
      "loss: 0.581045  [118400/525306]\n",
      "loss: 0.541371  [120000/525306]\n",
      "loss: 1.063499  [121600/525306]\n",
      "loss: 0.975184  [123200/525306]\n",
      "loss: 0.470685  [124800/525306]\n",
      "loss: 0.760123  [126400/525306]\n",
      "loss: 0.864840  [128000/525306]\n",
      "loss: 0.605675  [129600/525306]\n",
      "loss: 0.704908  [131200/525306]\n",
      "loss: 0.549628  [132800/525306]\n",
      "loss: 0.463621  [134400/525306]\n",
      "loss: 0.701465  [136000/525306]\n",
      "loss: 0.734576  [137600/525306]\n",
      "loss: 0.704668  [139200/525306]\n",
      "loss: 0.729125  [140800/525306]\n",
      "loss: 0.876137  [142400/525306]\n",
      "loss: 0.964873  [144000/525306]\n",
      "loss: 0.844089  [145600/525306]\n",
      "loss: 1.015479  [147200/525306]\n",
      "loss: 0.646255  [148800/525306]\n",
      "loss: 0.584595  [150400/525306]\n",
      "loss: 0.512233  [152000/525306]\n",
      "loss: 0.732499  [153600/525306]\n",
      "loss: 1.104968  [155200/525306]\n",
      "loss: 0.702382  [156800/525306]\n",
      "loss: 0.677557  [158400/525306]\n",
      "loss: 0.380415  [160000/525306]\n",
      "loss: 0.311304  [161600/525306]\n",
      "loss: 0.782444  [163200/525306]\n",
      "loss: 1.200610  [164800/525306]\n",
      "loss: 0.583239  [166400/525306]\n",
      "loss: 0.713719  [168000/525306]\n",
      "loss: 0.682121  [169600/525306]\n",
      "loss: 0.994337  [171200/525306]\n",
      "loss: 0.596163  [172800/525306]\n",
      "loss: 0.946274  [174400/525306]\n",
      "loss: 0.545195  [176000/525306]\n",
      "loss: 0.859016  [177600/525306]\n",
      "loss: 0.565400  [179200/525306]\n",
      "loss: 1.075905  [180800/525306]\n",
      "loss: 0.621539  [182400/525306]\n",
      "loss: 0.265550  [184000/525306]\n",
      "loss: 0.768598  [185600/525306]\n",
      "loss: 0.644315  [187200/525306]\n",
      "loss: 0.691955  [188800/525306]\n",
      "loss: 0.269059  [190400/525306]\n",
      "loss: 0.766587  [192000/525306]\n",
      "loss: 0.491419  [193600/525306]\n",
      "loss: 0.457627  [195200/525306]\n",
      "loss: 0.629305  [196800/525306]\n",
      "loss: 0.531924  [198400/525306]\n",
      "loss: 0.632410  [200000/525306]\n",
      "loss: 0.821152  [201600/525306]\n",
      "loss: 0.647708  [203200/525306]\n",
      "loss: 0.959746  [204800/525306]\n",
      "loss: 0.487016  [206400/525306]\n",
      "loss: 0.498057  [208000/525306]\n",
      "loss: 0.496666  [209600/525306]\n",
      "loss: 0.541170  [211200/525306]\n",
      "loss: 0.664463  [212800/525306]\n",
      "loss: 1.152832  [214400/525306]\n",
      "loss: 0.516094  [216000/525306]\n",
      "loss: 0.587689  [217600/525306]\n",
      "loss: 0.340273  [219200/525306]\n",
      "loss: 0.678546  [220800/525306]\n",
      "loss: 0.530264  [222400/525306]\n",
      "loss: 0.566189  [224000/525306]\n",
      "loss: 1.553331  [225600/525306]\n",
      "loss: 0.749594  [227200/525306]\n",
      "loss: 0.681410  [228800/525306]\n",
      "loss: 0.525086  [230400/525306]\n",
      "loss: 0.623201  [232000/525306]\n",
      "loss: 0.282604  [233600/525306]\n",
      "loss: 0.472831  [235200/525306]\n",
      "loss: 0.634119  [236800/525306]\n",
      "loss: 0.785325  [238400/525306]\n",
      "loss: 1.245925  [240000/525306]\n",
      "loss: 0.821434  [241600/525306]\n",
      "loss: 0.583778  [243200/525306]\n",
      "loss: 0.912279  [244800/525306]\n",
      "loss: 0.842469  [246400/525306]\n",
      "loss: 0.490113  [248000/525306]\n",
      "loss: 0.916287  [249600/525306]\n",
      "loss: 1.093931  [251200/525306]\n",
      "loss: 0.565394  [252800/525306]\n",
      "loss: 0.515809  [254400/525306]\n",
      "loss: 0.710314  [256000/525306]\n",
      "loss: 0.703326  [257600/525306]\n",
      "loss: 0.749808  [259200/525306]\n",
      "loss: 1.223710  [260800/525306]\n",
      "loss: 0.741740  [262400/525306]\n",
      "loss: 0.730072  [264000/525306]\n",
      "loss: 1.307767  [265600/525306]\n",
      "loss: 1.271675  [267200/525306]\n",
      "loss: 0.978664  [268800/525306]\n",
      "loss: 0.715021  [270400/525306]\n",
      "loss: 0.720744  [272000/525306]\n",
      "loss: 0.718169  [273600/525306]\n",
      "loss: 0.561152  [275200/525306]\n",
      "loss: 0.714705  [276800/525306]\n",
      "loss: 0.321083  [278400/525306]\n",
      "loss: 0.805268  [280000/525306]\n",
      "loss: 0.660755  [281600/525306]\n",
      "loss: 0.882929  [283200/525306]\n",
      "loss: 0.767560  [284800/525306]\n",
      "loss: 0.657147  [286400/525306]\n",
      "loss: 0.698541  [288000/525306]\n",
      "loss: 0.942117  [289600/525306]\n",
      "loss: 0.677038  [291200/525306]\n",
      "loss: 0.841571  [292800/525306]\n",
      "loss: 0.952556  [294400/525306]\n",
      "loss: 0.945158  [296000/525306]\n",
      "loss: 0.921282  [297600/525306]\n",
      "loss: 1.165744  [299200/525306]\n",
      "loss: 0.576250  [300800/525306]\n",
      "loss: 0.699739  [302400/525306]\n",
      "loss: 1.112998  [304000/525306]\n",
      "loss: 0.678488  [305600/525306]\n",
      "loss: 0.906017  [307200/525306]\n",
      "loss: 0.695497  [308800/525306]\n",
      "loss: 0.611439  [310400/525306]\n",
      "loss: 0.693718  [312000/525306]\n",
      "loss: 0.684477  [313600/525306]\n",
      "loss: 1.101767  [315200/525306]\n",
      "loss: 0.748279  [316800/525306]\n",
      "loss: 0.316716  [318400/525306]\n",
      "loss: 0.918775  [320000/525306]\n",
      "loss: 0.416868  [321600/525306]\n",
      "loss: 0.955931  [323200/525306]\n",
      "loss: 0.646309  [324800/525306]\n",
      "loss: 0.779405  [326400/525306]\n",
      "loss: 0.783798  [328000/525306]\n",
      "loss: 0.580331  [329600/525306]\n",
      "loss: 0.998336  [331200/525306]\n",
      "loss: 0.758940  [332800/525306]\n",
      "loss: 0.636553  [334400/525306]\n",
      "loss: 1.280922  [336000/525306]\n",
      "loss: 0.304465  [337600/525306]\n",
      "loss: 0.787469  [339200/525306]\n",
      "loss: 0.696578  [340800/525306]\n",
      "loss: 0.652020  [342400/525306]\n",
      "loss: 0.727738  [344000/525306]\n",
      "loss: 0.266363  [345600/525306]\n",
      "loss: 0.887181  [347200/525306]\n",
      "loss: 0.296991  [348800/525306]\n",
      "loss: 1.125430  [350400/525306]\n",
      "loss: 0.528350  [352000/525306]\n",
      "loss: 0.887167  [353600/525306]\n",
      "loss: 0.584391  [355200/525306]\n",
      "loss: 0.481925  [356800/525306]\n",
      "loss: 1.081917  [358400/525306]\n",
      "loss: 0.712388  [360000/525306]\n",
      "loss: 0.656307  [361600/525306]\n",
      "loss: 0.570547  [363200/525306]\n",
      "loss: 0.608764  [364800/525306]\n",
      "loss: 0.420311  [366400/525306]\n",
      "loss: 1.056344  [368000/525306]\n",
      "loss: 0.710664  [369600/525306]\n",
      "loss: 0.315294  [371200/525306]\n",
      "loss: 0.546373  [372800/525306]\n",
      "loss: 0.317233  [374400/525306]\n",
      "loss: 0.546975  [376000/525306]\n",
      "loss: 0.541307  [377600/525306]\n",
      "loss: 0.577717  [379200/525306]\n",
      "loss: 0.789176  [380800/525306]\n",
      "loss: 0.417703  [382400/525306]\n",
      "loss: 0.468760  [384000/525306]\n",
      "loss: 1.179927  [385600/525306]\n",
      "loss: 0.397029  [387200/525306]\n",
      "loss: 0.678244  [388800/525306]\n",
      "loss: 0.578027  [390400/525306]\n",
      "loss: 0.502453  [392000/525306]\n",
      "loss: 0.955501  [393600/525306]\n",
      "loss: 0.304934  [395200/525306]\n",
      "loss: 0.395759  [396800/525306]\n",
      "loss: 1.035606  [398400/525306]\n",
      "loss: 0.326580  [400000/525306]\n",
      "loss: 0.840435  [401600/525306]\n",
      "loss: 0.963113  [403200/525306]\n",
      "loss: 0.849303  [404800/525306]\n",
      "loss: 0.609618  [406400/525306]\n",
      "loss: 1.078903  [408000/525306]\n",
      "loss: 0.686080  [409600/525306]\n",
      "loss: 0.565463  [411200/525306]\n",
      "loss: 1.238829  [412800/525306]\n",
      "loss: 1.229197  [414400/525306]\n",
      "loss: 0.581210  [416000/525306]\n",
      "loss: 0.784529  [417600/525306]\n",
      "loss: 0.656697  [419200/525306]\n",
      "loss: 0.745348  [420800/525306]\n",
      "loss: 1.080306  [422400/525306]\n",
      "loss: 0.591974  [424000/525306]\n",
      "loss: 0.759457  [425600/525306]\n",
      "loss: 0.866943  [427200/525306]\n",
      "loss: 0.776622  [428800/525306]\n",
      "loss: 0.532267  [430400/525306]\n",
      "loss: 0.738273  [432000/525306]\n",
      "loss: 0.706232  [433600/525306]\n",
      "loss: 0.446575  [435200/525306]\n",
      "loss: 0.446805  [436800/525306]\n",
      "loss: 0.630503  [438400/525306]\n",
      "loss: 0.723755  [440000/525306]\n",
      "loss: 0.515094  [441600/525306]\n",
      "loss: 0.486334  [443200/525306]\n",
      "loss: 0.520649  [444800/525306]\n",
      "loss: 0.788287  [446400/525306]\n",
      "loss: 0.800231  [448000/525306]\n",
      "loss: 0.578135  [449600/525306]\n",
      "loss: 0.735957  [451200/525306]\n",
      "loss: 1.017777  [452800/525306]\n",
      "loss: 0.690491  [454400/525306]\n",
      "loss: 0.485468  [456000/525306]\n",
      "loss: 0.638781  [457600/525306]\n",
      "loss: 0.930374  [459200/525306]\n",
      "loss: 0.692641  [460800/525306]\n",
      "loss: 0.463793  [462400/525306]\n",
      "loss: 0.792604  [464000/525306]\n",
      "loss: 0.356294  [465600/525306]\n",
      "loss: 0.784871  [467200/525306]\n",
      "loss: 0.495070  [468800/525306]\n",
      "loss: 0.710503  [470400/525306]\n",
      "loss: 0.825986  [472000/525306]\n",
      "loss: 0.857450  [473600/525306]\n",
      "loss: 0.601043  [475200/525306]\n",
      "loss: 0.476765  [476800/525306]\n",
      "loss: 0.547560  [478400/525306]\n",
      "loss: 0.740572  [480000/525306]\n",
      "loss: 0.561827  [481600/525306]\n",
      "loss: 0.385489  [483200/525306]\n",
      "loss: 0.596498  [484800/525306]\n",
      "loss: 0.491111  [486400/525306]\n",
      "loss: 0.569527  [488000/525306]\n",
      "loss: 0.934766  [489600/525306]\n",
      "loss: 0.698627  [491200/525306]\n",
      "loss: 0.931286  [492800/525306]\n",
      "loss: 0.856794  [494400/525306]\n",
      "loss: 0.561773  [496000/525306]\n",
      "loss: 0.890515  [497600/525306]\n",
      "loss: 0.386304  [499200/525306]\n",
      "loss: 0.499302  [500800/525306]\n",
      "loss: 1.376529  [502400/525306]\n",
      "loss: 0.657651  [504000/525306]\n",
      "loss: 0.617693  [505600/525306]\n",
      "loss: 0.323298  [507200/525306]\n",
      "loss: 0.364666  [508800/525306]\n",
      "loss: 0.835768  [510400/525306]\n",
      "loss: 0.540566  [512000/525306]\n",
      "loss: 0.638422  [513600/525306]\n",
      "loss: 0.717889  [515200/525306]\n",
      "loss: 0.950564  [516800/525306]\n",
      "loss: 0.873112  [518400/525306]\n",
      "loss: 0.906365  [520000/525306]\n",
      "loss: 0.687790  [521600/525306]\n",
      "loss: 0.609310  [523200/525306]\n",
      "loss: 0.814442  [524800/525306]\n",
      "Train Accuracy: 72.8929%\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.899148, F1-score: 70.14%, Macro_F1-Score:  39.21%  \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.504219  [    0/525306]\n",
      "loss: 0.669755  [ 1600/525306]\n",
      "loss: 0.714944  [ 3200/525306]\n",
      "loss: 0.599551  [ 4800/525306]\n",
      "loss: 0.872172  [ 6400/525306]\n",
      "loss: 0.546764  [ 8000/525306]\n",
      "loss: 0.583667  [ 9600/525306]\n",
      "loss: 0.975318  [11200/525306]\n",
      "loss: 0.435469  [12800/525306]\n",
      "loss: 0.495741  [14400/525306]\n",
      "loss: 0.649483  [16000/525306]\n",
      "loss: 0.579764  [17600/525306]\n",
      "loss: 0.475817  [19200/525306]\n",
      "loss: 0.589387  [20800/525306]\n",
      "loss: 0.574587  [22400/525306]\n",
      "loss: 0.547645  [24000/525306]\n",
      "loss: 0.523707  [25600/525306]\n",
      "loss: 0.481748  [27200/525306]\n",
      "loss: 0.793804  [28800/525306]\n",
      "loss: 0.542480  [30400/525306]\n",
      "loss: 0.668873  [32000/525306]\n",
      "loss: 0.434070  [33600/525306]\n",
      "loss: 0.465815  [35200/525306]\n",
      "loss: 0.650780  [36800/525306]\n",
      "loss: 0.960856  [38400/525306]\n",
      "loss: 0.573442  [40000/525306]\n",
      "loss: 1.115650  [41600/525306]\n",
      "loss: 0.483814  [43200/525306]\n",
      "loss: 1.016454  [44800/525306]\n",
      "loss: 0.861842  [46400/525306]\n",
      "loss: 0.715332  [48000/525306]\n",
      "loss: 0.797580  [49600/525306]\n",
      "loss: 0.725179  [51200/525306]\n",
      "loss: 0.768080  [52800/525306]\n",
      "loss: 0.534079  [54400/525306]\n",
      "loss: 0.744662  [56000/525306]\n",
      "loss: 0.632998  [57600/525306]\n",
      "loss: 1.221595  [59200/525306]\n",
      "loss: 1.098791  [60800/525306]\n",
      "loss: 0.663977  [62400/525306]\n",
      "loss: 0.587322  [64000/525306]\n",
      "loss: 0.790940  [65600/525306]\n",
      "loss: 0.658556  [67200/525306]\n",
      "loss: 0.771281  [68800/525306]\n",
      "loss: 1.073656  [70400/525306]\n",
      "loss: 0.346348  [72000/525306]\n",
      "loss: 0.769172  [73600/525306]\n",
      "loss: 0.821641  [75200/525306]\n",
      "loss: 0.593532  [76800/525306]\n",
      "loss: 0.348138  [78400/525306]\n",
      "loss: 0.737228  [80000/525306]\n",
      "loss: 0.815075  [81600/525306]\n",
      "loss: 0.914409  [83200/525306]\n",
      "loss: 0.755657  [84800/525306]\n",
      "loss: 0.546116  [86400/525306]\n",
      "loss: 0.439604  [88000/525306]\n",
      "loss: 0.639705  [89600/525306]\n",
      "loss: 0.756587  [91200/525306]\n",
      "loss: 0.581547  [92800/525306]\n",
      "loss: 1.115424  [94400/525306]\n",
      "loss: 0.599977  [96000/525306]\n",
      "loss: 0.407249  [97600/525306]\n",
      "loss: 0.523380  [99200/525306]\n",
      "loss: 0.637089  [100800/525306]\n",
      "loss: 0.775429  [102400/525306]\n",
      "loss: 0.657351  [104000/525306]\n",
      "loss: 0.670002  [105600/525306]\n",
      "loss: 0.593078  [107200/525306]\n",
      "loss: 0.813387  [108800/525306]\n",
      "loss: 0.630578  [110400/525306]\n",
      "loss: 0.634503  [112000/525306]\n",
      "loss: 0.605424  [113600/525306]\n",
      "loss: 0.636484  [115200/525306]\n",
      "loss: 0.652699  [116800/525306]\n",
      "loss: 0.772395  [118400/525306]\n",
      "loss: 0.815268  [120000/525306]\n",
      "loss: 1.426843  [121600/525306]\n",
      "loss: 0.665343  [123200/525306]\n",
      "loss: 1.054825  [124800/525306]\n",
      "loss: 1.388379  [126400/525306]\n",
      "loss: 0.490758  [128000/525306]\n",
      "loss: 0.927662  [129600/525306]\n",
      "loss: 0.834252  [131200/525306]\n",
      "loss: 0.422566  [132800/525306]\n",
      "loss: 0.845938  [134400/525306]\n",
      "loss: 0.540582  [136000/525306]\n",
      "loss: 0.550189  [137600/525306]\n",
      "loss: 0.415424  [139200/525306]\n",
      "loss: 1.086476  [140800/525306]\n",
      "loss: 1.291545  [142400/525306]\n",
      "loss: 1.080145  [144000/525306]\n",
      "loss: 0.984393  [145600/525306]\n",
      "loss: 0.415116  [147200/525306]\n",
      "loss: 0.792102  [148800/525306]\n",
      "loss: 0.712631  [150400/525306]\n",
      "loss: 0.425603  [152000/525306]\n",
      "loss: 0.768803  [153600/525306]\n",
      "loss: 0.530596  [155200/525306]\n",
      "loss: 1.065186  [156800/525306]\n",
      "loss: 1.282094  [158400/525306]\n",
      "loss: 0.732775  [160000/525306]\n",
      "loss: 0.791414  [161600/525306]\n",
      "loss: 0.896348  [163200/525306]\n",
      "loss: 1.362651  [164800/525306]\n",
      "loss: 0.538034  [166400/525306]\n",
      "loss: 0.589794  [168000/525306]\n",
      "loss: 0.992198  [169600/525306]\n",
      "loss: 0.935507  [171200/525306]\n",
      "loss: 1.554700  [172800/525306]\n",
      "loss: 0.539133  [174400/525306]\n",
      "loss: 0.856059  [176000/525306]\n",
      "loss: 0.682962  [177600/525306]\n",
      "loss: 0.768680  [179200/525306]\n",
      "loss: 1.134217  [180800/525306]\n",
      "loss: 0.184441  [182400/525306]\n",
      "loss: 0.536721  [184000/525306]\n",
      "loss: 0.844560  [185600/525306]\n",
      "loss: 1.144346  [187200/525306]\n",
      "loss: 0.570898  [188800/525306]\n",
      "loss: 1.116811  [190400/525306]\n",
      "loss: 1.012876  [192000/525306]\n",
      "loss: 0.502285  [193600/525306]\n",
      "loss: 0.477133  [195200/525306]\n",
      "loss: 0.829781  [196800/525306]\n",
      "loss: 1.065658  [198400/525306]\n",
      "loss: 0.555802  [200000/525306]\n",
      "loss: 0.399421  [201600/525306]\n",
      "loss: 1.182693  [203200/525306]\n",
      "loss: 0.821605  [204800/525306]\n",
      "loss: 0.729524  [206400/525306]\n",
      "loss: 0.634626  [208000/525306]\n",
      "loss: 0.865212  [209600/525306]\n",
      "loss: 0.648972  [211200/525306]\n",
      "loss: 0.987299  [212800/525306]\n",
      "loss: 0.709402  [214400/525306]\n",
      "loss: 1.346865  [216000/525306]\n",
      "loss: 0.791288  [217600/525306]\n",
      "loss: 0.549204  [219200/525306]\n",
      "loss: 0.749065  [220800/525306]\n",
      "loss: 0.611715  [222400/525306]\n",
      "loss: 1.122368  [224000/525306]\n",
      "loss: 1.341257  [225600/525306]\n",
      "loss: 0.325570  [227200/525306]\n",
      "loss: 0.755772  [228800/525306]\n",
      "loss: 0.517849  [230400/525306]\n",
      "loss: 0.305116  [232000/525306]\n",
      "loss: 0.864205  [233600/525306]\n",
      "loss: 0.893985  [235200/525306]\n",
      "loss: 1.038123  [236800/525306]\n",
      "loss: 0.536662  [238400/525306]\n",
      "loss: 0.735214  [240000/525306]\n",
      "loss: 0.917720  [241600/525306]\n",
      "loss: 0.447408  [243200/525306]\n",
      "loss: 0.866886  [244800/525306]\n",
      "loss: 0.958880  [246400/525306]\n",
      "loss: 0.690904  [248000/525306]\n",
      "loss: 0.709903  [249600/525306]\n",
      "loss: 1.474706  [251200/525306]\n",
      "loss: 0.897688  [252800/525306]\n",
      "loss: 1.123347  [254400/525306]\n",
      "loss: 0.667754  [256000/525306]\n",
      "loss: 0.754558  [257600/525306]\n",
      "loss: 1.174482  [259200/525306]\n",
      "loss: 1.061745  [260800/525306]\n",
      "loss: 0.626626  [262400/525306]\n",
      "loss: 0.596516  [264000/525306]\n",
      "loss: 0.556689  [265600/525306]\n",
      "loss: 0.220950  [267200/525306]\n",
      "loss: 0.514541  [268800/525306]\n",
      "loss: 0.436286  [270400/525306]\n",
      "loss: 0.466964  [272000/525306]\n",
      "loss: 0.852805  [273600/525306]\n",
      "loss: 0.747568  [275200/525306]\n",
      "loss: 0.519587  [276800/525306]\n",
      "loss: 0.797195  [278400/525306]\n",
      "loss: 0.536667  [280000/525306]\n",
      "loss: 0.580130  [281600/525306]\n",
      "loss: 0.694402  [283200/525306]\n",
      "loss: 0.373515  [284800/525306]\n",
      "loss: 0.323085  [286400/525306]\n",
      "loss: 0.469796  [288000/525306]\n",
      "loss: 0.751333  [289600/525306]\n",
      "loss: 0.540710  [291200/525306]\n",
      "loss: 0.488920  [292800/525306]\n",
      "loss: 0.822057  [294400/525306]\n",
      "loss: 0.822083  [296000/525306]\n",
      "loss: 0.222017  [297600/525306]\n",
      "loss: 1.066616  [299200/525306]\n",
      "loss: 0.659127  [300800/525306]\n",
      "loss: 0.433940  [302400/525306]\n",
      "loss: 0.907136  [304000/525306]\n",
      "loss: 0.308110  [305600/525306]\n",
      "loss: 0.987344  [307200/525306]\n",
      "loss: 0.497651  [308800/525306]\n",
      "loss: 0.586918  [310400/525306]\n",
      "loss: 0.789467  [312000/525306]\n",
      "loss: 0.729316  [313600/525306]\n",
      "loss: 0.932903  [315200/525306]\n",
      "loss: 1.096297  [316800/525306]\n",
      "loss: 1.054844  [318400/525306]\n",
      "loss: 0.445385  [320000/525306]\n",
      "loss: 0.546591  [321600/525306]\n",
      "loss: 0.289509  [323200/525306]\n",
      "loss: 0.693915  [324800/525306]\n",
      "loss: 0.385620  [326400/525306]\n",
      "loss: 0.524899  [328000/525306]\n",
      "loss: 0.765386  [329600/525306]\n",
      "loss: 0.614536  [331200/525306]\n",
      "loss: 0.374667  [332800/525306]\n",
      "loss: 0.734548  [334400/525306]\n",
      "loss: 0.925092  [336000/525306]\n",
      "loss: 0.682924  [337600/525306]\n",
      "loss: 0.396258  [339200/525306]\n",
      "loss: 0.626240  [340800/525306]\n",
      "loss: 0.650253  [342400/525306]\n",
      "loss: 0.687163  [344000/525306]\n",
      "loss: 0.315330  [345600/525306]\n",
      "loss: 0.727922  [347200/525306]\n",
      "loss: 0.941404  [348800/525306]\n",
      "loss: 0.628536  [350400/525306]\n",
      "loss: 0.528192  [352000/525306]\n",
      "loss: 0.592404  [353600/525306]\n",
      "loss: 0.623037  [355200/525306]\n",
      "loss: 0.910411  [356800/525306]\n",
      "loss: 0.666834  [358400/525306]\n",
      "loss: 0.744618  [360000/525306]\n",
      "loss: 0.731521  [361600/525306]\n",
      "loss: 0.557794  [363200/525306]\n",
      "loss: 0.809898  [364800/525306]\n",
      "loss: 0.788332  [366400/525306]\n",
      "loss: 0.332130  [368000/525306]\n",
      "loss: 0.638960  [369600/525306]\n",
      "loss: 0.349591  [371200/525306]\n",
      "loss: 0.472481  [372800/525306]\n",
      "loss: 0.805854  [374400/525306]\n",
      "loss: 0.569537  [376000/525306]\n",
      "loss: 0.671293  [377600/525306]\n",
      "loss: 0.927633  [379200/525306]\n",
      "loss: 0.743056  [380800/525306]\n",
      "loss: 1.077455  [382400/525306]\n",
      "loss: 0.476508  [384000/525306]\n",
      "loss: 1.072359  [385600/525306]\n",
      "loss: 0.600142  [387200/525306]\n",
      "loss: 0.402043  [388800/525306]\n",
      "loss: 0.605178  [390400/525306]\n",
      "loss: 0.751278  [392000/525306]\n",
      "loss: 0.969246  [393600/525306]\n",
      "loss: 0.664851  [395200/525306]\n",
      "loss: 0.542897  [396800/525306]\n",
      "loss: 0.642711  [398400/525306]\n",
      "loss: 1.103538  [400000/525306]\n",
      "loss: 0.561912  [401600/525306]\n",
      "loss: 0.657094  [403200/525306]\n",
      "loss: 0.506529  [404800/525306]\n",
      "loss: 0.610010  [406400/525306]\n",
      "loss: 0.571168  [408000/525306]\n",
      "loss: 0.866796  [409600/525306]\n",
      "loss: 0.236887  [411200/525306]\n",
      "loss: 0.592746  [412800/525306]\n",
      "loss: 0.426545  [414400/525306]\n",
      "loss: 1.095271  [416000/525306]\n",
      "loss: 0.655861  [417600/525306]\n",
      "loss: 0.909437  [419200/525306]\n",
      "loss: 0.303670  [420800/525306]\n",
      "loss: 0.501281  [422400/525306]\n",
      "loss: 0.587724  [424000/525306]\n",
      "loss: 1.062141  [425600/525306]\n",
      "loss: 1.233162  [427200/525306]\n",
      "loss: 0.387318  [428800/525306]\n",
      "loss: 0.525791  [430400/525306]\n",
      "loss: 0.489622  [432000/525306]\n",
      "loss: 0.716628  [433600/525306]\n",
      "loss: 0.648251  [435200/525306]\n",
      "loss: 0.494418  [436800/525306]\n",
      "loss: 1.040271  [438400/525306]\n",
      "loss: 0.798247  [440000/525306]\n",
      "loss: 0.418966  [441600/525306]\n",
      "loss: 0.921767  [443200/525306]\n",
      "loss: 0.312491  [444800/525306]\n",
      "loss: 0.778487  [446400/525306]\n",
      "loss: 0.504461  [448000/525306]\n",
      "loss: 1.070281  [449600/525306]\n",
      "loss: 0.307251  [451200/525306]\n",
      "loss: 0.578476  [452800/525306]\n",
      "loss: 1.050350  [454400/525306]\n",
      "loss: 0.764510  [456000/525306]\n",
      "loss: 0.758072  [457600/525306]\n",
      "loss: 0.476014  [459200/525306]\n",
      "loss: 0.295970  [460800/525306]\n",
      "loss: 0.650630  [462400/525306]\n",
      "loss: 0.226584  [464000/525306]\n",
      "loss: 0.827666  [465600/525306]\n",
      "loss: 1.207983  [467200/525306]\n",
      "loss: 0.566106  [468800/525306]\n",
      "loss: 0.853885  [470400/525306]\n",
      "loss: 0.616704  [472000/525306]\n",
      "loss: 0.918918  [473600/525306]\n",
      "loss: 0.491844  [475200/525306]\n",
      "loss: 0.426407  [476800/525306]\n",
      "loss: 0.460699  [478400/525306]\n",
      "loss: 0.799765  [480000/525306]\n",
      "loss: 0.404924  [481600/525306]\n",
      "loss: 0.627190  [483200/525306]\n",
      "loss: 0.658502  [484800/525306]\n",
      "loss: 0.874482  [486400/525306]\n",
      "loss: 0.802709  [488000/525306]\n",
      "loss: 0.568316  [489600/525306]\n",
      "loss: 0.707855  [491200/525306]\n",
      "loss: 0.680516  [492800/525306]\n",
      "loss: 0.908045  [494400/525306]\n",
      "loss: 0.323741  [496000/525306]\n",
      "loss: 0.677344  [497600/525306]\n",
      "loss: 0.814900  [499200/525306]\n",
      "loss: 0.782007  [500800/525306]\n",
      "loss: 0.663595  [502400/525306]\n",
      "loss: 0.693443  [504000/525306]\n",
      "loss: 0.917402  [505600/525306]\n",
      "loss: 1.221462  [507200/525306]\n",
      "loss: 0.541064  [508800/525306]\n",
      "loss: 0.779595  [510400/525306]\n",
      "loss: 0.610736  [512000/525306]\n",
      "loss: 1.038091  [513600/525306]\n",
      "loss: 0.213230  [515200/525306]\n",
      "loss: 0.820286  [516800/525306]\n",
      "loss: 0.561422  [518400/525306]\n",
      "loss: 0.984553  [520000/525306]\n",
      "loss: 0.229817  [521600/525306]\n",
      "loss: 0.723722  [523200/525306]\n",
      "loss: 0.657606  [524800/525306]\n",
      "Train Accuracy: 73.0237%\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 0.906839, F1-score: 70.20%, Macro_F1-Score:  39.22%  \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.586042  [    0/525306]\n",
      "loss: 0.446148  [ 1600/525306]\n",
      "loss: 0.387000  [ 3200/525306]\n",
      "loss: 0.647427  [ 4800/525306]\n",
      "loss: 0.537589  [ 6400/525306]\n",
      "loss: 0.817570  [ 8000/525306]\n",
      "loss: 0.618325  [ 9600/525306]\n",
      "loss: 0.332733  [11200/525306]\n",
      "loss: 1.292651  [12800/525306]\n",
      "loss: 0.805780  [14400/525306]\n",
      "loss: 0.647589  [16000/525306]\n",
      "loss: 1.038409  [17600/525306]\n",
      "loss: 0.418689  [19200/525306]\n",
      "loss: 0.602013  [20800/525306]\n",
      "loss: 0.749084  [22400/525306]\n",
      "loss: 0.693491  [24000/525306]\n",
      "loss: 0.423109  [25600/525306]\n",
      "loss: 0.759138  [27200/525306]\n",
      "loss: 0.838028  [28800/525306]\n",
      "loss: 1.012184  [30400/525306]\n",
      "loss: 1.348795  [32000/525306]\n",
      "loss: 1.175077  [33600/525306]\n",
      "loss: 0.797503  [35200/525306]\n",
      "loss: 0.919129  [36800/525306]\n",
      "loss: 0.633549  [38400/525306]\n",
      "loss: 0.822376  [40000/525306]\n",
      "loss: 1.293219  [41600/525306]\n",
      "loss: 0.875982  [43200/525306]\n",
      "loss: 0.547104  [44800/525306]\n",
      "loss: 0.464682  [46400/525306]\n",
      "loss: 0.675778  [48000/525306]\n",
      "loss: 0.533547  [49600/525306]\n",
      "loss: 0.560535  [51200/525306]\n",
      "loss: 0.792190  [52800/525306]\n",
      "loss: 0.497474  [54400/525306]\n",
      "loss: 0.685324  [56000/525306]\n",
      "loss: 0.591162  [57600/525306]\n",
      "loss: 0.648610  [59200/525306]\n",
      "loss: 1.080385  [60800/525306]\n",
      "loss: 0.840154  [62400/525306]\n",
      "loss: 0.730868  [64000/525306]\n",
      "loss: 0.970812  [65600/525306]\n",
      "loss: 0.732458  [67200/525306]\n",
      "loss: 0.899523  [68800/525306]\n",
      "loss: 0.973193  [70400/525306]\n",
      "loss: 0.312711  [72000/525306]\n",
      "loss: 0.589571  [73600/525306]\n",
      "loss: 0.940340  [75200/525306]\n",
      "loss: 0.504572  [76800/525306]\n",
      "loss: 0.577732  [78400/525306]\n",
      "loss: 0.718104  [80000/525306]\n",
      "loss: 1.218318  [81600/525306]\n",
      "loss: 0.636858  [83200/525306]\n",
      "loss: 0.641472  [84800/525306]\n",
      "loss: 0.657398  [86400/525306]\n",
      "loss: 0.880068  [88000/525306]\n",
      "loss: 0.260701  [89600/525306]\n",
      "loss: 0.789997  [91200/525306]\n",
      "loss: 0.726097  [92800/525306]\n",
      "loss: 0.848524  [94400/525306]\n",
      "loss: 1.055884  [96000/525306]\n",
      "loss: 0.631218  [97600/525306]\n",
      "loss: 0.336362  [99200/525306]\n",
      "loss: 0.880724  [100800/525306]\n",
      "loss: 1.012702  [102400/525306]\n",
      "loss: 0.595877  [104000/525306]\n",
      "loss: 0.531043  [105600/525306]\n",
      "loss: 0.696428  [107200/525306]\n",
      "loss: 0.845528  [108800/525306]\n",
      "loss: 0.372201  [110400/525306]\n",
      "loss: 0.798986  [112000/525306]\n",
      "loss: 0.927224  [113600/525306]\n",
      "loss: 0.955187  [115200/525306]\n",
      "loss: 0.472465  [116800/525306]\n",
      "loss: 0.857509  [118400/525306]\n",
      "loss: 0.834713  [120000/525306]\n",
      "loss: 0.497196  [121600/525306]\n",
      "loss: 0.420435  [123200/525306]\n",
      "loss: 1.074369  [124800/525306]\n",
      "loss: 1.048042  [126400/525306]\n",
      "loss: 0.845471  [128000/525306]\n",
      "loss: 0.537644  [129600/525306]\n",
      "loss: 0.890192  [131200/525306]\n",
      "loss: 0.345416  [132800/525306]\n",
      "loss: 0.518809  [134400/525306]\n",
      "loss: 1.032067  [136000/525306]\n",
      "loss: 0.584160  [137600/525306]\n",
      "loss: 0.527571  [139200/525306]\n",
      "loss: 0.390608  [140800/525306]\n",
      "loss: 0.600214  [142400/525306]\n",
      "loss: 0.522265  [144000/525306]\n",
      "loss: 0.712102  [145600/525306]\n",
      "loss: 0.528859  [147200/525306]\n",
      "loss: 0.427123  [148800/525306]\n",
      "loss: 0.543393  [150400/525306]\n",
      "loss: 1.252361  [152000/525306]\n",
      "loss: 0.516338  [153600/525306]\n",
      "loss: 0.522284  [155200/525306]\n",
      "loss: 0.813263  [156800/525306]\n",
      "loss: 0.637916  [158400/525306]\n",
      "loss: 0.633283  [160000/525306]\n",
      "loss: 0.699730  [161600/525306]\n",
      "loss: 1.050245  [163200/525306]\n",
      "loss: 0.820647  [164800/525306]\n",
      "loss: 0.691328  [166400/525306]\n",
      "loss: 0.732856  [168000/525306]\n",
      "loss: 0.580163  [169600/525306]\n",
      "loss: 0.630276  [171200/525306]\n",
      "loss: 1.214406  [172800/525306]\n",
      "loss: 0.579394  [174400/525306]\n",
      "loss: 0.899251  [176000/525306]\n",
      "loss: 0.876529  [177600/525306]\n",
      "loss: 0.403284  [179200/525306]\n",
      "loss: 1.035300  [180800/525306]\n",
      "loss: 0.568430  [182400/525306]\n",
      "loss: 0.388144  [184000/525306]\n",
      "loss: 0.650390  [185600/525306]\n",
      "loss: 0.704695  [187200/525306]\n",
      "loss: 0.791457  [188800/525306]\n",
      "loss: 0.424466  [190400/525306]\n",
      "loss: 0.551209  [192000/525306]\n",
      "loss: 0.564085  [193600/525306]\n",
      "loss: 0.616941  [195200/525306]\n",
      "loss: 0.406640  [196800/525306]\n",
      "loss: 0.798250  [198400/525306]\n",
      "loss: 0.928525  [200000/525306]\n",
      "loss: 0.371778  [201600/525306]\n",
      "loss: 0.671353  [203200/525306]\n",
      "loss: 0.841090  [204800/525306]\n",
      "loss: 0.853311  [206400/525306]\n",
      "loss: 0.545225  [208000/525306]\n",
      "loss: 0.786205  [209600/525306]\n",
      "loss: 0.708403  [211200/525306]\n",
      "loss: 0.499497  [212800/525306]\n",
      "loss: 0.798790  [214400/525306]\n",
      "loss: 0.927680  [216000/525306]\n",
      "loss: 0.837679  [217600/525306]\n",
      "loss: 0.783123  [219200/525306]\n",
      "loss: 0.977253  [220800/525306]\n",
      "loss: 0.773069  [222400/525306]\n",
      "loss: 0.269537  [224000/525306]\n",
      "loss: 0.538866  [225600/525306]\n",
      "loss: 0.766900  [227200/525306]\n",
      "loss: 0.607395  [228800/525306]\n",
      "loss: 0.844856  [230400/525306]\n",
      "loss: 0.350840  [232000/525306]\n",
      "loss: 0.571375  [233600/525306]\n",
      "loss: 0.364233  [235200/525306]\n",
      "loss: 0.708999  [236800/525306]\n",
      "loss: 0.432876  [238400/525306]\n",
      "loss: 0.581520  [240000/525306]\n",
      "loss: 0.808036  [241600/525306]\n",
      "loss: 0.985318  [243200/525306]\n",
      "loss: 0.863293  [244800/525306]\n",
      "loss: 0.396331  [246400/525306]\n",
      "loss: 0.596389  [248000/525306]\n",
      "loss: 0.616407  [249600/525306]\n",
      "loss: 0.967428  [251200/525306]\n",
      "loss: 0.480049  [252800/525306]\n",
      "loss: 0.903877  [254400/525306]\n",
      "loss: 0.540755  [256000/525306]\n",
      "loss: 0.863251  [257600/525306]\n",
      "loss: 0.428536  [259200/525306]\n",
      "loss: 1.382462  [260800/525306]\n",
      "loss: 0.757369  [262400/525306]\n",
      "loss: 1.125516  [264000/525306]\n",
      "loss: 0.895310  [265600/525306]\n",
      "loss: 0.659560  [267200/525306]\n",
      "loss: 0.934792  [268800/525306]\n",
      "loss: 0.794944  [270400/525306]\n",
      "loss: 0.738611  [272000/525306]\n",
      "loss: 0.946668  [273600/525306]\n",
      "loss: 0.852423  [275200/525306]\n",
      "loss: 0.508596  [276800/525306]\n",
      "loss: 0.857481  [278400/525306]\n",
      "loss: 0.591552  [280000/525306]\n",
      "loss: 0.428178  [281600/525306]\n",
      "loss: 0.871250  [283200/525306]\n",
      "loss: 0.535485  [284800/525306]\n",
      "loss: 0.765330  [286400/525306]\n",
      "loss: 1.015859  [288000/525306]\n",
      "loss: 0.475349  [289600/525306]\n",
      "loss: 0.686753  [291200/525306]\n",
      "loss: 0.488865  [292800/525306]\n",
      "loss: 0.749108  [294400/525306]\n",
      "loss: 0.407004  [296000/525306]\n",
      "loss: 0.394433  [297600/525306]\n",
      "loss: 0.629552  [299200/525306]\n",
      "loss: 0.935219  [300800/525306]\n",
      "loss: 0.790063  [302400/525306]\n",
      "loss: 0.496760  [304000/525306]\n",
      "loss: 0.906652  [305600/525306]\n",
      "loss: 0.774185  [307200/525306]\n",
      "loss: 0.607109  [308800/525306]\n",
      "loss: 0.752182  [310400/525306]\n",
      "loss: 1.039706  [312000/525306]\n",
      "loss: 0.803396  [313600/525306]\n",
      "loss: 0.691665  [315200/525306]\n",
      "loss: 0.883181  [316800/525306]\n",
      "loss: 0.535837  [318400/525306]\n",
      "loss: 0.798332  [320000/525306]\n",
      "loss: 0.485186  [321600/525306]\n",
      "loss: 0.862845  [323200/525306]\n",
      "loss: 0.638527  [324800/525306]\n",
      "loss: 0.742193  [326400/525306]\n",
      "loss: 0.588413  [328000/525306]\n",
      "loss: 0.825468  [329600/525306]\n",
      "loss: 0.502749  [331200/525306]\n",
      "loss: 0.727449  [332800/525306]\n",
      "loss: 0.813935  [334400/525306]\n",
      "loss: 0.756947  [336000/525306]\n",
      "loss: 0.621390  [337600/525306]\n",
      "loss: 0.934535  [339200/525306]\n",
      "loss: 0.279647  [340800/525306]\n",
      "loss: 0.960581  [342400/525306]\n",
      "loss: 0.582458  [344000/525306]\n",
      "loss: 0.977643  [345600/525306]\n",
      "loss: 1.031121  [347200/525306]\n",
      "loss: 0.709954  [348800/525306]\n",
      "loss: 0.350825  [350400/525306]\n",
      "loss: 0.620835  [352000/525306]\n",
      "loss: 0.651378  [353600/525306]\n",
      "loss: 0.943125  [355200/525306]\n",
      "loss: 0.823688  [356800/525306]\n",
      "loss: 0.600127  [358400/525306]\n",
      "loss: 0.507081  [360000/525306]\n",
      "loss: 0.864721  [361600/525306]\n",
      "loss: 0.661895  [363200/525306]\n",
      "loss: 0.707195  [364800/525306]\n",
      "loss: 0.435310  [366400/525306]\n",
      "loss: 0.509865  [368000/525306]\n",
      "loss: 0.387529  [369600/525306]\n",
      "loss: 0.402029  [371200/525306]\n",
      "loss: 0.657988  [372800/525306]\n",
      "loss: 0.758257  [374400/525306]\n",
      "loss: 0.971866  [376000/525306]\n",
      "loss: 0.332517  [377600/525306]\n",
      "loss: 1.139507  [379200/525306]\n",
      "loss: 0.638142  [380800/525306]\n",
      "loss: 0.510119  [382400/525306]\n",
      "loss: 0.590700  [384000/525306]\n",
      "loss: 0.382971  [385600/525306]\n",
      "loss: 0.709891  [387200/525306]\n",
      "loss: 0.649148  [388800/525306]\n",
      "loss: 0.631239  [390400/525306]\n",
      "loss: 0.398446  [392000/525306]\n",
      "loss: 1.132441  [393600/525306]\n",
      "loss: 0.669892  [395200/525306]\n",
      "loss: 0.666078  [396800/525306]\n",
      "loss: 0.777122  [398400/525306]\n",
      "loss: 0.691227  [400000/525306]\n",
      "loss: 0.510572  [401600/525306]\n",
      "loss: 0.520127  [403200/525306]\n",
      "loss: 0.639638  [404800/525306]\n",
      "loss: 0.579462  [406400/525306]\n",
      "loss: 0.559583  [408000/525306]\n",
      "loss: 0.607585  [409600/525306]\n",
      "loss: 0.648140  [411200/525306]\n",
      "loss: 1.043237  [412800/525306]\n",
      "loss: 0.717739  [414400/525306]\n",
      "loss: 0.679309  [416000/525306]\n",
      "loss: 0.460007  [417600/525306]\n",
      "loss: 0.461911  [419200/525306]\n",
      "loss: 0.919562  [420800/525306]\n",
      "loss: 0.553501  [422400/525306]\n",
      "loss: 0.632970  [424000/525306]\n",
      "loss: 0.449198  [425600/525306]\n",
      "loss: 1.038091  [427200/525306]\n",
      "loss: 0.775669  [428800/525306]\n",
      "loss: 0.897121  [430400/525306]\n",
      "loss: 1.090652  [432000/525306]\n",
      "loss: 0.580002  [433600/525306]\n",
      "loss: 0.467267  [435200/525306]\n",
      "loss: 0.471562  [436800/525306]\n",
      "loss: 0.954963  [438400/525306]\n",
      "loss: 0.419883  [440000/525306]\n",
      "loss: 0.728925  [441600/525306]\n",
      "loss: 0.706480  [443200/525306]\n",
      "loss: 0.889740  [444800/525306]\n",
      "loss: 0.905828  [446400/525306]\n",
      "loss: 0.325227  [448000/525306]\n",
      "loss: 0.588923  [449600/525306]\n",
      "loss: 0.420746  [451200/525306]\n",
      "loss: 0.939373  [452800/525306]\n",
      "loss: 1.749145  [454400/525306]\n",
      "loss: 0.799652  [456000/525306]\n",
      "loss: 0.525812  [457600/525306]\n",
      "loss: 0.840347  [459200/525306]\n",
      "loss: 0.531741  [460800/525306]\n",
      "loss: 0.891454  [462400/525306]\n",
      "loss: 0.587073  [464000/525306]\n",
      "loss: 0.756127  [465600/525306]\n",
      "loss: 0.862595  [467200/525306]\n",
      "loss: 0.482141  [468800/525306]\n",
      "loss: 0.470601  [470400/525306]\n",
      "loss: 0.335320  [472000/525306]\n",
      "loss: 0.241102  [473600/525306]\n",
      "loss: 0.767318  [475200/525306]\n",
      "loss: 0.398899  [476800/525306]\n",
      "loss: 0.812718  [478400/525306]\n",
      "loss: 0.410023  [480000/525306]\n",
      "loss: 0.917884  [481600/525306]\n",
      "loss: 0.839498  [483200/525306]\n",
      "loss: 1.019139  [484800/525306]\n",
      "loss: 0.860633  [486400/525306]\n",
      "loss: 1.234870  [488000/525306]\n",
      "loss: 1.183791  [489600/525306]\n",
      "loss: 0.619947  [491200/525306]\n",
      "loss: 0.648383  [492800/525306]\n",
      "loss: 0.962442  [494400/525306]\n",
      "loss: 0.830303  [496000/525306]\n",
      "loss: 0.542870  [497600/525306]\n",
      "loss: 1.149960  [499200/525306]\n",
      "loss: 0.746741  [500800/525306]\n",
      "loss: 0.517370  [502400/525306]\n",
      "loss: 0.527811  [504000/525306]\n",
      "loss: 0.527464  [505600/525306]\n",
      "loss: 0.713941  [507200/525306]\n",
      "loss: 0.688566  [508800/525306]\n",
      "loss: 0.343439  [510400/525306]\n",
      "loss: 0.650186  [512000/525306]\n",
      "loss: 0.605567  [513600/525306]\n",
      "loss: 0.991334  [515200/525306]\n",
      "loss: 0.651111  [516800/525306]\n",
      "loss: 0.778107  [518400/525306]\n",
      "loss: 0.756713  [520000/525306]\n",
      "loss: 0.684098  [521600/525306]\n",
      "loss: 0.842299  [523200/525306]\n",
      "loss: 0.744877  [524800/525306]\n",
      "Train Accuracy: 73.0833%\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.867415, F1-score: 70.31%, Macro_F1-Score:  39.17%  \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.891631  [    0/525306]\n",
      "loss: 0.645307  [ 1600/525306]\n",
      "loss: 0.612432  [ 3200/525306]\n",
      "loss: 0.855212  [ 4800/525306]\n",
      "loss: 1.034669  [ 6400/525306]\n",
      "loss: 0.893499  [ 8000/525306]\n",
      "loss: 0.622955  [ 9600/525306]\n",
      "loss: 0.847797  [11200/525306]\n",
      "loss: 1.079374  [12800/525306]\n",
      "loss: 0.592121  [14400/525306]\n",
      "loss: 1.022668  [16000/525306]\n",
      "loss: 0.703213  [17600/525306]\n",
      "loss: 0.927976  [19200/525306]\n",
      "loss: 0.449783  [20800/525306]\n",
      "loss: 0.238669  [22400/525306]\n",
      "loss: 0.683198  [24000/525306]\n",
      "loss: 0.488187  [25600/525306]\n",
      "loss: 0.513009  [27200/525306]\n",
      "loss: 0.616962  [28800/525306]\n",
      "loss: 0.745365  [30400/525306]\n",
      "loss: 0.585088  [32000/525306]\n",
      "loss: 0.497035  [33600/525306]\n",
      "loss: 0.566333  [35200/525306]\n",
      "loss: 0.664855  [36800/525306]\n",
      "loss: 0.541312  [38400/525306]\n",
      "loss: 0.680894  [40000/525306]\n",
      "loss: 0.489465  [41600/525306]\n",
      "loss: 0.552033  [43200/525306]\n",
      "loss: 0.279974  [44800/525306]\n",
      "loss: 0.607972  [46400/525306]\n",
      "loss: 0.892183  [48000/525306]\n",
      "loss: 0.750725  [49600/525306]\n",
      "loss: 0.555121  [51200/525306]\n",
      "loss: 0.757418  [52800/525306]\n",
      "loss: 0.614906  [54400/525306]\n",
      "loss: 0.834031  [56000/525306]\n",
      "loss: 1.112120  [57600/525306]\n",
      "loss: 0.992560  [59200/525306]\n",
      "loss: 0.793258  [60800/525306]\n",
      "loss: 0.737019  [62400/525306]\n",
      "loss: 0.462064  [64000/525306]\n",
      "loss: 0.705014  [65600/525306]\n",
      "loss: 0.534624  [67200/525306]\n",
      "loss: 0.779543  [68800/525306]\n",
      "loss: 0.693011  [70400/525306]\n",
      "loss: 1.197083  [72000/525306]\n",
      "loss: 0.949064  [73600/525306]\n",
      "loss: 0.712124  [75200/525306]\n",
      "loss: 1.120089  [76800/525306]\n",
      "loss: 0.651309  [78400/525306]\n",
      "loss: 0.355039  [80000/525306]\n",
      "loss: 0.831355  [81600/525306]\n",
      "loss: 0.542357  [83200/525306]\n",
      "loss: 0.769217  [84800/525306]\n",
      "loss: 0.942517  [86400/525306]\n",
      "loss: 0.559248  [88000/525306]\n",
      "loss: 1.481570  [89600/525306]\n",
      "loss: 0.228249  [91200/525306]\n",
      "loss: 0.563322  [92800/525306]\n",
      "loss: 0.545305  [94400/525306]\n",
      "loss: 0.797756  [96000/525306]\n",
      "loss: 0.979315  [97600/525306]\n",
      "loss: 0.923424  [99200/525306]\n",
      "loss: 0.666460  [100800/525306]\n",
      "loss: 0.721538  [102400/525306]\n",
      "loss: 1.239131  [104000/525306]\n",
      "loss: 0.514758  [105600/525306]\n",
      "loss: 0.821277  [107200/525306]\n",
      "loss: 1.097646  [108800/525306]\n",
      "loss: 0.521052  [110400/525306]\n",
      "loss: 0.608664  [112000/525306]\n",
      "loss: 0.945556  [113600/525306]\n",
      "loss: 0.746483  [115200/525306]\n",
      "loss: 0.943096  [116800/525306]\n",
      "loss: 0.893464  [118400/525306]\n",
      "loss: 0.552688  [120000/525306]\n",
      "loss: 0.907479  [121600/525306]\n",
      "loss: 0.388176  [123200/525306]\n",
      "loss: 0.428291  [124800/525306]\n",
      "loss: 0.992349  [126400/525306]\n",
      "loss: 1.007450  [128000/525306]\n",
      "loss: 0.572530  [129600/525306]\n",
      "loss: 0.728005  [131200/525306]\n",
      "loss: 0.788542  [132800/525306]\n",
      "loss: 0.616690  [134400/525306]\n",
      "loss: 0.691508  [136000/525306]\n",
      "loss: 0.462825  [137600/525306]\n",
      "loss: 0.784065  [139200/525306]\n",
      "loss: 0.383841  [140800/525306]\n",
      "loss: 0.560070  [142400/525306]\n",
      "loss: 0.446525  [144000/525306]\n",
      "loss: 0.795525  [145600/525306]\n",
      "loss: 0.570215  [147200/525306]\n",
      "loss: 0.780726  [148800/525306]\n",
      "loss: 0.378891  [150400/525306]\n",
      "loss: 0.713274  [152000/525306]\n",
      "loss: 0.615327  [153600/525306]\n",
      "loss: 0.334270  [155200/525306]\n",
      "loss: 1.338837  [156800/525306]\n",
      "loss: 0.667287  [158400/525306]\n",
      "loss: 0.432217  [160000/525306]\n",
      "loss: 0.417355  [161600/525306]\n",
      "loss: 0.556847  [163200/525306]\n",
      "loss: 0.432459  [164800/525306]\n",
      "loss: 0.885082  [166400/525306]\n",
      "loss: 0.719592  [168000/525306]\n",
      "loss: 0.258722  [169600/525306]\n",
      "loss: 0.561685  [171200/525306]\n",
      "loss: 0.678495  [172800/525306]\n",
      "loss: 0.830256  [174400/525306]\n",
      "loss: 0.287433  [176000/525306]\n",
      "loss: 0.845485  [177600/525306]\n",
      "loss: 1.404297  [179200/525306]\n",
      "loss: 0.428329  [180800/525306]\n",
      "loss: 1.127255  [182400/525306]\n",
      "loss: 0.400258  [184000/525306]\n",
      "loss: 0.863394  [185600/525306]\n",
      "loss: 0.758225  [187200/525306]\n",
      "loss: 0.505241  [188800/525306]\n",
      "loss: 0.846733  [190400/525306]\n",
      "loss: 0.426096  [192000/525306]\n",
      "loss: 0.419729  [193600/525306]\n",
      "loss: 0.695233  [195200/525306]\n",
      "loss: 1.221457  [196800/525306]\n",
      "loss: 0.880965  [198400/525306]\n",
      "loss: 0.680023  [200000/525306]\n",
      "loss: 0.991628  [201600/525306]\n",
      "loss: 0.476963  [203200/525306]\n",
      "loss: 0.623075  [204800/525306]\n",
      "loss: 1.010906  [206400/525306]\n",
      "loss: 0.692231  [208000/525306]\n",
      "loss: 0.521637  [209600/525306]\n",
      "loss: 0.993074  [211200/525306]\n",
      "loss: 0.956276  [212800/525306]\n",
      "loss: 1.026106  [214400/525306]\n",
      "loss: 0.428092  [216000/525306]\n",
      "loss: 0.415125  [217600/525306]\n",
      "loss: 1.186152  [219200/525306]\n",
      "loss: 0.650617  [220800/525306]\n",
      "loss: 0.401278  [222400/525306]\n",
      "loss: 0.665250  [224000/525306]\n",
      "loss: 0.557312  [225600/525306]\n",
      "loss: 0.640747  [227200/525306]\n",
      "loss: 0.816173  [228800/525306]\n",
      "loss: 0.545148  [230400/525306]\n",
      "loss: 0.559382  [232000/525306]\n",
      "loss: 0.679793  [233600/525306]\n",
      "loss: 0.805057  [235200/525306]\n",
      "loss: 1.206135  [236800/525306]\n",
      "loss: 0.494259  [238400/525306]\n",
      "loss: 0.720290  [240000/525306]\n",
      "loss: 0.487595  [241600/525306]\n",
      "loss: 0.903598  [243200/525306]\n",
      "loss: 0.642263  [244800/525306]\n",
      "loss: 0.912083  [246400/525306]\n",
      "loss: 0.703337  [248000/525306]\n",
      "loss: 0.649689  [249600/525306]\n",
      "loss: 0.391482  [251200/525306]\n",
      "loss: 0.605593  [252800/525306]\n",
      "loss: 0.905970  [254400/525306]\n",
      "loss: 0.727755  [256000/525306]\n",
      "loss: 0.714007  [257600/525306]\n",
      "loss: 0.719405  [259200/525306]\n",
      "loss: 0.825336  [260800/525306]\n",
      "loss: 0.645952  [262400/525306]\n",
      "loss: 0.468073  [264000/525306]\n",
      "loss: 0.881567  [265600/525306]\n",
      "loss: 0.941048  [267200/525306]\n",
      "loss: 0.361160  [268800/525306]\n",
      "loss: 0.741827  [270400/525306]\n",
      "loss: 0.646865  [272000/525306]\n",
      "loss: 0.213501  [273600/525306]\n",
      "loss: 0.630996  [275200/525306]\n",
      "loss: 0.316863  [276800/525306]\n",
      "loss: 0.656943  [278400/525306]\n",
      "loss: 0.826988  [280000/525306]\n",
      "loss: 0.699529  [281600/525306]\n",
      "loss: 0.541471  [283200/525306]\n",
      "loss: 0.506528  [284800/525306]\n",
      "loss: 0.371413  [286400/525306]\n",
      "loss: 0.385816  [288000/525306]\n",
      "loss: 0.575041  [289600/525306]\n",
      "loss: 0.951036  [291200/525306]\n",
      "loss: 0.419743  [292800/525306]\n",
      "loss: 0.604845  [294400/525306]\n",
      "loss: 0.974692  [296000/525306]\n",
      "loss: 0.423998  [297600/525306]\n",
      "loss: 0.830696  [299200/525306]\n",
      "loss: 0.626270  [300800/525306]\n",
      "loss: 0.290783  [302400/525306]\n",
      "loss: 0.247467  [304000/525306]\n",
      "loss: 0.815921  [305600/525306]\n",
      "loss: 0.412669  [307200/525306]\n",
      "loss: 0.685294  [308800/525306]\n",
      "loss: 0.263362  [310400/525306]\n",
      "loss: 0.535066  [312000/525306]\n",
      "loss: 0.773812  [313600/525306]\n",
      "loss: 0.871216  [315200/525306]\n",
      "loss: 1.386316  [316800/525306]\n",
      "loss: 0.372113  [318400/525306]\n",
      "loss: 0.833860  [320000/525306]\n",
      "loss: 0.935183  [321600/525306]\n",
      "loss: 0.415975  [323200/525306]\n",
      "loss: 0.643023  [324800/525306]\n",
      "loss: 0.512144  [326400/525306]\n",
      "loss: 0.407686  [328000/525306]\n",
      "loss: 0.557456  [329600/525306]\n",
      "loss: 0.681062  [331200/525306]\n",
      "loss: 0.354994  [332800/525306]\n",
      "loss: 0.659294  [334400/525306]\n",
      "loss: 0.325821  [336000/525306]\n",
      "loss: 0.482794  [337600/525306]\n",
      "loss: 0.447599  [339200/525306]\n",
      "loss: 0.504628  [340800/525306]\n",
      "loss: 1.114504  [342400/525306]\n",
      "loss: 0.960795  [344000/525306]\n",
      "loss: 0.674831  [345600/525306]\n",
      "loss: 0.495064  [347200/525306]\n",
      "loss: 0.891603  [348800/525306]\n",
      "loss: 0.726759  [350400/525306]\n",
      "loss: 0.490540  [352000/525306]\n",
      "loss: 0.809580  [353600/525306]\n",
      "loss: 0.496456  [355200/525306]\n",
      "loss: 0.437992  [356800/525306]\n",
      "loss: 0.781251  [358400/525306]\n",
      "loss: 0.832828  [360000/525306]\n",
      "loss: 0.855050  [361600/525306]\n",
      "loss: 0.433283  [363200/525306]\n",
      "loss: 1.165308  [364800/525306]\n",
      "loss: 0.699735  [366400/525306]\n",
      "loss: 0.727003  [368000/525306]\n",
      "loss: 0.753419  [369600/525306]\n",
      "loss: 1.075700  [371200/525306]\n",
      "loss: 0.663024  [372800/525306]\n",
      "loss: 0.784910  [374400/525306]\n",
      "loss: 0.725267  [376000/525306]\n",
      "loss: 0.526405  [377600/525306]\n",
      "loss: 0.738891  [379200/525306]\n",
      "loss: 0.608062  [380800/525306]\n",
      "loss: 0.486557  [382400/525306]\n",
      "loss: 0.839964  [384000/525306]\n",
      "loss: 0.628897  [385600/525306]\n",
      "loss: 0.666699  [387200/525306]\n",
      "loss: 0.490995  [388800/525306]\n",
      "loss: 0.462343  [390400/525306]\n",
      "loss: 0.775301  [392000/525306]\n",
      "loss: 0.941407  [393600/525306]\n",
      "loss: 0.771045  [395200/525306]\n",
      "loss: 0.837528  [396800/525306]\n",
      "loss: 0.361799  [398400/525306]\n",
      "loss: 0.406151  [400000/525306]\n",
      "loss: 0.861691  [401600/525306]\n",
      "loss: 0.422625  [403200/525306]\n",
      "loss: 0.955992  [404800/525306]\n",
      "loss: 0.616392  [406400/525306]\n",
      "loss: 0.730237  [408000/525306]\n",
      "loss: 0.343282  [409600/525306]\n",
      "loss: 0.433586  [411200/525306]\n",
      "loss: 0.654557  [412800/525306]\n",
      "loss: 0.593394  [414400/525306]\n",
      "loss: 0.569551  [416000/525306]\n",
      "loss: 0.610020  [417600/525306]\n",
      "loss: 0.575323  [419200/525306]\n",
      "loss: 1.314983  [420800/525306]\n",
      "loss: 0.738767  [422400/525306]\n",
      "loss: 0.277339  [424000/525306]\n",
      "loss: 0.486168  [425600/525306]\n",
      "loss: 0.544374  [427200/525306]\n",
      "loss: 0.838406  [428800/525306]\n",
      "loss: 0.716171  [430400/525306]\n",
      "loss: 0.545429  [432000/525306]\n",
      "loss: 0.652419  [433600/525306]\n",
      "loss: 0.461834  [435200/525306]\n",
      "loss: 0.761801  [436800/525306]\n",
      "loss: 0.714584  [438400/525306]\n",
      "loss: 0.590415  [440000/525306]\n",
      "loss: 0.506792  [441600/525306]\n",
      "loss: 0.503535  [443200/525306]\n",
      "loss: 1.169616  [444800/525306]\n",
      "loss: 0.612595  [446400/525306]\n",
      "loss: 0.637232  [448000/525306]\n",
      "loss: 1.099505  [449600/525306]\n",
      "loss: 0.745561  [451200/525306]\n",
      "loss: 0.734802  [452800/525306]\n",
      "loss: 0.877155  [454400/525306]\n",
      "loss: 0.420625  [456000/525306]\n",
      "loss: 0.642927  [457600/525306]\n",
      "loss: 0.749438  [459200/525306]\n",
      "loss: 0.770167  [460800/525306]\n",
      "loss: 0.672688  [462400/525306]\n",
      "loss: 1.125173  [464000/525306]\n",
      "loss: 0.646727  [465600/525306]\n",
      "loss: 1.174254  [467200/525306]\n",
      "loss: 0.587886  [468800/525306]\n",
      "loss: 0.775042  [470400/525306]\n",
      "loss: 0.743481  [472000/525306]\n",
      "loss: 0.566802  [473600/525306]\n",
      "loss: 0.973074  [475200/525306]\n",
      "loss: 0.963005  [476800/525306]\n",
      "loss: 0.492072  [478400/525306]\n",
      "loss: 1.013511  [480000/525306]\n",
      "loss: 0.517330  [481600/525306]\n",
      "loss: 0.591519  [483200/525306]\n",
      "loss: 0.752184  [484800/525306]\n",
      "loss: 0.852341  [486400/525306]\n",
      "loss: 0.633684  [488000/525306]\n",
      "loss: 0.702272  [489600/525306]\n",
      "loss: 0.420721  [491200/525306]\n",
      "loss: 0.438292  [492800/525306]\n",
      "loss: 1.099088  [494400/525306]\n",
      "loss: 0.857429  [496000/525306]\n",
      "loss: 0.586665  [497600/525306]\n",
      "loss: 0.498378  [499200/525306]\n",
      "loss: 0.812645  [500800/525306]\n",
      "loss: 0.518884  [502400/525306]\n",
      "loss: 0.593017  [504000/525306]\n",
      "loss: 0.826082  [505600/525306]\n",
      "loss: 0.621382  [507200/525306]\n",
      "loss: 0.667769  [508800/525306]\n",
      "loss: 0.482444  [510400/525306]\n",
      "loss: 0.720777  [512000/525306]\n",
      "loss: 0.772645  [513600/525306]\n",
      "loss: 0.470671  [515200/525306]\n",
      "loss: 0.497656  [516800/525306]\n",
      "loss: 0.540351  [518400/525306]\n",
      "loss: 0.963766  [520000/525306]\n",
      "loss: 0.627024  [521600/525306]\n",
      "loss: 1.067456  [523200/525306]\n",
      "loss: 0.614451  [524800/525306]\n",
      "Train Accuracy: 73.1977%\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 0.895778, F1-score: 70.28%, Macro_F1-Score:  39.57%  \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.080624  [    0/525306]\n",
      "loss: 0.574674  [ 1600/525306]\n",
      "loss: 0.544802  [ 3200/525306]\n",
      "loss: 0.835794  [ 4800/525306]\n",
      "loss: 0.530834  [ 6400/525306]\n",
      "loss: 0.664243  [ 8000/525306]\n",
      "loss: 0.405912  [ 9600/525306]\n",
      "loss: 1.192335  [11200/525306]\n",
      "loss: 0.923596  [12800/525306]\n",
      "loss: 1.100074  [14400/525306]\n",
      "loss: 0.883660  [16000/525306]\n",
      "loss: 0.569995  [17600/525306]\n",
      "loss: 1.002151  [19200/525306]\n",
      "loss: 1.325672  [20800/525306]\n",
      "loss: 0.842175  [22400/525306]\n",
      "loss: 0.752436  [24000/525306]\n",
      "loss: 0.925203  [25600/525306]\n",
      "loss: 0.634076  [27200/525306]\n",
      "loss: 0.761710  [28800/525306]\n",
      "loss: 0.733209  [30400/525306]\n",
      "loss: 0.455245  [32000/525306]\n",
      "loss: 0.428682  [33600/525306]\n",
      "loss: 0.157048  [35200/525306]\n",
      "loss: 0.479371  [36800/525306]\n",
      "loss: 0.587079  [38400/525306]\n",
      "loss: 0.885471  [40000/525306]\n",
      "loss: 0.635733  [41600/525306]\n",
      "loss: 0.551599  [43200/525306]\n",
      "loss: 0.677178  [44800/525306]\n",
      "loss: 0.932581  [46400/525306]\n",
      "loss: 0.778504  [48000/525306]\n",
      "loss: 0.413755  [49600/525306]\n",
      "loss: 0.495495  [51200/525306]\n",
      "loss: 0.747821  [52800/525306]\n",
      "loss: 0.568899  [54400/525306]\n",
      "loss: 0.695813  [56000/525306]\n",
      "loss: 1.097475  [57600/525306]\n",
      "loss: 0.555244  [59200/525306]\n",
      "loss: 0.964757  [60800/525306]\n",
      "loss: 0.606472  [62400/525306]\n",
      "loss: 0.599459  [64000/525306]\n",
      "loss: 0.740739  [65600/525306]\n",
      "loss: 0.826136  [67200/525306]\n",
      "loss: 0.514210  [68800/525306]\n",
      "loss: 0.512460  [70400/525306]\n",
      "loss: 0.607523  [72000/525306]\n",
      "loss: 0.779217  [73600/525306]\n",
      "loss: 0.633948  [75200/525306]\n",
      "loss: 0.750030  [76800/525306]\n",
      "loss: 0.660148  [78400/525306]\n",
      "loss: 0.555993  [80000/525306]\n",
      "loss: 0.455699  [81600/525306]\n",
      "loss: 1.308365  [83200/525306]\n",
      "loss: 0.617447  [84800/525306]\n",
      "loss: 0.550127  [86400/525306]\n",
      "loss: 0.660124  [88000/525306]\n",
      "loss: 0.466558  [89600/525306]\n",
      "loss: 1.310338  [91200/525306]\n",
      "loss: 0.424821  [92800/525306]\n",
      "loss: 0.409500  [94400/525306]\n",
      "loss: 0.484410  [96000/525306]\n",
      "loss: 0.913849  [97600/525306]\n",
      "loss: 0.510310  [99200/525306]\n",
      "loss: 0.477996  [100800/525306]\n",
      "loss: 0.642697  [102400/525306]\n",
      "loss: 0.650819  [104000/525306]\n",
      "loss: 0.985095  [105600/525306]\n",
      "loss: 0.842240  [107200/525306]\n",
      "loss: 0.592194  [108800/525306]\n",
      "loss: 0.886096  [110400/525306]\n",
      "loss: 0.707093  [112000/525306]\n",
      "loss: 0.793904  [113600/525306]\n",
      "loss: 0.648350  [115200/525306]\n",
      "loss: 0.607518  [116800/525306]\n",
      "loss: 0.439337  [118400/525306]\n",
      "loss: 0.510698  [120000/525306]\n",
      "loss: 0.566335  [121600/525306]\n",
      "loss: 0.648770  [123200/525306]\n",
      "loss: 0.256224  [124800/525306]\n",
      "loss: 1.190259  [126400/525306]\n",
      "loss: 0.692584  [128000/525306]\n",
      "loss: 0.789944  [129600/525306]\n",
      "loss: 0.730751  [131200/525306]\n",
      "loss: 0.691156  [132800/525306]\n",
      "loss: 1.153239  [134400/525306]\n",
      "loss: 1.030020  [136000/525306]\n",
      "loss: 0.601467  [137600/525306]\n",
      "loss: 0.764424  [139200/525306]\n",
      "loss: 1.278483  [140800/525306]\n",
      "loss: 1.024284  [142400/525306]\n",
      "loss: 0.780240  [144000/525306]\n",
      "loss: 0.797195  [145600/525306]\n",
      "loss: 0.767974  [147200/525306]\n",
      "loss: 0.606964  [148800/525306]\n",
      "loss: 1.212086  [150400/525306]\n",
      "loss: 0.627277  [152000/525306]\n",
      "loss: 0.985152  [153600/525306]\n",
      "loss: 0.651497  [155200/525306]\n",
      "loss: 0.583929  [156800/525306]\n",
      "loss: 0.630341  [158400/525306]\n",
      "loss: 0.563444  [160000/525306]\n",
      "loss: 0.511999  [161600/525306]\n",
      "loss: 1.206052  [163200/525306]\n",
      "loss: 0.436185  [164800/525306]\n",
      "loss: 0.716605  [166400/525306]\n",
      "loss: 0.389629  [168000/525306]\n",
      "loss: 0.537985  [169600/525306]\n",
      "loss: 1.100717  [171200/525306]\n",
      "loss: 0.355487  [172800/525306]\n",
      "loss: 0.969199  [174400/525306]\n",
      "loss: 0.852603  [176000/525306]\n",
      "loss: 0.474898  [177600/525306]\n",
      "loss: 0.571890  [179200/525306]\n",
      "loss: 0.533996  [180800/525306]\n",
      "loss: 0.699535  [182400/525306]\n",
      "loss: 1.052649  [184000/525306]\n",
      "loss: 0.843203  [185600/525306]\n",
      "loss: 0.610044  [187200/525306]\n",
      "loss: 0.317085  [188800/525306]\n",
      "loss: 0.837999  [190400/525306]\n",
      "loss: 0.767741  [192000/525306]\n",
      "loss: 0.489202  [193600/525306]\n",
      "loss: 0.819843  [195200/525306]\n",
      "loss: 0.467943  [196800/525306]\n",
      "loss: 1.137258  [198400/525306]\n",
      "loss: 1.146088  [200000/525306]\n",
      "loss: 0.611880  [201600/525306]\n",
      "loss: 0.661600  [203200/525306]\n",
      "loss: 0.674411  [204800/525306]\n",
      "loss: 0.809710  [206400/525306]\n",
      "loss: 1.115267  [208000/525306]\n",
      "loss: 0.790701  [209600/525306]\n",
      "loss: 0.852040  [211200/525306]\n",
      "loss: 0.366717  [212800/525306]\n",
      "loss: 0.834445  [214400/525306]\n",
      "loss: 1.073851  [216000/525306]\n",
      "loss: 0.836905  [217600/525306]\n",
      "loss: 0.576836  [219200/525306]\n",
      "loss: 0.907535  [220800/525306]\n",
      "loss: 0.438248  [222400/525306]\n",
      "loss: 0.559717  [224000/525306]\n",
      "loss: 1.085463  [225600/525306]\n",
      "loss: 0.794616  [227200/525306]\n",
      "loss: 0.845056  [228800/525306]\n",
      "loss: 0.417203  [230400/525306]\n",
      "loss: 0.383023  [232000/525306]\n",
      "loss: 0.761868  [233600/525306]\n",
      "loss: 0.521825  [235200/525306]\n",
      "loss: 0.829091  [236800/525306]\n",
      "loss: 0.902292  [238400/525306]\n",
      "loss: 0.532154  [240000/525306]\n",
      "loss: 0.749956  [241600/525306]\n",
      "loss: 0.668245  [243200/525306]\n",
      "loss: 0.651358  [244800/525306]\n",
      "loss: 0.207317  [246400/525306]\n",
      "loss: 0.531214  [248000/525306]\n",
      "loss: 0.597427  [249600/525306]\n",
      "loss: 0.997177  [251200/525306]\n",
      "loss: 1.018700  [252800/525306]\n",
      "loss: 0.577621  [254400/525306]\n",
      "loss: 0.641016  [256000/525306]\n",
      "loss: 0.318500  [257600/525306]\n",
      "loss: 0.465705  [259200/525306]\n",
      "loss: 0.605410  [260800/525306]\n",
      "loss: 0.937556  [262400/525306]\n",
      "loss: 1.098541  [264000/525306]\n",
      "loss: 0.682660  [265600/525306]\n",
      "loss: 0.851395  [267200/525306]\n",
      "loss: 0.369695  [268800/525306]\n",
      "loss: 0.481727  [270400/525306]\n",
      "loss: 0.429234  [272000/525306]\n",
      "loss: 0.916261  [273600/525306]\n",
      "loss: 0.776296  [275200/525306]\n",
      "loss: 0.800546  [276800/525306]\n",
      "loss: 0.765533  [278400/525306]\n",
      "loss: 0.755887  [280000/525306]\n",
      "loss: 0.915361  [281600/525306]\n",
      "loss: 0.495258  [283200/525306]\n",
      "loss: 0.728648  [284800/525306]\n",
      "loss: 0.444229  [286400/525306]\n",
      "loss: 0.747216  [288000/525306]\n",
      "loss: 0.388865  [289600/525306]\n",
      "loss: 0.556571  [291200/525306]\n",
      "loss: 0.629613  [292800/525306]\n",
      "loss: 0.638847  [294400/525306]\n",
      "loss: 0.517709  [296000/525306]\n",
      "loss: 0.699851  [297600/525306]\n",
      "loss: 0.463479  [299200/525306]\n",
      "loss: 0.832147  [300800/525306]\n",
      "loss: 0.562225  [302400/525306]\n",
      "loss: 0.639977  [304000/525306]\n",
      "loss: 0.672436  [305600/525306]\n",
      "loss: 1.222925  [307200/525306]\n",
      "loss: 0.475030  [308800/525306]\n",
      "loss: 0.447923  [310400/525306]\n",
      "loss: 0.769731  [312000/525306]\n",
      "loss: 0.428661  [313600/525306]\n",
      "loss: 0.631962  [315200/525306]\n",
      "loss: 0.467361  [316800/525306]\n",
      "loss: 1.199001  [318400/525306]\n",
      "loss: 0.589543  [320000/525306]\n",
      "loss: 0.640897  [321600/525306]\n",
      "loss: 1.414716  [323200/525306]\n",
      "loss: 0.600360  [324800/525306]\n",
      "loss: 0.348783  [326400/525306]\n",
      "loss: 0.474720  [328000/525306]\n",
      "loss: 0.647169  [329600/525306]\n",
      "loss: 0.907515  [331200/525306]\n",
      "loss: 0.830943  [332800/525306]\n",
      "loss: 0.972857  [334400/525306]\n",
      "loss: 0.893001  [336000/525306]\n",
      "loss: 0.847160  [337600/525306]\n",
      "loss: 0.396495  [339200/525306]\n",
      "loss: 1.541181  [340800/525306]\n",
      "loss: 1.032637  [342400/525306]\n",
      "loss: 0.502681  [344000/525306]\n",
      "loss: 0.508032  [345600/525306]\n",
      "loss: 1.295266  [347200/525306]\n",
      "loss: 1.190168  [348800/525306]\n",
      "loss: 0.611010  [350400/525306]\n",
      "loss: 1.216230  [352000/525306]\n",
      "loss: 0.877726  [353600/525306]\n",
      "loss: 0.490445  [355200/525306]\n",
      "loss: 0.440068  [356800/525306]\n",
      "loss: 0.517204  [358400/525306]\n",
      "loss: 0.900783  [360000/525306]\n",
      "loss: 0.924695  [361600/525306]\n",
      "loss: 0.645711  [363200/525306]\n",
      "loss: 0.844749  [364800/525306]\n",
      "loss: 0.780340  [366400/525306]\n",
      "loss: 1.113445  [368000/525306]\n",
      "loss: 0.361255  [369600/525306]\n",
      "loss: 0.591309  [371200/525306]\n",
      "loss: 0.879197  [372800/525306]\n",
      "loss: 0.616660  [374400/525306]\n",
      "loss: 0.647932  [376000/525306]\n",
      "loss: 0.914650  [377600/525306]\n",
      "loss: 0.654173  [379200/525306]\n",
      "loss: 0.892661  [380800/525306]\n",
      "loss: 0.586542  [382400/525306]\n",
      "loss: 0.819471  [384000/525306]\n",
      "loss: 0.574432  [385600/525306]\n",
      "loss: 0.636787  [387200/525306]\n",
      "loss: 0.854780  [388800/525306]\n",
      "loss: 0.775287  [390400/525306]\n",
      "loss: 0.749761  [392000/525306]\n",
      "loss: 0.938282  [393600/525306]\n",
      "loss: 0.416523  [395200/525306]\n",
      "loss: 0.695746  [396800/525306]\n",
      "loss: 1.122378  [398400/525306]\n",
      "loss: 0.895034  [400000/525306]\n",
      "loss: 0.746129  [401600/525306]\n",
      "loss: 0.523164  [403200/525306]\n",
      "loss: 0.407961  [404800/525306]\n",
      "loss: 0.920901  [406400/525306]\n",
      "loss: 1.328970  [408000/525306]\n",
      "loss: 0.908425  [409600/525306]\n",
      "loss: 0.469651  [411200/525306]\n",
      "loss: 0.803597  [412800/525306]\n",
      "loss: 0.322726  [414400/525306]\n",
      "loss: 0.808257  [416000/525306]\n",
      "loss: 0.579877  [417600/525306]\n",
      "loss: 0.698939  [419200/525306]\n",
      "loss: 1.013261  [420800/525306]\n",
      "loss: 0.830818  [422400/525306]\n",
      "loss: 0.457451  [424000/525306]\n",
      "loss: 0.663134  [425600/525306]\n",
      "loss: 0.913882  [427200/525306]\n",
      "loss: 0.616592  [428800/525306]\n",
      "loss: 0.684011  [430400/525306]\n",
      "loss: 1.465298  [432000/525306]\n",
      "loss: 0.459392  [433600/525306]\n",
      "loss: 0.902576  [435200/525306]\n",
      "loss: 0.958841  [436800/525306]\n",
      "loss: 0.637739  [438400/525306]\n",
      "loss: 0.689196  [440000/525306]\n",
      "loss: 0.539291  [441600/525306]\n",
      "loss: 0.414561  [443200/525306]\n",
      "loss: 0.538950  [444800/525306]\n",
      "loss: 0.369745  [446400/525306]\n",
      "loss: 0.570835  [448000/525306]\n",
      "loss: 0.699438  [449600/525306]\n",
      "loss: 0.964479  [451200/525306]\n",
      "loss: 0.675124  [452800/525306]\n",
      "loss: 0.662645  [454400/525306]\n",
      "loss: 0.721798  [456000/525306]\n",
      "loss: 0.319306  [457600/525306]\n",
      "loss: 0.701204  [459200/525306]\n",
      "loss: 0.659073  [460800/525306]\n",
      "loss: 1.017067  [462400/525306]\n",
      "loss: 0.442236  [464000/525306]\n",
      "loss: 0.566595  [465600/525306]\n",
      "loss: 0.930853  [467200/525306]\n",
      "loss: 0.842473  [468800/525306]\n",
      "loss: 0.610130  [470400/525306]\n",
      "loss: 0.440873  [472000/525306]\n",
      "loss: 0.410067  [473600/525306]\n",
      "loss: 0.556836  [475200/525306]\n",
      "loss: 0.955061  [476800/525306]\n",
      "loss: 0.823204  [478400/525306]\n",
      "loss: 0.726161  [480000/525306]\n",
      "loss: 0.645042  [481600/525306]\n",
      "loss: 0.534993  [483200/525306]\n",
      "loss: 0.179559  [484800/525306]\n",
      "loss: 0.462879  [486400/525306]\n",
      "loss: 0.723754  [488000/525306]\n",
      "loss: 0.437683  [489600/525306]\n",
      "loss: 0.816684  [491200/525306]\n",
      "loss: 0.771360  [492800/525306]\n",
      "loss: 0.709570  [494400/525306]\n",
      "loss: 0.581447  [496000/525306]\n",
      "loss: 0.694190  [497600/525306]\n",
      "loss: 0.823870  [499200/525306]\n",
      "loss: 1.054578  [500800/525306]\n",
      "loss: 0.880608  [502400/525306]\n",
      "loss: 1.311558  [504000/525306]\n",
      "loss: 0.369397  [505600/525306]\n",
      "loss: 0.366310  [507200/525306]\n",
      "loss: 0.710755  [508800/525306]\n",
      "loss: 0.851397  [510400/525306]\n",
      "loss: 0.611096  [512000/525306]\n",
      "loss: 0.669355  [513600/525306]\n",
      "loss: 0.794865  [515200/525306]\n",
      "loss: 0.779045  [516800/525306]\n",
      "loss: 0.725963  [518400/525306]\n",
      "loss: 1.204098  [520000/525306]\n",
      "loss: 0.810325  [521600/525306]\n",
      "loss: 0.936473  [523200/525306]\n",
      "loss: 0.928920  [524800/525306]\n",
      "Train Accuracy: 73.2402%\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 0.955199, F1-score: 69.92%, Macro_F1-Score:  38.40%  \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.557750  [    0/525306]\n",
      "loss: 0.871013  [ 1600/525306]\n",
      "loss: 0.515640  [ 3200/525306]\n",
      "loss: 0.288471  [ 4800/525306]\n",
      "loss: 0.752345  [ 6400/525306]\n",
      "loss: 0.609498  [ 8000/525306]\n",
      "loss: 0.557295  [ 9600/525306]\n",
      "loss: 1.251450  [11200/525306]\n",
      "loss: 0.697111  [12800/525306]\n",
      "loss: 0.719380  [14400/525306]\n",
      "loss: 0.676168  [16000/525306]\n",
      "loss: 0.795658  [17600/525306]\n",
      "loss: 0.445674  [19200/525306]\n",
      "loss: 0.490442  [20800/525306]\n",
      "loss: 0.619347  [22400/525306]\n",
      "loss: 1.115911  [24000/525306]\n",
      "loss: 0.301622  [25600/525306]\n",
      "loss: 0.635685  [27200/525306]\n",
      "loss: 0.621170  [28800/525306]\n",
      "loss: 0.421623  [30400/525306]\n",
      "loss: 0.575799  [32000/525306]\n",
      "loss: 0.242260  [33600/525306]\n",
      "loss: 0.738820  [35200/525306]\n",
      "loss: 0.408853  [36800/525306]\n",
      "loss: 0.885817  [38400/525306]\n",
      "loss: 0.718732  [40000/525306]\n",
      "loss: 1.009290  [41600/525306]\n",
      "loss: 0.866270  [43200/525306]\n",
      "loss: 1.003270  [44800/525306]\n",
      "loss: 0.753927  [46400/525306]\n",
      "loss: 0.467718  [48000/525306]\n",
      "loss: 0.662674  [49600/525306]\n",
      "loss: 0.543579  [51200/525306]\n",
      "loss: 0.653754  [52800/525306]\n",
      "loss: 0.821138  [54400/525306]\n",
      "loss: 0.439335  [56000/525306]\n",
      "loss: 0.512676  [57600/525306]\n",
      "loss: 0.722905  [59200/525306]\n",
      "loss: 0.662135  [60800/525306]\n",
      "loss: 1.061121  [62400/525306]\n",
      "loss: 0.988793  [64000/525306]\n",
      "loss: 0.772155  [65600/525306]\n",
      "loss: 0.538221  [67200/525306]\n",
      "loss: 0.652485  [68800/525306]\n",
      "loss: 0.719994  [70400/525306]\n",
      "loss: 0.503031  [72000/525306]\n",
      "loss: 0.500337  [73600/525306]\n",
      "loss: 0.755673  [75200/525306]\n",
      "loss: 0.510392  [76800/525306]\n",
      "loss: 1.046059  [78400/525306]\n",
      "loss: 0.838341  [80000/525306]\n",
      "loss: 0.423727  [81600/525306]\n",
      "loss: 0.542514  [83200/525306]\n",
      "loss: 0.622199  [84800/525306]\n",
      "loss: 0.995298  [86400/525306]\n",
      "loss: 1.091464  [88000/525306]\n",
      "loss: 1.183013  [89600/525306]\n",
      "loss: 1.347599  [91200/525306]\n",
      "loss: 0.685869  [92800/525306]\n",
      "loss: 0.744046  [94400/525306]\n",
      "loss: 0.860447  [96000/525306]\n",
      "loss: 0.521193  [97600/525306]\n",
      "loss: 0.683982  [99200/525306]\n",
      "loss: 0.567393  [100800/525306]\n",
      "loss: 0.501586  [102400/525306]\n",
      "loss: 0.697703  [104000/525306]\n",
      "loss: 0.210568  [105600/525306]\n",
      "loss: 0.653782  [107200/525306]\n",
      "loss: 0.614402  [108800/525306]\n",
      "loss: 0.794055  [110400/525306]\n",
      "loss: 0.843929  [112000/525306]\n",
      "loss: 0.551972  [113600/525306]\n",
      "loss: 0.775568  [115200/525306]\n",
      "loss: 0.337166  [116800/525306]\n",
      "loss: 0.788755  [118400/525306]\n",
      "loss: 0.748538  [120000/525306]\n",
      "loss: 0.519152  [121600/525306]\n",
      "loss: 0.359587  [123200/525306]\n",
      "loss: 0.513869  [124800/525306]\n",
      "loss: 0.835168  [126400/525306]\n",
      "loss: 0.588315  [128000/525306]\n",
      "loss: 1.085964  [129600/525306]\n",
      "loss: 0.417679  [131200/525306]\n",
      "loss: 0.565118  [132800/525306]\n",
      "loss: 0.526626  [134400/525306]\n",
      "loss: 0.844314  [136000/525306]\n",
      "loss: 1.156370  [137600/525306]\n",
      "loss: 0.748521  [139200/525306]\n",
      "loss: 0.595403  [140800/525306]\n",
      "loss: 0.539727  [142400/525306]\n",
      "loss: 1.038855  [144000/525306]\n",
      "loss: 0.549375  [145600/525306]\n",
      "loss: 0.659774  [147200/525306]\n",
      "loss: 0.726818  [148800/525306]\n",
      "loss: 0.482466  [150400/525306]\n",
      "loss: 0.356953  [152000/525306]\n",
      "loss: 0.521586  [153600/525306]\n",
      "loss: 0.458329  [155200/525306]\n",
      "loss: 0.695719  [156800/525306]\n",
      "loss: 0.644023  [158400/525306]\n",
      "loss: 0.736838  [160000/525306]\n",
      "loss: 0.324075  [161600/525306]\n",
      "loss: 0.327122  [163200/525306]\n",
      "loss: 1.045802  [164800/525306]\n",
      "loss: 0.638058  [166400/525306]\n",
      "loss: 1.354542  [168000/525306]\n",
      "loss: 0.637649  [169600/525306]\n",
      "loss: 0.595083  [171200/525306]\n",
      "loss: 0.808937  [172800/525306]\n",
      "loss: 0.408215  [174400/525306]\n",
      "loss: 0.700682  [176000/525306]\n",
      "loss: 0.511000  [177600/525306]\n",
      "loss: 0.632568  [179200/525306]\n",
      "loss: 1.361649  [180800/525306]\n",
      "loss: 0.924878  [182400/525306]\n",
      "loss: 0.586361  [184000/525306]\n",
      "loss: 0.975043  [185600/525306]\n",
      "loss: 0.698978  [187200/525306]\n",
      "loss: 0.834200  [188800/525306]\n",
      "loss: 0.620627  [190400/525306]\n",
      "loss: 0.592946  [192000/525306]\n",
      "loss: 0.662120  [193600/525306]\n",
      "loss: 0.998599  [195200/525306]\n",
      "loss: 0.651384  [196800/525306]\n",
      "loss: 0.550002  [198400/525306]\n",
      "loss: 0.491739  [200000/525306]\n",
      "loss: 0.691101  [201600/525306]\n",
      "loss: 0.753447  [203200/525306]\n",
      "loss: 0.330327  [204800/525306]\n",
      "loss: 1.105045  [206400/525306]\n",
      "loss: 0.501798  [208000/525306]\n",
      "loss: 0.767991  [209600/525306]\n",
      "loss: 0.379964  [211200/525306]\n",
      "loss: 0.776464  [212800/525306]\n",
      "loss: 1.068356  [214400/525306]\n",
      "loss: 0.680530  [216000/525306]\n",
      "loss: 0.708393  [217600/525306]\n",
      "loss: 0.620374  [219200/525306]\n",
      "loss: 0.657246  [220800/525306]\n",
      "loss: 0.727591  [222400/525306]\n",
      "loss: 1.188319  [224000/525306]\n",
      "loss: 0.718361  [225600/525306]\n",
      "loss: 0.612935  [227200/525306]\n",
      "loss: 0.777269  [228800/525306]\n",
      "loss: 0.949458  [230400/525306]\n",
      "loss: 0.725670  [232000/525306]\n",
      "loss: 0.883699  [233600/525306]\n",
      "loss: 1.137510  [235200/525306]\n",
      "loss: 0.820518  [236800/525306]\n",
      "loss: 0.474137  [238400/525306]\n",
      "loss: 0.470901  [240000/525306]\n",
      "loss: 0.933221  [241600/525306]\n",
      "loss: 0.704203  [243200/525306]\n",
      "loss: 1.190462  [244800/525306]\n",
      "loss: 0.610974  [246400/525306]\n",
      "loss: 0.901718  [248000/525306]\n",
      "loss: 0.743996  [249600/525306]\n",
      "loss: 0.609940  [251200/525306]\n",
      "loss: 0.887894  [252800/525306]\n",
      "loss: 1.226174  [254400/525306]\n",
      "loss: 0.615751  [256000/525306]\n",
      "loss: 0.688280  [257600/525306]\n",
      "loss: 0.570270  [259200/525306]\n",
      "loss: 0.664957  [260800/525306]\n",
      "loss: 0.692463  [262400/525306]\n",
      "loss: 0.621634  [264000/525306]\n",
      "loss: 1.133939  [265600/525306]\n",
      "loss: 0.557975  [267200/525306]\n",
      "loss: 0.538740  [268800/525306]\n",
      "loss: 0.646474  [270400/525306]\n",
      "loss: 0.969264  [272000/525306]\n",
      "loss: 0.344192  [273600/525306]\n",
      "loss: 0.963890  [275200/525306]\n",
      "loss: 0.895597  [276800/525306]\n",
      "loss: 0.955860  [278400/525306]\n",
      "loss: 0.713370  [280000/525306]\n",
      "loss: 0.752174  [281600/525306]\n",
      "loss: 0.764489  [283200/525306]\n",
      "loss: 0.483198  [284800/525306]\n",
      "loss: 0.681499  [286400/525306]\n",
      "loss: 1.024060  [288000/525306]\n",
      "loss: 0.559658  [289600/525306]\n",
      "loss: 0.398355  [291200/525306]\n",
      "loss: 0.617975  [292800/525306]\n",
      "loss: 0.957361  [294400/525306]\n",
      "loss: 0.670627  [296000/525306]\n",
      "loss: 0.714888  [297600/525306]\n",
      "loss: 0.640276  [299200/525306]\n",
      "loss: 0.761293  [300800/525306]\n",
      "loss: 1.020773  [302400/525306]\n",
      "loss: 1.113408  [304000/525306]\n",
      "loss: 0.539401  [305600/525306]\n",
      "loss: 0.714118  [307200/525306]\n",
      "loss: 0.825265  [308800/525306]\n",
      "loss: 0.691997  [310400/525306]\n",
      "loss: 0.504841  [312000/525306]\n",
      "loss: 0.595268  [313600/525306]\n",
      "loss: 0.817335  [315200/525306]\n",
      "loss: 1.152346  [316800/525306]\n",
      "loss: 0.552473  [318400/525306]\n",
      "loss: 2.031300  [320000/525306]\n",
      "loss: 0.526317  [321600/525306]\n",
      "loss: 0.677036  [323200/525306]\n",
      "loss: 0.624753  [324800/525306]\n",
      "loss: 0.707214  [326400/525306]\n",
      "loss: 0.687236  [328000/525306]\n",
      "loss: 0.376164  [329600/525306]\n",
      "loss: 0.751613  [331200/525306]\n",
      "loss: 0.657675  [332800/525306]\n",
      "loss: 0.707081  [334400/525306]\n",
      "loss: 0.504308  [336000/525306]\n",
      "loss: 0.479028  [337600/525306]\n",
      "loss: 0.609147  [339200/525306]\n",
      "loss: 0.903234  [340800/525306]\n",
      "loss: 0.548536  [342400/525306]\n",
      "loss: 0.574290  [344000/525306]\n",
      "loss: 0.743132  [345600/525306]\n",
      "loss: 0.708336  [347200/525306]\n",
      "loss: 0.810085  [348800/525306]\n",
      "loss: 0.534111  [350400/525306]\n",
      "loss: 0.481914  [352000/525306]\n",
      "loss: 0.787990  [353600/525306]\n",
      "loss: 0.841514  [355200/525306]\n",
      "loss: 1.231926  [356800/525306]\n",
      "loss: 0.744234  [358400/525306]\n",
      "loss: 0.881100  [360000/525306]\n",
      "loss: 0.700754  [361600/525306]\n",
      "loss: 0.879208  [363200/525306]\n",
      "loss: 0.741306  [364800/525306]\n",
      "loss: 0.722728  [366400/525306]\n",
      "loss: 0.526930  [368000/525306]\n",
      "loss: 0.706691  [369600/525306]\n",
      "loss: 0.701991  [371200/525306]\n",
      "loss: 0.594501  [372800/525306]\n",
      "loss: 0.487013  [374400/525306]\n",
      "loss: 0.584926  [376000/525306]\n",
      "loss: 0.941788  [377600/525306]\n",
      "loss: 1.149811  [379200/525306]\n",
      "loss: 0.383835  [380800/525306]\n",
      "loss: 0.615164  [382400/525306]\n",
      "loss: 0.655498  [384000/525306]\n",
      "loss: 0.409840  [385600/525306]\n",
      "loss: 0.595006  [387200/525306]\n",
      "loss: 1.410564  [388800/525306]\n",
      "loss: 1.260099  [390400/525306]\n",
      "loss: 0.710186  [392000/525306]\n",
      "loss: 0.828166  [393600/525306]\n",
      "loss: 0.412665  [395200/525306]\n",
      "loss: 0.889182  [396800/525306]\n",
      "loss: 0.934466  [398400/525306]\n",
      "loss: 0.344725  [400000/525306]\n",
      "loss: 0.627676  [401600/525306]\n",
      "loss: 0.644616  [403200/525306]\n",
      "loss: 1.088736  [404800/525306]\n",
      "loss: 0.787407  [406400/525306]\n",
      "loss: 0.753468  [408000/525306]\n",
      "loss: 0.567947  [409600/525306]\n",
      "loss: 1.148817  [411200/525306]\n",
      "loss: 0.739438  [412800/525306]\n",
      "loss: 0.365341  [414400/525306]\n",
      "loss: 0.470264  [416000/525306]\n",
      "loss: 0.537635  [417600/525306]\n",
      "loss: 0.746572  [419200/525306]\n",
      "loss: 0.901282  [420800/525306]\n",
      "loss: 0.921206  [422400/525306]\n",
      "loss: 0.491379  [424000/525306]\n",
      "loss: 1.095882  [425600/525306]\n",
      "loss: 0.657544  [427200/525306]\n",
      "loss: 0.577210  [428800/525306]\n",
      "loss: 0.828954  [430400/525306]\n",
      "loss: 0.845979  [432000/525306]\n",
      "loss: 0.789388  [433600/525306]\n",
      "loss: 0.772079  [435200/525306]\n",
      "loss: 0.808582  [436800/525306]\n",
      "loss: 0.738740  [438400/525306]\n",
      "loss: 0.900300  [440000/525306]\n",
      "loss: 0.741996  [441600/525306]\n",
      "loss: 1.194934  [443200/525306]\n",
      "loss: 0.717817  [444800/525306]\n",
      "loss: 0.514084  [446400/525306]\n",
      "loss: 0.628413  [448000/525306]\n",
      "loss: 0.700720  [449600/525306]\n",
      "loss: 0.366470  [451200/525306]\n",
      "loss: 0.893180  [452800/525306]\n",
      "loss: 0.709393  [454400/525306]\n",
      "loss: 0.386842  [456000/525306]\n",
      "loss: 0.958480  [457600/525306]\n",
      "loss: 0.777087  [459200/525306]\n",
      "loss: 0.594014  [460800/525306]\n",
      "loss: 0.593859  [462400/525306]\n",
      "loss: 1.333770  [464000/525306]\n",
      "loss: 0.909145  [465600/525306]\n",
      "loss: 0.638541  [467200/525306]\n",
      "loss: 0.519208  [468800/525306]\n",
      "loss: 0.695611  [470400/525306]\n",
      "loss: 0.628564  [472000/525306]\n",
      "loss: 1.055380  [473600/525306]\n",
      "loss: 0.485415  [475200/525306]\n",
      "loss: 0.475975  [476800/525306]\n",
      "loss: 0.915288  [478400/525306]\n",
      "loss: 0.497261  [480000/525306]\n",
      "loss: 0.667751  [481600/525306]\n",
      "loss: 0.787725  [483200/525306]\n",
      "loss: 0.893342  [484800/525306]\n",
      "loss: 0.705335  [486400/525306]\n",
      "loss: 0.746689  [488000/525306]\n",
      "loss: 0.868783  [489600/525306]\n",
      "loss: 0.613322  [491200/525306]\n",
      "loss: 0.533115  [492800/525306]\n",
      "loss: 0.452074  [494400/525306]\n",
      "loss: 0.384866  [496000/525306]\n",
      "loss: 0.529771  [497600/525306]\n",
      "loss: 0.706001  [499200/525306]\n",
      "loss: 0.950300  [500800/525306]\n",
      "loss: 0.507854  [502400/525306]\n",
      "loss: 0.817142  [504000/525306]\n",
      "loss: 0.695464  [505600/525306]\n",
      "loss: 0.735951  [507200/525306]\n",
      "loss: 0.405235  [508800/525306]\n",
      "loss: 0.756168  [510400/525306]\n",
      "loss: 0.640943  [512000/525306]\n",
      "loss: 0.791528  [513600/525306]\n",
      "loss: 0.573457  [515200/525306]\n",
      "loss: 0.562936  [516800/525306]\n",
      "loss: 0.801334  [518400/525306]\n",
      "loss: 0.611816  [520000/525306]\n",
      "loss: 0.648887  [521600/525306]\n",
      "loss: 0.840901  [523200/525306]\n",
      "loss: 0.885491  [524800/525306]\n",
      "Train Accuracy: 73.3300%\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.881349, F1-score: 69.92%, Macro_F1-Score:  37.61%  \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.629006  [    0/525306]\n",
      "loss: 0.768586  [ 1600/525306]\n",
      "loss: 0.660718  [ 3200/525306]\n",
      "loss: 0.547622  [ 4800/525306]\n",
      "loss: 0.773013  [ 6400/525306]\n",
      "loss: 0.843563  [ 8000/525306]\n",
      "loss: 0.865481  [ 9600/525306]\n",
      "loss: 0.710972  [11200/525306]\n",
      "loss: 0.277345  [12800/525306]\n",
      "loss: 0.459033  [14400/525306]\n",
      "loss: 0.995861  [16000/525306]\n",
      "loss: 0.315931  [17600/525306]\n",
      "loss: 0.602095  [19200/525306]\n",
      "loss: 1.109559  [20800/525306]\n",
      "loss: 0.425994  [22400/525306]\n",
      "loss: 0.460800  [24000/525306]\n",
      "loss: 0.861554  [25600/525306]\n",
      "loss: 0.402243  [27200/525306]\n",
      "loss: 1.160584  [28800/525306]\n",
      "loss: 0.737725  [30400/525306]\n",
      "loss: 0.934989  [32000/525306]\n",
      "loss: 0.817506  [33600/525306]\n",
      "loss: 0.418934  [35200/525306]\n",
      "loss: 0.733036  [36800/525306]\n",
      "loss: 1.082422  [38400/525306]\n",
      "loss: 0.884793  [40000/525306]\n",
      "loss: 0.686388  [41600/525306]\n",
      "loss: 0.679842  [43200/525306]\n",
      "loss: 0.705720  [44800/525306]\n",
      "loss: 0.476788  [46400/525306]\n",
      "loss: 0.936568  [48000/525306]\n",
      "loss: 0.442240  [49600/525306]\n",
      "loss: 0.925882  [51200/525306]\n",
      "loss: 0.900355  [52800/525306]\n",
      "loss: 0.416872  [54400/525306]\n",
      "loss: 0.487711  [56000/525306]\n",
      "loss: 0.495219  [57600/525306]\n",
      "loss: 0.583324  [59200/525306]\n",
      "loss: 0.827315  [60800/525306]\n",
      "loss: 0.656420  [62400/525306]\n",
      "loss: 0.707469  [64000/525306]\n",
      "loss: 0.800935  [65600/525306]\n",
      "loss: 0.851381  [67200/525306]\n",
      "loss: 0.435959  [68800/525306]\n",
      "loss: 0.535623  [70400/525306]\n",
      "loss: 0.622603  [72000/525306]\n",
      "loss: 0.945610  [73600/525306]\n",
      "loss: 0.708580  [75200/525306]\n",
      "loss: 0.945226  [76800/525306]\n",
      "loss: 0.436028  [78400/525306]\n",
      "loss: 1.035097  [80000/525306]\n",
      "loss: 1.101716  [81600/525306]\n",
      "loss: 0.872139  [83200/525306]\n",
      "loss: 0.630170  [84800/525306]\n",
      "loss: 1.212904  [86400/525306]\n",
      "loss: 0.883953  [88000/525306]\n",
      "loss: 0.467946  [89600/525306]\n",
      "loss: 0.942679  [91200/525306]\n",
      "loss: 1.089814  [92800/525306]\n",
      "loss: 0.902685  [94400/525306]\n",
      "loss: 0.554528  [96000/525306]\n",
      "loss: 0.600403  [97600/525306]\n",
      "loss: 0.753832  [99200/525306]\n",
      "loss: 0.498347  [100800/525306]\n",
      "loss: 1.009323  [102400/525306]\n",
      "loss: 0.568606  [104000/525306]\n",
      "loss: 0.830858  [105600/525306]\n",
      "loss: 0.579962  [107200/525306]\n",
      "loss: 0.809197  [108800/525306]\n",
      "loss: 0.524007  [110400/525306]\n",
      "loss: 0.599108  [112000/525306]\n",
      "loss: 0.535323  [113600/525306]\n",
      "loss: 0.707963  [115200/525306]\n",
      "loss: 1.144824  [116800/525306]\n",
      "loss: 0.702596  [118400/525306]\n",
      "loss: 1.020181  [120000/525306]\n",
      "loss: 0.932688  [121600/525306]\n",
      "loss: 1.143945  [123200/525306]\n",
      "loss: 0.583774  [124800/525306]\n",
      "loss: 0.503798  [126400/525306]\n",
      "loss: 0.377810  [128000/525306]\n",
      "loss: 0.511564  [129600/525306]\n",
      "loss: 0.469002  [131200/525306]\n",
      "loss: 0.610506  [132800/525306]\n",
      "loss: 0.564940  [134400/525306]\n",
      "loss: 0.622855  [136000/525306]\n",
      "loss: 0.695822  [137600/525306]\n",
      "loss: 0.714808  [139200/525306]\n",
      "loss: 0.705496  [140800/525306]\n",
      "loss: 0.335217  [142400/525306]\n",
      "loss: 0.429148  [144000/525306]\n",
      "loss: 0.441024  [145600/525306]\n",
      "loss: 0.975355  [147200/525306]\n",
      "loss: 0.396444  [148800/525306]\n",
      "loss: 0.773509  [150400/525306]\n",
      "loss: 0.669200  [152000/525306]\n",
      "loss: 0.909628  [153600/525306]\n",
      "loss: 1.112446  [155200/525306]\n",
      "loss: 0.533102  [156800/525306]\n",
      "loss: 0.976846  [158400/525306]\n",
      "loss: 0.782083  [160000/525306]\n",
      "loss: 0.652237  [161600/525306]\n",
      "loss: 0.553180  [163200/525306]\n",
      "loss: 0.936059  [164800/525306]\n",
      "loss: 0.543736  [166400/525306]\n",
      "loss: 0.981848  [168000/525306]\n",
      "loss: 0.477348  [169600/525306]\n",
      "loss: 1.090375  [171200/525306]\n",
      "loss: 0.702341  [172800/525306]\n",
      "loss: 0.333025  [174400/525306]\n",
      "loss: 0.706149  [176000/525306]\n",
      "loss: 0.574563  [177600/525306]\n",
      "loss: 0.416153  [179200/525306]\n",
      "loss: 0.309716  [180800/525306]\n",
      "loss: 0.633372  [182400/525306]\n",
      "loss: 1.335705  [184000/525306]\n",
      "loss: 0.840157  [185600/525306]\n",
      "loss: 0.974416  [187200/525306]\n",
      "loss: 0.734388  [188800/525306]\n",
      "loss: 0.994303  [190400/525306]\n",
      "loss: 0.713077  [192000/525306]\n",
      "loss: 0.440109  [193600/525306]\n",
      "loss: 0.731524  [195200/525306]\n",
      "loss: 0.374239  [196800/525306]\n",
      "loss: 0.513316  [198400/525306]\n",
      "loss: 0.599372  [200000/525306]\n",
      "loss: 0.841090  [201600/525306]\n",
      "loss: 1.049020  [203200/525306]\n",
      "loss: 0.707879  [204800/525306]\n",
      "loss: 0.912260  [206400/525306]\n",
      "loss: 0.738519  [208000/525306]\n",
      "loss: 1.054557  [209600/525306]\n",
      "loss: 0.648973  [211200/525306]\n",
      "loss: 0.556802  [212800/525306]\n",
      "loss: 0.862170  [214400/525306]\n",
      "loss: 0.572565  [216000/525306]\n",
      "loss: 0.298450  [217600/525306]\n",
      "loss: 0.728637  [219200/525306]\n",
      "loss: 0.911689  [220800/525306]\n",
      "loss: 0.588388  [222400/525306]\n",
      "loss: 1.056771  [224000/525306]\n",
      "loss: 0.759272  [225600/525306]\n",
      "loss: 0.364685  [227200/525306]\n",
      "loss: 0.567298  [228800/525306]\n",
      "loss: 1.214713  [230400/525306]\n",
      "loss: 0.324820  [232000/525306]\n",
      "loss: 0.638351  [233600/525306]\n",
      "loss: 0.608585  [235200/525306]\n",
      "loss: 0.408004  [236800/525306]\n",
      "loss: 1.227384  [238400/525306]\n",
      "loss: 0.655717  [240000/525306]\n",
      "loss: 0.733377  [241600/525306]\n",
      "loss: 1.025063  [243200/525306]\n",
      "loss: 0.660891  [244800/525306]\n",
      "loss: 0.622657  [246400/525306]\n",
      "loss: 0.598762  [248000/525306]\n",
      "loss: 1.255213  [249600/525306]\n",
      "loss: 0.609034  [251200/525306]\n",
      "loss: 0.773251  [252800/525306]\n",
      "loss: 0.507611  [254400/525306]\n",
      "loss: 0.623909  [256000/525306]\n",
      "loss: 0.591783  [257600/525306]\n",
      "loss: 0.474071  [259200/525306]\n",
      "loss: 0.684316  [260800/525306]\n",
      "loss: 0.687713  [262400/525306]\n",
      "loss: 0.536128  [264000/525306]\n",
      "loss: 0.674303  [265600/525306]\n",
      "loss: 0.454098  [267200/525306]\n",
      "loss: 0.784047  [268800/525306]\n",
      "loss: 1.029988  [270400/525306]\n",
      "loss: 0.789372  [272000/525306]\n",
      "loss: 0.582821  [273600/525306]\n",
      "loss: 0.762240  [275200/525306]\n",
      "loss: 0.715447  [276800/525306]\n",
      "loss: 0.874808  [278400/525306]\n",
      "loss: 0.384905  [280000/525306]\n",
      "loss: 1.008018  [281600/525306]\n",
      "loss: 1.086053  [283200/525306]\n",
      "loss: 1.230330  [284800/525306]\n",
      "loss: 1.095360  [286400/525306]\n",
      "loss: 0.474773  [288000/525306]\n",
      "loss: 1.128551  [289600/525306]\n",
      "loss: 0.716034  [291200/525306]\n",
      "loss: 0.446947  [292800/525306]\n",
      "loss: 0.681985  [294400/525306]\n",
      "loss: 1.166692  [296000/525306]\n",
      "loss: 0.699481  [297600/525306]\n",
      "loss: 0.715573  [299200/525306]\n",
      "loss: 0.745772  [300800/525306]\n",
      "loss: 0.829726  [302400/525306]\n",
      "loss: 0.740322  [304000/525306]\n",
      "loss: 0.316510  [305600/525306]\n",
      "loss: 0.818684  [307200/525306]\n",
      "loss: 0.604688  [308800/525306]\n",
      "loss: 0.803316  [310400/525306]\n",
      "loss: 0.797004  [312000/525306]\n",
      "loss: 0.306844  [313600/525306]\n",
      "loss: 0.538892  [315200/525306]\n",
      "loss: 0.707352  [316800/525306]\n",
      "loss: 0.888985  [318400/525306]\n",
      "loss: 1.138322  [320000/525306]\n",
      "loss: 0.950870  [321600/525306]\n",
      "loss: 0.442153  [323200/525306]\n",
      "loss: 0.662590  [324800/525306]\n",
      "loss: 0.793210  [326400/525306]\n",
      "loss: 1.163438  [328000/525306]\n",
      "loss: 0.910678  [329600/525306]\n",
      "loss: 1.103491  [331200/525306]\n",
      "loss: 0.770957  [332800/525306]\n",
      "loss: 0.588053  [334400/525306]\n",
      "loss: 0.646386  [336000/525306]\n",
      "loss: 0.764598  [337600/525306]\n",
      "loss: 1.485577  [339200/525306]\n",
      "loss: 0.329450  [340800/525306]\n",
      "loss: 0.718385  [342400/525306]\n",
      "loss: 0.537280  [344000/525306]\n",
      "loss: 0.952409  [345600/525306]\n",
      "loss: 0.755077  [347200/525306]\n",
      "loss: 0.588476  [348800/525306]\n",
      "loss: 0.861706  [350400/525306]\n",
      "loss: 0.453643  [352000/525306]\n",
      "loss: 0.671346  [353600/525306]\n",
      "loss: 0.592473  [355200/525306]\n",
      "loss: 0.955918  [356800/525306]\n",
      "loss: 0.257362  [358400/525306]\n",
      "loss: 0.884227  [360000/525306]\n",
      "loss: 0.631076  [361600/525306]\n",
      "loss: 0.736939  [363200/525306]\n",
      "loss: 0.496277  [364800/525306]\n",
      "loss: 0.693950  [366400/525306]\n",
      "loss: 0.815679  [368000/525306]\n",
      "loss: 0.471308  [369600/525306]\n",
      "loss: 1.253928  [371200/525306]\n",
      "loss: 0.570036  [372800/525306]\n",
      "loss: 0.769483  [374400/525306]\n",
      "loss: 1.233503  [376000/525306]\n",
      "loss: 0.877374  [377600/525306]\n",
      "loss: 0.770805  [379200/525306]\n",
      "loss: 1.081704  [380800/525306]\n",
      "loss: 1.484370  [382400/525306]\n",
      "loss: 0.702014  [384000/525306]\n",
      "loss: 0.889554  [385600/525306]\n",
      "loss: 0.674160  [387200/525306]\n",
      "loss: 0.404897  [388800/525306]\n",
      "loss: 0.758353  [390400/525306]\n",
      "loss: 0.587047  [392000/525306]\n",
      "loss: 0.609482  [393600/525306]\n",
      "loss: 0.493204  [395200/525306]\n",
      "loss: 0.498338  [396800/525306]\n",
      "loss: 0.962934  [398400/525306]\n",
      "loss: 0.463913  [400000/525306]\n",
      "loss: 0.644577  [401600/525306]\n",
      "loss: 1.036076  [403200/525306]\n",
      "loss: 0.696333  [404800/525306]\n",
      "loss: 0.612327  [406400/525306]\n",
      "loss: 0.713671  [408000/525306]\n",
      "loss: 0.731329  [409600/525306]\n",
      "loss: 0.803864  [411200/525306]\n",
      "loss: 0.750339  [412800/525306]\n",
      "loss: 0.571949  [414400/525306]\n",
      "loss: 0.671073  [416000/525306]\n",
      "loss: 0.846608  [417600/525306]\n",
      "loss: 0.737481  [419200/525306]\n",
      "loss: 0.478663  [420800/525306]\n",
      "loss: 0.688837  [422400/525306]\n",
      "loss: 1.344311  [424000/525306]\n",
      "loss: 0.956884  [425600/525306]\n",
      "loss: 0.667245  [427200/525306]\n",
      "loss: 0.724005  [428800/525306]\n",
      "loss: 0.824414  [430400/525306]\n",
      "loss: 0.278497  [432000/525306]\n",
      "loss: 0.254032  [433600/525306]\n",
      "loss: 0.390223  [435200/525306]\n",
      "loss: 0.941761  [436800/525306]\n",
      "loss: 0.833265  [438400/525306]\n",
      "loss: 0.947721  [440000/525306]\n",
      "loss: 0.624781  [441600/525306]\n",
      "loss: 0.848426  [443200/525306]\n",
      "loss: 1.221109  [444800/525306]\n",
      "loss: 0.731378  [446400/525306]\n",
      "loss: 0.381673  [448000/525306]\n",
      "loss: 0.898943  [449600/525306]\n",
      "loss: 0.856336  [451200/525306]\n",
      "loss: 0.654458  [452800/525306]\n",
      "loss: 0.446493  [454400/525306]\n",
      "loss: 0.810013  [456000/525306]\n",
      "loss: 0.814888  [457600/525306]\n",
      "loss: 0.275555  [459200/525306]\n",
      "loss: 0.835792  [460800/525306]\n",
      "loss: 0.608996  [462400/525306]\n",
      "loss: 0.628209  [464000/525306]\n",
      "loss: 0.698334  [465600/525306]\n",
      "loss: 0.420866  [467200/525306]\n",
      "loss: 0.730018  [468800/525306]\n",
      "loss: 1.365186  [470400/525306]\n",
      "loss: 0.616576  [472000/525306]\n",
      "loss: 0.420506  [473600/525306]\n",
      "loss: 0.698471  [475200/525306]\n",
      "loss: 0.988428  [476800/525306]\n",
      "loss: 0.903152  [478400/525306]\n",
      "loss: 1.553528  [480000/525306]\n",
      "loss: 0.546408  [481600/525306]\n",
      "loss: 0.674142  [483200/525306]\n",
      "loss: 0.705059  [484800/525306]\n",
      "loss: 0.506382  [486400/525306]\n",
      "loss: 0.644894  [488000/525306]\n",
      "loss: 0.859635  [489600/525306]\n",
      "loss: 0.366113  [491200/525306]\n",
      "loss: 0.676612  [492800/525306]\n",
      "loss: 0.391053  [494400/525306]\n",
      "loss: 0.563336  [496000/525306]\n",
      "loss: 0.505780  [497600/525306]\n",
      "loss: 0.731971  [499200/525306]\n",
      "loss: 0.473068  [500800/525306]\n",
      "loss: 1.086630  [502400/525306]\n",
      "loss: 0.408229  [504000/525306]\n",
      "loss: 0.745375  [505600/525306]\n",
      "loss: 0.263306  [507200/525306]\n",
      "loss: 0.577643  [508800/525306]\n",
      "loss: 0.444625  [510400/525306]\n",
      "loss: 0.696030  [512000/525306]\n",
      "loss: 0.508824  [513600/525306]\n",
      "loss: 0.489885  [515200/525306]\n",
      "loss: 0.717376  [516800/525306]\n",
      "loss: 0.543516  [518400/525306]\n",
      "loss: 0.319259  [520000/525306]\n",
      "loss: 1.060304  [521600/525306]\n",
      "loss: 0.881519  [523200/525306]\n",
      "loss: 0.766323  [524800/525306]\n",
      "Train Accuracy: 73.4172%\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 0.872679, F1-score: 70.45%, Macro_F1-Score:  40.09%  \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.547069  [    0/525306]\n",
      "loss: 0.213777  [ 1600/525306]\n",
      "loss: 0.864727  [ 3200/525306]\n",
      "loss: 1.195989  [ 4800/525306]\n",
      "loss: 1.046584  [ 6400/525306]\n",
      "loss: 0.377226  [ 8000/525306]\n",
      "loss: 0.992357  [ 9600/525306]\n",
      "loss: 0.626873  [11200/525306]\n",
      "loss: 0.595672  [12800/525306]\n",
      "loss: 0.582735  [14400/525306]\n",
      "loss: 1.072126  [16000/525306]\n",
      "loss: 0.859942  [17600/525306]\n",
      "loss: 0.370706  [19200/525306]\n",
      "loss: 0.878293  [20800/525306]\n",
      "loss: 0.796739  [22400/525306]\n",
      "loss: 0.269778  [24000/525306]\n",
      "loss: 0.722181  [25600/525306]\n",
      "loss: 0.963159  [27200/525306]\n",
      "loss: 0.807882  [28800/525306]\n",
      "loss: 0.919319  [30400/525306]\n",
      "loss: 0.942471  [32000/525306]\n",
      "loss: 1.067575  [33600/525306]\n",
      "loss: 1.268721  [35200/525306]\n",
      "loss: 0.315323  [36800/525306]\n",
      "loss: 1.463825  [38400/525306]\n",
      "loss: 0.410918  [40000/525306]\n",
      "loss: 0.868331  [41600/525306]\n",
      "loss: 0.856466  [43200/525306]\n",
      "loss: 0.594414  [44800/525306]\n",
      "loss: 0.719725  [46400/525306]\n",
      "loss: 1.129487  [48000/525306]\n",
      "loss: 0.751111  [49600/525306]\n",
      "loss: 0.772159  [51200/525306]\n",
      "loss: 0.809402  [52800/525306]\n",
      "loss: 0.759510  [54400/525306]\n",
      "loss: 0.471802  [56000/525306]\n",
      "loss: 0.836896  [57600/525306]\n",
      "loss: 0.557613  [59200/525306]\n",
      "loss: 1.137638  [60800/525306]\n",
      "loss: 0.890987  [62400/525306]\n",
      "loss: 0.501558  [64000/525306]\n",
      "loss: 0.992580  [65600/525306]\n",
      "loss: 0.773360  [67200/525306]\n",
      "loss: 0.574782  [68800/525306]\n",
      "loss: 0.749472  [70400/525306]\n",
      "loss: 0.780710  [72000/525306]\n",
      "loss: 0.749225  [73600/525306]\n",
      "loss: 0.818412  [75200/525306]\n",
      "loss: 0.661089  [76800/525306]\n",
      "loss: 0.200014  [78400/525306]\n",
      "loss: 0.771643  [80000/525306]\n",
      "loss: 0.129516  [81600/525306]\n",
      "loss: 0.464498  [83200/525306]\n",
      "loss: 0.974116  [84800/525306]\n",
      "loss: 0.393006  [86400/525306]\n",
      "loss: 0.211639  [88000/525306]\n",
      "loss: 1.101956  [89600/525306]\n",
      "loss: 0.626095  [91200/525306]\n",
      "loss: 0.883097  [92800/525306]\n",
      "loss: 0.612580  [94400/525306]\n",
      "loss: 0.689998  [96000/525306]\n",
      "loss: 1.035066  [97600/525306]\n",
      "loss: 0.649992  [99200/525306]\n",
      "loss: 0.939505  [100800/525306]\n",
      "loss: 0.679552  [102400/525306]\n",
      "loss: 0.910430  [104000/525306]\n",
      "loss: 0.626058  [105600/525306]\n",
      "loss: 0.924292  [107200/525306]\n",
      "loss: 0.410704  [108800/525306]\n",
      "loss: 0.455097  [110400/525306]\n",
      "loss: 0.458396  [112000/525306]\n",
      "loss: 0.816417  [113600/525306]\n",
      "loss: 0.784994  [115200/525306]\n",
      "loss: 0.499043  [116800/525306]\n",
      "loss: 0.455493  [118400/525306]\n",
      "loss: 0.643063  [120000/525306]\n",
      "loss: 1.018628  [121600/525306]\n",
      "loss: 0.653118  [123200/525306]\n",
      "loss: 0.594576  [124800/525306]\n",
      "loss: 0.639906  [126400/525306]\n",
      "loss: 0.775409  [128000/525306]\n",
      "loss: 1.027408  [129600/525306]\n",
      "loss: 0.630418  [131200/525306]\n",
      "loss: 0.488496  [132800/525306]\n",
      "loss: 0.699261  [134400/525306]\n",
      "loss: 0.664025  [136000/525306]\n",
      "loss: 0.519598  [137600/525306]\n",
      "loss: 0.731367  [139200/525306]\n",
      "loss: 0.700707  [140800/525306]\n",
      "loss: 0.534769  [142400/525306]\n",
      "loss: 0.981150  [144000/525306]\n",
      "loss: 0.740918  [145600/525306]\n",
      "loss: 0.477969  [147200/525306]\n",
      "loss: 1.128117  [148800/525306]\n",
      "loss: 1.130914  [150400/525306]\n",
      "loss: 0.408734  [152000/525306]\n",
      "loss: 0.458081  [153600/525306]\n",
      "loss: 0.833851  [155200/525306]\n",
      "loss: 0.797349  [156800/525306]\n",
      "loss: 0.618791  [158400/525306]\n",
      "loss: 0.436254  [160000/525306]\n",
      "loss: 0.660874  [161600/525306]\n",
      "loss: 1.176550  [163200/525306]\n",
      "loss: 0.481005  [164800/525306]\n",
      "loss: 0.804993  [166400/525306]\n",
      "loss: 0.612151  [168000/525306]\n",
      "loss: 0.945531  [169600/525306]\n",
      "loss: 0.516727  [171200/525306]\n",
      "loss: 0.589433  [172800/525306]\n",
      "loss: 0.893558  [174400/525306]\n",
      "loss: 0.800323  [176000/525306]\n",
      "loss: 0.475153  [177600/525306]\n",
      "loss: 0.508375  [179200/525306]\n",
      "loss: 0.298533  [180800/525306]\n",
      "loss: 0.497724  [182400/525306]\n",
      "loss: 0.603486  [184000/525306]\n",
      "loss: 0.839491  [185600/525306]\n",
      "loss: 0.471226  [187200/525306]\n",
      "loss: 0.853974  [188800/525306]\n",
      "loss: 0.393629  [190400/525306]\n",
      "loss: 1.192011  [192000/525306]\n",
      "loss: 1.264190  [193600/525306]\n",
      "loss: 1.351661  [195200/525306]\n",
      "loss: 0.658409  [196800/525306]\n",
      "loss: 0.639979  [198400/525306]\n",
      "loss: 0.476912  [200000/525306]\n",
      "loss: 0.608178  [201600/525306]\n",
      "loss: 0.746390  [203200/525306]\n",
      "loss: 0.305462  [204800/525306]\n",
      "loss: 0.780210  [206400/525306]\n",
      "loss: 0.900589  [208000/525306]\n",
      "loss: 1.236115  [209600/525306]\n",
      "loss: 0.658755  [211200/525306]\n",
      "loss: 0.581724  [212800/525306]\n",
      "loss: 0.908954  [214400/525306]\n",
      "loss: 1.250522  [216000/525306]\n",
      "loss: 0.912706  [217600/525306]\n",
      "loss: 0.575277  [219200/525306]\n",
      "loss: 0.673470  [220800/525306]\n",
      "loss: 0.587263  [222400/525306]\n",
      "loss: 0.781658  [224000/525306]\n",
      "loss: 0.451939  [225600/525306]\n",
      "loss: 0.967108  [227200/525306]\n",
      "loss: 0.841108  [228800/525306]\n",
      "loss: 0.574738  [230400/525306]\n",
      "loss: 0.559981  [232000/525306]\n",
      "loss: 0.943896  [233600/525306]\n",
      "loss: 1.184408  [235200/525306]\n",
      "loss: 0.865989  [236800/525306]\n",
      "loss: 0.866954  [238400/525306]\n",
      "loss: 1.257953  [240000/525306]\n",
      "loss: 1.159675  [241600/525306]\n",
      "loss: 0.199861  [243200/525306]\n",
      "loss: 0.531979  [244800/525306]\n",
      "loss: 0.719344  [246400/525306]\n",
      "loss: 0.441800  [248000/525306]\n",
      "loss: 0.561906  [249600/525306]\n",
      "loss: 0.975478  [251200/525306]\n",
      "loss: 0.668062  [252800/525306]\n",
      "loss: 1.043085  [254400/525306]\n",
      "loss: 0.844578  [256000/525306]\n",
      "loss: 0.450876  [257600/525306]\n",
      "loss: 0.674992  [259200/525306]\n",
      "loss: 0.252241  [260800/525306]\n",
      "loss: 0.683538  [262400/525306]\n",
      "loss: 0.508602  [264000/525306]\n",
      "loss: 0.946423  [265600/525306]\n",
      "loss: 0.810306  [267200/525306]\n",
      "loss: 0.950128  [268800/525306]\n",
      "loss: 0.345954  [270400/525306]\n",
      "loss: 0.739808  [272000/525306]\n",
      "loss: 0.698600  [273600/525306]\n",
      "loss: 0.440987  [275200/525306]\n",
      "loss: 0.500310  [276800/525306]\n",
      "loss: 0.685190  [278400/525306]\n",
      "loss: 0.705292  [280000/525306]\n",
      "loss: 0.521199  [281600/525306]\n",
      "loss: 0.804603  [283200/525306]\n",
      "loss: 0.777052  [284800/525306]\n",
      "loss: 0.668454  [286400/525306]\n",
      "loss: 0.814884  [288000/525306]\n",
      "loss: 0.618931  [289600/525306]\n",
      "loss: 0.763955  [291200/525306]\n",
      "loss: 0.517409  [292800/525306]\n",
      "loss: 0.815579  [294400/525306]\n",
      "loss: 0.587339  [296000/525306]\n",
      "loss: 0.822076  [297600/525306]\n",
      "loss: 0.408948  [299200/525306]\n",
      "loss: 1.132250  [300800/525306]\n",
      "loss: 0.743608  [302400/525306]\n",
      "loss: 0.402603  [304000/525306]\n",
      "loss: 0.778626  [305600/525306]\n",
      "loss: 0.716462  [307200/525306]\n",
      "loss: 0.489232  [308800/525306]\n",
      "loss: 0.862339  [310400/525306]\n",
      "loss: 0.723866  [312000/525306]\n",
      "loss: 0.605770  [313600/525306]\n",
      "loss: 0.603661  [315200/525306]\n",
      "loss: 0.578213  [316800/525306]\n",
      "loss: 0.605487  [318400/525306]\n",
      "loss: 0.818088  [320000/525306]\n",
      "loss: 0.337686  [321600/525306]\n",
      "loss: 0.558533  [323200/525306]\n",
      "loss: 0.389860  [324800/525306]\n",
      "loss: 0.654769  [326400/525306]\n",
      "loss: 0.399168  [328000/525306]\n",
      "loss: 0.774342  [329600/525306]\n",
      "loss: 0.947283  [331200/525306]\n",
      "loss: 0.862373  [332800/525306]\n",
      "loss: 0.615135  [334400/525306]\n",
      "loss: 0.786781  [336000/525306]\n",
      "loss: 1.145461  [337600/525306]\n",
      "loss: 0.897741  [339200/525306]\n",
      "loss: 0.555810  [340800/525306]\n",
      "loss: 0.624724  [342400/525306]\n",
      "loss: 0.552196  [344000/525306]\n",
      "loss: 1.183188  [345600/525306]\n",
      "loss: 0.675348  [347200/525306]\n",
      "loss: 0.770469  [348800/525306]\n",
      "loss: 0.857456  [350400/525306]\n",
      "loss: 0.640297  [352000/525306]\n",
      "loss: 0.358732  [353600/525306]\n",
      "loss: 0.764370  [355200/525306]\n",
      "loss: 0.552633  [356800/525306]\n",
      "loss: 0.790992  [358400/525306]\n",
      "loss: 0.746400  [360000/525306]\n",
      "loss: 0.956192  [361600/525306]\n",
      "loss: 1.274297  [363200/525306]\n",
      "loss: 0.471603  [364800/525306]\n",
      "loss: 0.600613  [366400/525306]\n",
      "loss: 0.933444  [368000/525306]\n",
      "loss: 0.197060  [369600/525306]\n",
      "loss: 0.578831  [371200/525306]\n",
      "loss: 0.718745  [372800/525306]\n",
      "loss: 1.236038  [374400/525306]\n",
      "loss: 0.555754  [376000/525306]\n",
      "loss: 0.571284  [377600/525306]\n",
      "loss: 0.494269  [379200/525306]\n",
      "loss: 0.853059  [380800/525306]\n",
      "loss: 0.481584  [382400/525306]\n",
      "loss: 0.627981  [384000/525306]\n",
      "loss: 0.566092  [385600/525306]\n",
      "loss: 0.314896  [387200/525306]\n",
      "loss: 0.508627  [388800/525306]\n",
      "loss: 0.622840  [390400/525306]\n",
      "loss: 0.614569  [392000/525306]\n",
      "loss: 0.578142  [393600/525306]\n",
      "loss: 1.515708  [395200/525306]\n",
      "loss: 0.754533  [396800/525306]\n",
      "loss: 0.396840  [398400/525306]\n",
      "loss: 0.587096  [400000/525306]\n",
      "loss: 0.685878  [401600/525306]\n",
      "loss: 0.714807  [403200/525306]\n",
      "loss: 0.800108  [404800/525306]\n",
      "loss: 0.901630  [406400/525306]\n",
      "loss: 0.269716  [408000/525306]\n",
      "loss: 0.539386  [409600/525306]\n",
      "loss: 1.017401  [411200/525306]\n",
      "loss: 0.562683  [412800/525306]\n",
      "loss: 0.393214  [414400/525306]\n",
      "loss: 0.735051  [416000/525306]\n",
      "loss: 0.975928  [417600/525306]\n",
      "loss: 0.950266  [419200/525306]\n",
      "loss: 0.446520  [420800/525306]\n",
      "loss: 0.500473  [422400/525306]\n",
      "loss: 0.498401  [424000/525306]\n",
      "loss: 0.847482  [425600/525306]\n",
      "loss: 0.476859  [427200/525306]\n",
      "loss: 0.358025  [428800/525306]\n",
      "loss: 0.850944  [430400/525306]\n",
      "loss: 0.528889  [432000/525306]\n",
      "loss: 1.383948  [433600/525306]\n",
      "loss: 0.630003  [435200/525306]\n",
      "loss: 0.387820  [436800/525306]\n",
      "loss: 1.043022  [438400/525306]\n",
      "loss: 0.685758  [440000/525306]\n",
      "loss: 0.922659  [441600/525306]\n",
      "loss: 0.530993  [443200/525306]\n",
      "loss: 0.897484  [444800/525306]\n",
      "loss: 0.515617  [446400/525306]\n",
      "loss: 0.513157  [448000/525306]\n",
      "loss: 0.765862  [449600/525306]\n",
      "loss: 0.690559  [451200/525306]\n",
      "loss: 0.683564  [452800/525306]\n",
      "loss: 0.791510  [454400/525306]\n",
      "loss: 0.390719  [456000/525306]\n",
      "loss: 0.398662  [457600/525306]\n",
      "loss: 0.384216  [459200/525306]\n",
      "loss: 0.903979  [460800/525306]\n",
      "loss: 0.417306  [462400/525306]\n",
      "loss: 0.469843  [464000/525306]\n",
      "loss: 0.473061  [465600/525306]\n",
      "loss: 0.528304  [467200/525306]\n",
      "loss: 0.523136  [468800/525306]\n",
      "loss: 0.943648  [470400/525306]\n",
      "loss: 0.847450  [472000/525306]\n",
      "loss: 0.826476  [473600/525306]\n",
      "loss: 0.548766  [475200/525306]\n",
      "loss: 0.750135  [476800/525306]\n",
      "loss: 0.836131  [478400/525306]\n",
      "loss: 0.308258  [480000/525306]\n",
      "loss: 0.816789  [481600/525306]\n",
      "loss: 0.668554  [483200/525306]\n",
      "loss: 0.587010  [484800/525306]\n",
      "loss: 0.428292  [486400/525306]\n",
      "loss: 0.443330  [488000/525306]\n",
      "loss: 0.633198  [489600/525306]\n",
      "loss: 0.973871  [491200/525306]\n",
      "loss: 0.617616  [492800/525306]\n",
      "loss: 0.359861  [494400/525306]\n",
      "loss: 0.926376  [496000/525306]\n",
      "loss: 0.403928  [497600/525306]\n",
      "loss: 0.551011  [499200/525306]\n",
      "loss: 0.620331  [500800/525306]\n",
      "loss: 0.576270  [502400/525306]\n",
      "loss: 0.811976  [504000/525306]\n",
      "loss: 0.459016  [505600/525306]\n",
      "loss: 0.778974  [507200/525306]\n",
      "loss: 0.831857  [508800/525306]\n",
      "loss: 0.755695  [510400/525306]\n",
      "loss: 0.493133  [512000/525306]\n",
      "loss: 0.825491  [513600/525306]\n",
      "loss: 0.966394  [515200/525306]\n",
      "loss: 1.101243  [516800/525306]\n",
      "loss: 0.833013  [518400/525306]\n",
      "loss: 0.648488  [520000/525306]\n",
      "loss: 0.664248  [521600/525306]\n",
      "loss: 0.613674  [523200/525306]\n",
      "loss: 1.280928  [524800/525306]\n",
      "Train Accuracy: 73.5341%\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.860018, F1-score: 71.18%, Macro_F1-Score:  41.81%  \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.863566  [    0/525306]\n",
      "loss: 0.867564  [ 1600/525306]\n",
      "loss: 1.037873  [ 3200/525306]\n",
      "loss: 0.603946  [ 4800/525306]\n",
      "loss: 0.548832  [ 6400/525306]\n",
      "loss: 0.667708  [ 8000/525306]\n",
      "loss: 0.726903  [ 9600/525306]\n",
      "loss: 0.433257  [11200/525306]\n",
      "loss: 0.507101  [12800/525306]\n",
      "loss: 0.884399  [14400/525306]\n",
      "loss: 0.558094  [16000/525306]\n",
      "loss: 0.640676  [17600/525306]\n",
      "loss: 0.682554  [19200/525306]\n",
      "loss: 0.506827  [20800/525306]\n",
      "loss: 0.670146  [22400/525306]\n",
      "loss: 0.795869  [24000/525306]\n",
      "loss: 0.545589  [25600/525306]\n",
      "loss: 0.440349  [27200/525306]\n",
      "loss: 0.889181  [28800/525306]\n",
      "loss: 1.355583  [30400/525306]\n",
      "loss: 0.943630  [32000/525306]\n",
      "loss: 0.861771  [33600/525306]\n",
      "loss: 0.881474  [35200/525306]\n",
      "loss: 0.920399  [36800/525306]\n",
      "loss: 0.595557  [38400/525306]\n",
      "loss: 0.172775  [40000/525306]\n",
      "loss: 0.836067  [41600/525306]\n",
      "loss: 0.614629  [43200/525306]\n",
      "loss: 0.334458  [44800/525306]\n",
      "loss: 0.396799  [46400/525306]\n",
      "loss: 0.574893  [48000/525306]\n",
      "loss: 0.365101  [49600/525306]\n",
      "loss: 1.161609  [51200/525306]\n",
      "loss: 1.020968  [52800/525306]\n",
      "loss: 0.945966  [54400/525306]\n",
      "loss: 0.435642  [56000/525306]\n",
      "loss: 0.363025  [57600/525306]\n",
      "loss: 0.828591  [59200/525306]\n",
      "loss: 0.716196  [60800/525306]\n",
      "loss: 0.911006  [62400/525306]\n",
      "loss: 1.018141  [64000/525306]\n",
      "loss: 0.673103  [65600/525306]\n",
      "loss: 0.389708  [67200/525306]\n",
      "loss: 0.910783  [68800/525306]\n",
      "loss: 1.095196  [70400/525306]\n",
      "loss: 0.883691  [72000/525306]\n",
      "loss: 0.479932  [73600/525306]\n",
      "loss: 0.959343  [75200/525306]\n",
      "loss: 0.655457  [76800/525306]\n",
      "loss: 0.356446  [78400/525306]\n",
      "loss: 0.367103  [80000/525306]\n",
      "loss: 0.639537  [81600/525306]\n",
      "loss: 0.655284  [83200/525306]\n",
      "loss: 0.556294  [84800/525306]\n",
      "loss: 0.696632  [86400/525306]\n",
      "loss: 0.969674  [88000/525306]\n",
      "loss: 0.350951  [89600/525306]\n",
      "loss: 0.478975  [91200/525306]\n",
      "loss: 0.541260  [92800/525306]\n",
      "loss: 0.709469  [94400/525306]\n",
      "loss: 0.379025  [96000/525306]\n",
      "loss: 0.526483  [97600/525306]\n",
      "loss: 0.647817  [99200/525306]\n",
      "loss: 0.771721  [100800/525306]\n",
      "loss: 0.621623  [102400/525306]\n",
      "loss: 0.658961  [104000/525306]\n",
      "loss: 0.482094  [105600/525306]\n",
      "loss: 0.402716  [107200/525306]\n",
      "loss: 1.152578  [108800/525306]\n",
      "loss: 1.260329  [110400/525306]\n",
      "loss: 0.377487  [112000/525306]\n",
      "loss: 0.667816  [113600/525306]\n",
      "loss: 0.675541  [115200/525306]\n",
      "loss: 0.394636  [116800/525306]\n",
      "loss: 0.831517  [118400/525306]\n",
      "loss: 0.755673  [120000/525306]\n",
      "loss: 0.974309  [121600/525306]\n",
      "loss: 1.374659  [123200/525306]\n",
      "loss: 0.815817  [124800/525306]\n",
      "loss: 0.594467  [126400/525306]\n",
      "loss: 0.953966  [128000/525306]\n",
      "loss: 0.452785  [129600/525306]\n",
      "loss: 0.707602  [131200/525306]\n",
      "loss: 0.395496  [132800/525306]\n",
      "loss: 0.661098  [134400/525306]\n",
      "loss: 0.481341  [136000/525306]\n",
      "loss: 1.164945  [137600/525306]\n",
      "loss: 0.530531  [139200/525306]\n",
      "loss: 0.681591  [140800/525306]\n",
      "loss: 0.603698  [142400/525306]\n",
      "loss: 0.719958  [144000/525306]\n",
      "loss: 0.411119  [145600/525306]\n",
      "loss: 0.458967  [147200/525306]\n",
      "loss: 1.100245  [148800/525306]\n",
      "loss: 0.581213  [150400/525306]\n",
      "loss: 0.719557  [152000/525306]\n",
      "loss: 0.528248  [153600/525306]\n",
      "loss: 0.726815  [155200/525306]\n",
      "loss: 0.749887  [156800/525306]\n",
      "loss: 0.283362  [158400/525306]\n",
      "loss: 0.905451  [160000/525306]\n",
      "loss: 0.606746  [161600/525306]\n",
      "loss: 0.919754  [163200/525306]\n",
      "loss: 1.347221  [164800/525306]\n",
      "loss: 0.594580  [166400/525306]\n",
      "loss: 0.919080  [168000/525306]\n",
      "loss: 0.738313  [169600/525306]\n",
      "loss: 0.268282  [171200/525306]\n",
      "loss: 1.232234  [172800/525306]\n",
      "loss: 0.388602  [174400/525306]\n",
      "loss: 0.485210  [176000/525306]\n",
      "loss: 0.721228  [177600/525306]\n",
      "loss: 0.813680  [179200/525306]\n",
      "loss: 0.610237  [180800/525306]\n",
      "loss: 0.905013  [182400/525306]\n",
      "loss: 0.519003  [184000/525306]\n",
      "loss: 1.597216  [185600/525306]\n",
      "loss: 0.668239  [187200/525306]\n",
      "loss: 1.216590  [188800/525306]\n",
      "loss: 0.706150  [190400/525306]\n",
      "loss: 0.759153  [192000/525306]\n",
      "loss: 0.526824  [193600/525306]\n",
      "loss: 1.008951  [195200/525306]\n",
      "loss: 0.460048  [196800/525306]\n",
      "loss: 1.101772  [198400/525306]\n",
      "loss: 0.678009  [200000/525306]\n",
      "loss: 0.788811  [201600/525306]\n",
      "loss: 0.512113  [203200/525306]\n",
      "loss: 0.425878  [204800/525306]\n",
      "loss: 1.029579  [206400/525306]\n",
      "loss: 0.806848  [208000/525306]\n",
      "loss: 0.464282  [209600/525306]\n",
      "loss: 0.448979  [211200/525306]\n",
      "loss: 0.489787  [212800/525306]\n",
      "loss: 0.649377  [214400/525306]\n",
      "loss: 0.856685  [216000/525306]\n",
      "loss: 0.766437  [217600/525306]\n",
      "loss: 0.677551  [219200/525306]\n",
      "loss: 0.923251  [220800/525306]\n",
      "loss: 0.433038  [222400/525306]\n",
      "loss: 0.777521  [224000/525306]\n",
      "loss: 0.591699  [225600/525306]\n",
      "loss: 0.828664  [227200/525306]\n",
      "loss: 0.457447  [228800/525306]\n",
      "loss: 0.614057  [230400/525306]\n",
      "loss: 0.801402  [232000/525306]\n",
      "loss: 0.406158  [233600/525306]\n",
      "loss: 0.391048  [235200/525306]\n",
      "loss: 0.474931  [236800/525306]\n",
      "loss: 1.232855  [238400/525306]\n",
      "loss: 0.745153  [240000/525306]\n",
      "loss: 0.403209  [241600/525306]\n",
      "loss: 0.727167  [243200/525306]\n",
      "loss: 0.700435  [244800/525306]\n",
      "loss: 0.665799  [246400/525306]\n",
      "loss: 0.712680  [248000/525306]\n",
      "loss: 0.445141  [249600/525306]\n",
      "loss: 0.649746  [251200/525306]\n",
      "loss: 0.931270  [252800/525306]\n",
      "loss: 0.638032  [254400/525306]\n",
      "loss: 0.606490  [256000/525306]\n",
      "loss: 0.648199  [257600/525306]\n",
      "loss: 0.566327  [259200/525306]\n",
      "loss: 0.494371  [260800/525306]\n",
      "loss: 0.947474  [262400/525306]\n",
      "loss: 0.553443  [264000/525306]\n",
      "loss: 0.286217  [265600/525306]\n",
      "loss: 0.777616  [267200/525306]\n",
      "loss: 0.390689  [268800/525306]\n",
      "loss: 1.330018  [270400/525306]\n",
      "loss: 0.848140  [272000/525306]\n",
      "loss: 0.970834  [273600/525306]\n",
      "loss: 1.008935  [275200/525306]\n",
      "loss: 0.662407  [276800/525306]\n",
      "loss: 0.892433  [278400/525306]\n",
      "loss: 0.961205  [280000/525306]\n",
      "loss: 0.557970  [281600/525306]\n",
      "loss: 0.541908  [283200/525306]\n",
      "loss: 0.387022  [284800/525306]\n",
      "loss: 0.982729  [286400/525306]\n",
      "loss: 0.633669  [288000/525306]\n",
      "loss: 0.450632  [289600/525306]\n",
      "loss: 0.604704  [291200/525306]\n",
      "loss: 0.925349  [292800/525306]\n",
      "loss: 0.536527  [294400/525306]\n",
      "loss: 0.459108  [296000/525306]\n",
      "loss: 0.387593  [297600/525306]\n",
      "loss: 0.506728  [299200/525306]\n",
      "loss: 1.087409  [300800/525306]\n",
      "loss: 0.720442  [302400/525306]\n",
      "loss: 0.603258  [304000/525306]\n",
      "loss: 0.502203  [305600/525306]\n",
      "loss: 0.406486  [307200/525306]\n",
      "loss: 0.592451  [308800/525306]\n",
      "loss: 0.747870  [310400/525306]\n",
      "loss: 0.610257  [312000/525306]\n",
      "loss: 0.856488  [313600/525306]\n",
      "loss: 0.602140  [315200/525306]\n",
      "loss: 0.477107  [316800/525306]\n",
      "loss: 0.897207  [318400/525306]\n",
      "loss: 0.241145  [320000/525306]\n",
      "loss: 0.830878  [321600/525306]\n",
      "loss: 0.499403  [323200/525306]\n",
      "loss: 0.854497  [324800/525306]\n",
      "loss: 0.940693  [326400/525306]\n",
      "loss: 0.812135  [328000/525306]\n",
      "loss: 1.184917  [329600/525306]\n",
      "loss: 0.645274  [331200/525306]\n",
      "loss: 0.780726  [332800/525306]\n",
      "loss: 0.632679  [334400/525306]\n",
      "loss: 0.855571  [336000/525306]\n",
      "loss: 0.772158  [337600/525306]\n",
      "loss: 0.713215  [339200/525306]\n",
      "loss: 0.753253  [340800/525306]\n",
      "loss: 0.549980  [342400/525306]\n",
      "loss: 0.603960  [344000/525306]\n",
      "loss: 0.409661  [345600/525306]\n",
      "loss: 0.602228  [347200/525306]\n",
      "loss: 0.316269  [348800/525306]\n",
      "loss: 0.815564  [350400/525306]\n",
      "loss: 0.745601  [352000/525306]\n",
      "loss: 0.595437  [353600/525306]\n",
      "loss: 0.409476  [355200/525306]\n",
      "loss: 0.544474  [356800/525306]\n",
      "loss: 0.472679  [358400/525306]\n",
      "loss: 0.807309  [360000/525306]\n",
      "loss: 0.477427  [361600/525306]\n",
      "loss: 0.638053  [363200/525306]\n",
      "loss: 0.410123  [364800/525306]\n",
      "loss: 1.069322  [366400/525306]\n",
      "loss: 0.899653  [368000/525306]\n",
      "loss: 0.895824  [369600/525306]\n",
      "loss: 0.775746  [371200/525306]\n",
      "loss: 0.683752  [372800/525306]\n",
      "loss: 0.515736  [374400/525306]\n",
      "loss: 0.797771  [376000/525306]\n",
      "loss: 0.532982  [377600/525306]\n",
      "loss: 1.008168  [379200/525306]\n",
      "loss: 1.060799  [380800/525306]\n",
      "loss: 0.578152  [382400/525306]\n",
      "loss: 0.293083  [384000/525306]\n",
      "loss: 0.919232  [385600/525306]\n",
      "loss: 0.756909  [387200/525306]\n",
      "loss: 0.962241  [388800/525306]\n",
      "loss: 1.202585  [390400/525306]\n",
      "loss: 1.071758  [392000/525306]\n",
      "loss: 0.343510  [393600/525306]\n",
      "loss: 0.592078  [395200/525306]\n",
      "loss: 1.003521  [396800/525306]\n",
      "loss: 0.524654  [398400/525306]\n",
      "loss: 0.420961  [400000/525306]\n",
      "loss: 0.431092  [401600/525306]\n",
      "loss: 0.673243  [403200/525306]\n",
      "loss: 0.413181  [404800/525306]\n",
      "loss: 0.547180  [406400/525306]\n",
      "loss: 0.725377  [408000/525306]\n",
      "loss: 0.399269  [409600/525306]\n",
      "loss: 0.619160  [411200/525306]\n",
      "loss: 0.618564  [412800/525306]\n",
      "loss: 1.182810  [414400/525306]\n",
      "loss: 0.706330  [416000/525306]\n",
      "loss: 0.493991  [417600/525306]\n",
      "loss: 0.819791  [419200/525306]\n",
      "loss: 0.636613  [420800/525306]\n",
      "loss: 0.478367  [422400/525306]\n",
      "loss: 0.865979  [424000/525306]\n",
      "loss: 0.774950  [425600/525306]\n",
      "loss: 0.858725  [427200/525306]\n",
      "loss: 1.039465  [428800/525306]\n",
      "loss: 1.164595  [430400/525306]\n",
      "loss: 0.644539  [432000/525306]\n",
      "loss: 0.853491  [433600/525306]\n",
      "loss: 0.767085  [435200/525306]\n",
      "loss: 0.374331  [436800/525306]\n",
      "loss: 0.355061  [438400/525306]\n",
      "loss: 0.470436  [440000/525306]\n",
      "loss: 0.765027  [441600/525306]\n",
      "loss: 0.506819  [443200/525306]\n",
      "loss: 1.082141  [444800/525306]\n",
      "loss: 0.622617  [446400/525306]\n",
      "loss: 0.628401  [448000/525306]\n",
      "loss: 0.542924  [449600/525306]\n",
      "loss: 0.497217  [451200/525306]\n",
      "loss: 0.845616  [452800/525306]\n",
      "loss: 0.482628  [454400/525306]\n",
      "loss: 0.650410  [456000/525306]\n",
      "loss: 0.677441  [457600/525306]\n",
      "loss: 1.143551  [459200/525306]\n",
      "loss: 0.500917  [460800/525306]\n",
      "loss: 0.910506  [462400/525306]\n",
      "loss: 1.022388  [464000/525306]\n",
      "loss: 0.403121  [465600/525306]\n",
      "loss: 0.708188  [467200/525306]\n",
      "loss: 0.588782  [468800/525306]\n",
      "loss: 0.711142  [470400/525306]\n",
      "loss: 0.801935  [472000/525306]\n",
      "loss: 0.642794  [473600/525306]\n",
      "loss: 0.708446  [475200/525306]\n",
      "loss: 0.345403  [476800/525306]\n",
      "loss: 0.590907  [478400/525306]\n",
      "loss: 0.473416  [480000/525306]\n",
      "loss: 0.394043  [481600/525306]\n",
      "loss: 0.724092  [483200/525306]\n",
      "loss: 0.543182  [484800/525306]\n",
      "loss: 0.866272  [486400/525306]\n",
      "loss: 0.660338  [488000/525306]\n",
      "loss: 0.329687  [489600/525306]\n",
      "loss: 0.431387  [491200/525306]\n",
      "loss: 0.900791  [492800/525306]\n",
      "loss: 0.729542  [494400/525306]\n",
      "loss: 0.403535  [496000/525306]\n",
      "loss: 0.538587  [497600/525306]\n",
      "loss: 0.489227  [499200/525306]\n",
      "loss: 0.537889  [500800/525306]\n",
      "loss: 0.855836  [502400/525306]\n",
      "loss: 0.660321  [504000/525306]\n",
      "loss: 1.101201  [505600/525306]\n",
      "loss: 0.426750  [507200/525306]\n",
      "loss: 0.773378  [508800/525306]\n",
      "loss: 0.572037  [510400/525306]\n",
      "loss: 0.482358  [512000/525306]\n",
      "loss: 0.063884  [513600/525306]\n",
      "loss: 0.694521  [515200/525306]\n",
      "loss: 1.213138  [516800/525306]\n",
      "loss: 0.900058  [518400/525306]\n",
      "loss: 0.739998  [520000/525306]\n",
      "loss: 0.604448  [521600/525306]\n",
      "loss: 0.881320  [523200/525306]\n",
      "loss: 0.616154  [524800/525306]\n",
      "Train Accuracy: 73.5594%\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 0.941927, F1-score: 69.93%, Macro_F1-Score:  38.67%  \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001,weight_decay=1e-4)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\") k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fdafbf2b-d151-40e6-b9d2-35b65c2b9781",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.309941  [    0/525306]\n",
      "loss: 2.247578  [ 1600/525306]\n",
      "loss: 2.262057  [ 3200/525306]\n",
      "loss: 2.321743  [ 4800/525306]\n",
      "loss: 2.173556  [ 6400/525306]\n",
      "loss: 2.116397  [ 8000/525306]\n",
      "loss: 2.245455  [ 9600/525306]\n",
      "loss: 1.998780  [11200/525306]\n",
      "loss: 2.125493  [12800/525306]\n",
      "loss: 2.208004  [14400/525306]\n",
      "loss: 2.122947  [16000/525306]\n",
      "loss: 1.923572  [17600/525306]\n",
      "loss: 2.142982  [19200/525306]\n",
      "loss: 1.981627  [20800/525306]\n",
      "loss: 2.004133  [22400/525306]\n",
      "loss: 1.827319  [24000/525306]\n",
      "loss: 1.778176  [25600/525306]\n",
      "loss: 2.088956  [27200/525306]\n",
      "loss: 2.069673  [28800/525306]\n",
      "loss: 2.078050  [30400/525306]\n",
      "loss: 1.964544  [32000/525306]\n",
      "loss: 1.533457  [33600/525306]\n",
      "loss: 1.995542  [35200/525306]\n",
      "loss: 1.807556  [36800/525306]\n",
      "loss: 1.957354  [38400/525306]\n",
      "loss: 2.035468  [40000/525306]\n",
      "loss: 2.035608  [41600/525306]\n",
      "loss: 1.946472  [43200/525306]\n",
      "loss: 1.874613  [44800/525306]\n",
      "loss: 1.806409  [46400/525306]\n",
      "loss: 1.952912  [48000/525306]\n",
      "loss: 1.353044  [49600/525306]\n",
      "loss: 2.027754  [51200/525306]\n",
      "loss: 1.753679  [52800/525306]\n",
      "loss: 1.808837  [54400/525306]\n",
      "loss: 1.824513  [56000/525306]\n",
      "loss: 1.937926  [57600/525306]\n",
      "loss: 1.644949  [59200/525306]\n",
      "loss: 1.630470  [60800/525306]\n",
      "loss: 1.572908  [62400/525306]\n",
      "loss: 1.679526  [64000/525306]\n",
      "loss: 1.567570  [65600/525306]\n",
      "loss: 1.883735  [67200/525306]\n",
      "loss: 1.572647  [68800/525306]\n",
      "loss: 1.479323  [70400/525306]\n",
      "loss: 1.995914  [72000/525306]\n",
      "loss: 1.790767  [73600/525306]\n",
      "loss: 1.352189  [75200/525306]\n",
      "loss: 2.066865  [76800/525306]\n",
      "loss: 1.785872  [78400/525306]\n",
      "loss: 1.783175  [80000/525306]\n",
      "loss: 1.428601  [81600/525306]\n",
      "loss: 1.602424  [83200/525306]\n",
      "loss: 1.604258  [84800/525306]\n",
      "loss: 1.672092  [86400/525306]\n",
      "loss: 1.446112  [88000/525306]\n",
      "loss: 1.660626  [89600/525306]\n",
      "loss: 1.532513  [91200/525306]\n",
      "loss: 1.662732  [92800/525306]\n",
      "loss: 1.393851  [94400/525306]\n",
      "loss: 1.652411  [96000/525306]\n",
      "loss: 1.393801  [97600/525306]\n",
      "loss: 1.526210  [99200/525306]\n",
      "loss: 1.440710  [100800/525306]\n",
      "loss: 1.140557  [102400/525306]\n",
      "loss: 1.579907  [104000/525306]\n",
      "loss: 1.615602  [105600/525306]\n",
      "loss: 1.633216  [107200/525306]\n",
      "loss: 1.043852  [108800/525306]\n",
      "loss: 1.354798  [110400/525306]\n",
      "loss: 1.368777  [112000/525306]\n",
      "loss: 1.444777  [113600/525306]\n",
      "loss: 1.601522  [115200/525306]\n",
      "loss: 1.438231  [116800/525306]\n",
      "loss: 1.437541  [118400/525306]\n",
      "loss: 1.462569  [120000/525306]\n",
      "loss: 1.666746  [121600/525306]\n",
      "loss: 1.670591  [123200/525306]\n",
      "loss: 1.398831  [124800/525306]\n",
      "loss: 1.423020  [126400/525306]\n",
      "loss: 1.465740  [128000/525306]\n",
      "loss: 1.347927  [129600/525306]\n",
      "loss: 1.130971  [131200/525306]\n",
      "loss: 1.019051  [132800/525306]\n",
      "loss: 1.776584  [134400/525306]\n",
      "loss: 1.702227  [136000/525306]\n",
      "loss: 1.065324  [137600/525306]\n",
      "loss: 1.573131  [139200/525306]\n",
      "loss: 1.548252  [140800/525306]\n",
      "loss: 1.500076  [142400/525306]\n",
      "loss: 1.388909  [144000/525306]\n",
      "loss: 1.403570  [145600/525306]\n",
      "loss: 1.429953  [147200/525306]\n",
      "loss: 1.130429  [148800/525306]\n",
      "loss: 1.466805  [150400/525306]\n",
      "loss: 1.326984  [152000/525306]\n",
      "loss: 1.367030  [153600/525306]\n",
      "loss: 1.143191  [155200/525306]\n",
      "loss: 1.167271  [156800/525306]\n",
      "loss: 1.175337  [158400/525306]\n",
      "loss: 1.450710  [160000/525306]\n",
      "loss: 1.138977  [161600/525306]\n",
      "loss: 1.204082  [163200/525306]\n",
      "loss: 1.310525  [164800/525306]\n",
      "loss: 1.544188  [166400/525306]\n",
      "loss: 0.907621  [168000/525306]\n",
      "loss: 1.368990  [169600/525306]\n",
      "loss: 1.449131  [171200/525306]\n",
      "loss: 1.675514  [172800/525306]\n",
      "loss: 0.782886  [174400/525306]\n",
      "loss: 1.342846  [176000/525306]\n",
      "loss: 1.228403  [177600/525306]\n",
      "loss: 1.013888  [179200/525306]\n",
      "loss: 1.445803  [180800/525306]\n",
      "loss: 1.707166  [182400/525306]\n",
      "loss: 1.152156  [184000/525306]\n",
      "loss: 1.715255  [185600/525306]\n",
      "loss: 1.405645  [187200/525306]\n",
      "loss: 1.158036  [188800/525306]\n",
      "loss: 1.296502  [190400/525306]\n",
      "loss: 1.542246  [192000/525306]\n",
      "loss: 0.982127  [193600/525306]\n",
      "loss: 1.464868  [195200/525306]\n",
      "loss: 1.532498  [196800/525306]\n",
      "loss: 1.275224  [198400/525306]\n",
      "loss: 1.052162  [200000/525306]\n",
      "loss: 1.461293  [201600/525306]\n",
      "loss: 1.601648  [203200/525306]\n",
      "loss: 1.241899  [204800/525306]\n",
      "loss: 1.097327  [206400/525306]\n",
      "loss: 1.189816  [208000/525306]\n",
      "loss: 1.131291  [209600/525306]\n",
      "loss: 1.163014  [211200/525306]\n",
      "loss: 1.025838  [212800/525306]\n",
      "loss: 1.139379  [214400/525306]\n",
      "loss: 1.107349  [216000/525306]\n",
      "loss: 1.028727  [217600/525306]\n",
      "loss: 1.485136  [219200/525306]\n",
      "loss: 0.871714  [220800/525306]\n",
      "loss: 1.375042  [222400/525306]\n",
      "loss: 1.156900  [224000/525306]\n",
      "loss: 0.982967  [225600/525306]\n",
      "loss: 2.036998  [227200/525306]\n",
      "loss: 1.172856  [228800/525306]\n",
      "loss: 1.326910  [230400/525306]\n",
      "loss: 0.962614  [232000/525306]\n",
      "loss: 1.198101  [233600/525306]\n",
      "loss: 1.394280  [235200/525306]\n",
      "loss: 1.197619  [236800/525306]\n",
      "loss: 1.698692  [238400/525306]\n",
      "loss: 0.951379  [240000/525306]\n",
      "loss: 1.917000  [241600/525306]\n",
      "loss: 1.010531  [243200/525306]\n",
      "loss: 1.636155  [244800/525306]\n",
      "loss: 0.931772  [246400/525306]\n",
      "loss: 1.209501  [248000/525306]\n",
      "loss: 1.532054  [249600/525306]\n",
      "loss: 1.174527  [251200/525306]\n",
      "loss: 1.630171  [252800/525306]\n",
      "loss: 1.307498  [254400/525306]\n",
      "loss: 1.059409  [256000/525306]\n",
      "loss: 1.035794  [257600/525306]\n",
      "loss: 1.152725  [259200/525306]\n",
      "loss: 1.214210  [260800/525306]\n",
      "loss: 1.343224  [262400/525306]\n",
      "loss: 0.882958  [264000/525306]\n",
      "loss: 0.981141  [265600/525306]\n",
      "loss: 1.256900  [267200/525306]\n",
      "loss: 1.128312  [268800/525306]\n",
      "loss: 1.207791  [270400/525306]\n",
      "loss: 1.100561  [272000/525306]\n",
      "loss: 0.989826  [273600/525306]\n",
      "loss: 0.879511  [275200/525306]\n",
      "loss: 0.688818  [276800/525306]\n",
      "loss: 1.514277  [278400/525306]\n",
      "loss: 0.904868  [280000/525306]\n",
      "loss: 0.810545  [281600/525306]\n",
      "loss: 0.752748  [283200/525306]\n",
      "loss: 1.282731  [284800/525306]\n",
      "loss: 0.864649  [286400/525306]\n",
      "loss: 1.053966  [288000/525306]\n",
      "loss: 0.927611  [289600/525306]\n",
      "loss: 1.329922  [291200/525306]\n",
      "loss: 1.021150  [292800/525306]\n",
      "loss: 1.111351  [294400/525306]\n",
      "loss: 1.230656  [296000/525306]\n",
      "loss: 0.972568  [297600/525306]\n",
      "loss: 0.774580  [299200/525306]\n",
      "loss: 1.401120  [300800/525306]\n",
      "loss: 1.134852  [302400/525306]\n",
      "loss: 1.472483  [304000/525306]\n",
      "loss: 0.835981  [305600/525306]\n",
      "loss: 1.125572  [307200/525306]\n",
      "loss: 0.918340  [308800/525306]\n",
      "loss: 1.335006  [310400/525306]\n",
      "loss: 1.107950  [312000/525306]\n",
      "loss: 1.378718  [313600/525306]\n",
      "loss: 1.584980  [315200/525306]\n",
      "loss: 1.209717  [316800/525306]\n",
      "loss: 1.265117  [318400/525306]\n",
      "loss: 1.265472  [320000/525306]\n",
      "loss: 1.144618  [321600/525306]\n",
      "loss: 1.000010  [323200/525306]\n",
      "loss: 0.724978  [324800/525306]\n",
      "loss: 0.554870  [326400/525306]\n",
      "loss: 1.082907  [328000/525306]\n",
      "loss: 1.136877  [329600/525306]\n",
      "loss: 1.203249  [331200/525306]\n",
      "loss: 1.191451  [332800/525306]\n",
      "loss: 1.288469  [334400/525306]\n",
      "loss: 1.226986  [336000/525306]\n",
      "loss: 0.844740  [337600/525306]\n",
      "loss: 1.217487  [339200/525306]\n",
      "loss: 0.996534  [340800/525306]\n",
      "loss: 1.141852  [342400/525306]\n",
      "loss: 1.090225  [344000/525306]\n",
      "loss: 1.032216  [345600/525306]\n",
      "loss: 0.715744  [347200/525306]\n",
      "loss: 1.016073  [348800/525306]\n",
      "loss: 1.089862  [350400/525306]\n",
      "loss: 0.990226  [352000/525306]\n",
      "loss: 1.302708  [353600/525306]\n",
      "loss: 1.214787  [355200/525306]\n",
      "loss: 0.971730  [356800/525306]\n",
      "loss: 1.151307  [358400/525306]\n",
      "loss: 1.650949  [360000/525306]\n",
      "loss: 0.833911  [361600/525306]\n",
      "loss: 1.065749  [363200/525306]\n",
      "loss: 1.162247  [364800/525306]\n",
      "loss: 1.222594  [366400/525306]\n",
      "loss: 1.080586  [368000/525306]\n",
      "loss: 0.943801  [369600/525306]\n",
      "loss: 0.553930  [371200/525306]\n",
      "loss: 0.962412  [372800/525306]\n",
      "loss: 1.127077  [374400/525306]\n",
      "loss: 1.254903  [376000/525306]\n",
      "loss: 0.966863  [377600/525306]\n",
      "loss: 1.224184  [379200/525306]\n",
      "loss: 1.266982  [380800/525306]\n",
      "loss: 0.777643  [382400/525306]\n",
      "loss: 1.002281  [384000/525306]\n",
      "loss: 1.156031  [385600/525306]\n",
      "loss: 1.056140  [387200/525306]\n",
      "loss: 1.046260  [388800/525306]\n",
      "loss: 0.938451  [390400/525306]\n",
      "loss: 0.776676  [392000/525306]\n",
      "loss: 1.253148  [393600/525306]\n",
      "loss: 1.041509  [395200/525306]\n",
      "loss: 0.866989  [396800/525306]\n",
      "loss: 1.037733  [398400/525306]\n",
      "loss: 0.951381  [400000/525306]\n",
      "loss: 1.329231  [401600/525306]\n",
      "loss: 1.254854  [403200/525306]\n",
      "loss: 0.719207  [404800/525306]\n",
      "loss: 1.220142  [406400/525306]\n",
      "loss: 1.350437  [408000/525306]\n",
      "loss: 1.332576  [409600/525306]\n",
      "loss: 0.719888  [411200/525306]\n",
      "loss: 1.372668  [412800/525306]\n",
      "loss: 1.511237  [414400/525306]\n",
      "loss: 1.204898  [416000/525306]\n",
      "loss: 0.884229  [417600/525306]\n",
      "loss: 0.981943  [419200/525306]\n",
      "loss: 0.899688  [420800/525306]\n",
      "loss: 1.109776  [422400/525306]\n",
      "loss: 0.749308  [424000/525306]\n",
      "loss: 1.502164  [425600/525306]\n",
      "loss: 0.890538  [427200/525306]\n",
      "loss: 1.247596  [428800/525306]\n",
      "loss: 1.380082  [430400/525306]\n",
      "loss: 1.203254  [432000/525306]\n",
      "loss: 1.230473  [433600/525306]\n",
      "loss: 1.358946  [435200/525306]\n",
      "loss: 1.152751  [436800/525306]\n",
      "loss: 0.717647  [438400/525306]\n",
      "loss: 1.076753  [440000/525306]\n",
      "loss: 1.386528  [441600/525306]\n",
      "loss: 1.185977  [443200/525306]\n",
      "loss: 0.967572  [444800/525306]\n",
      "loss: 0.923311  [446400/525306]\n",
      "loss: 1.123784  [448000/525306]\n",
      "loss: 0.768244  [449600/525306]\n",
      "loss: 1.512059  [451200/525306]\n",
      "loss: 1.049135  [452800/525306]\n",
      "loss: 1.024844  [454400/525306]\n",
      "loss: 1.318256  [456000/525306]\n",
      "loss: 0.975486  [457600/525306]\n",
      "loss: 0.874934  [459200/525306]\n",
      "loss: 1.018363  [460800/525306]\n",
      "loss: 1.354374  [462400/525306]\n",
      "loss: 1.076705  [464000/525306]\n",
      "loss: 1.681308  [465600/525306]\n",
      "loss: 1.326214  [467200/525306]\n",
      "loss: 0.999984  [468800/525306]\n",
      "loss: 1.070390  [470400/525306]\n",
      "loss: 1.144856  [472000/525306]\n",
      "loss: 0.746370  [473600/525306]\n",
      "loss: 1.094921  [475200/525306]\n",
      "loss: 0.828735  [476800/525306]\n",
      "loss: 1.400977  [478400/525306]\n",
      "loss: 0.766755  [480000/525306]\n",
      "loss: 0.653201  [481600/525306]\n",
      "loss: 1.062861  [483200/525306]\n",
      "loss: 0.903131  [484800/525306]\n",
      "loss: 0.850722  [486400/525306]\n",
      "loss: 0.892269  [488000/525306]\n",
      "loss: 0.824414  [489600/525306]\n",
      "loss: 1.017714  [491200/525306]\n",
      "loss: 0.986278  [492800/525306]\n",
      "loss: 0.742494  [494400/525306]\n",
      "loss: 1.005738  [496000/525306]\n",
      "loss: 0.840408  [497600/525306]\n",
      "loss: 1.065679  [499200/525306]\n",
      "loss: 0.904821  [500800/525306]\n",
      "loss: 0.730020  [502400/525306]\n",
      "loss: 0.888333  [504000/525306]\n",
      "loss: 0.736866  [505600/525306]\n",
      "loss: 1.116447  [507200/525306]\n",
      "loss: 1.248619  [508800/525306]\n",
      "loss: 0.735279  [510400/525306]\n",
      "loss: 1.341270  [512000/525306]\n",
      "loss: 1.284264  [513600/525306]\n",
      "loss: 1.127059  [515200/525306]\n",
      "loss: 0.957670  [516800/525306]\n",
      "loss: 1.150754  [518400/525306]\n",
      "loss: 0.701932  [520000/525306]\n",
      "loss: 0.757025  [521600/525306]\n",
      "loss: 1.136603  [523200/525306]\n",
      "loss: 0.989674  [524800/525306]\n",
      "Train Accuracy: 53.7961%\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 1.121033, F1-score: 64.63%, Macro_F1-Score:  29.39%  \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.983395  [    0/525306]\n",
      "loss: 1.382730  [ 1600/525306]\n",
      "loss: 1.169121  [ 3200/525306]\n",
      "loss: 1.130811  [ 4800/525306]\n",
      "loss: 0.887347  [ 6400/525306]\n",
      "loss: 1.341404  [ 8000/525306]\n",
      "loss: 1.088594  [ 9600/525306]\n",
      "loss: 0.833705  [11200/525306]\n",
      "loss: 0.654699  [12800/525306]\n",
      "loss: 0.889987  [14400/525306]\n",
      "loss: 0.685329  [16000/525306]\n",
      "loss: 1.437518  [17600/525306]\n",
      "loss: 1.078796  [19200/525306]\n",
      "loss: 0.538345  [20800/525306]\n",
      "loss: 1.139351  [22400/525306]\n",
      "loss: 1.052592  [24000/525306]\n",
      "loss: 1.090261  [25600/525306]\n",
      "loss: 0.988629  [27200/525306]\n",
      "loss: 0.865176  [28800/525306]\n",
      "loss: 1.030319  [30400/525306]\n",
      "loss: 0.982265  [32000/525306]\n",
      "loss: 1.118186  [33600/525306]\n",
      "loss: 1.693957  [35200/525306]\n",
      "loss: 0.646778  [36800/525306]\n",
      "loss: 0.941487  [38400/525306]\n",
      "loss: 0.585541  [40000/525306]\n",
      "loss: 1.074770  [41600/525306]\n",
      "loss: 0.902614  [43200/525306]\n",
      "loss: 0.639397  [44800/525306]\n",
      "loss: 1.006432  [46400/525306]\n",
      "loss: 1.143723  [48000/525306]\n",
      "loss: 0.818636  [49600/525306]\n",
      "loss: 1.114901  [51200/525306]\n",
      "loss: 1.182244  [52800/525306]\n",
      "loss: 1.041508  [54400/525306]\n",
      "loss: 1.141041  [56000/525306]\n",
      "loss: 1.320581  [57600/525306]\n",
      "loss: 0.985939  [59200/525306]\n",
      "loss: 0.886565  [60800/525306]\n",
      "loss: 0.846221  [62400/525306]\n",
      "loss: 0.869099  [64000/525306]\n",
      "loss: 0.748344  [65600/525306]\n",
      "loss: 1.644040  [67200/525306]\n",
      "loss: 1.042074  [68800/525306]\n",
      "loss: 1.341610  [70400/525306]\n",
      "loss: 0.886380  [72000/525306]\n",
      "loss: 0.952636  [73600/525306]\n",
      "loss: 0.839202  [75200/525306]\n",
      "loss: 1.013070  [76800/525306]\n",
      "loss: 1.128068  [78400/525306]\n",
      "loss: 1.003388  [80000/525306]\n",
      "loss: 0.799866  [81600/525306]\n",
      "loss: 1.029595  [83200/525306]\n",
      "loss: 1.221466  [84800/525306]\n",
      "loss: 1.004648  [86400/525306]\n",
      "loss: 1.011481  [88000/525306]\n",
      "loss: 1.319782  [89600/525306]\n",
      "loss: 0.973304  [91200/525306]\n",
      "loss: 1.201816  [92800/525306]\n",
      "loss: 0.657353  [94400/525306]\n",
      "loss: 1.215466  [96000/525306]\n",
      "loss: 1.252738  [97600/525306]\n",
      "loss: 0.907568  [99200/525306]\n",
      "loss: 1.451890  [100800/525306]\n",
      "loss: 1.272123  [102400/525306]\n",
      "loss: 1.299421  [104000/525306]\n",
      "loss: 0.738600  [105600/525306]\n",
      "loss: 1.148003  [107200/525306]\n",
      "loss: 1.214584  [108800/525306]\n",
      "loss: 0.903757  [110400/525306]\n",
      "loss: 0.615249  [112000/525306]\n",
      "loss: 0.701187  [113600/525306]\n",
      "loss: 0.753084  [115200/525306]\n",
      "loss: 0.879657  [116800/525306]\n",
      "loss: 1.037754  [118400/525306]\n",
      "loss: 0.871093  [120000/525306]\n",
      "loss: 1.671456  [121600/525306]\n",
      "loss: 1.057049  [123200/525306]\n",
      "loss: 0.831166  [124800/525306]\n",
      "loss: 1.019860  [126400/525306]\n",
      "loss: 1.381511  [128000/525306]\n",
      "loss: 0.871583  [129600/525306]\n",
      "loss: 0.838105  [131200/525306]\n",
      "loss: 0.646586  [132800/525306]\n",
      "loss: 1.111147  [134400/525306]\n",
      "loss: 0.557601  [136000/525306]\n",
      "loss: 1.139555  [137600/525306]\n",
      "loss: 0.783893  [139200/525306]\n",
      "loss: 0.865105  [140800/525306]\n",
      "loss: 1.272965  [142400/525306]\n",
      "loss: 0.950707  [144000/525306]\n",
      "loss: 1.044639  [145600/525306]\n",
      "loss: 0.865351  [147200/525306]\n",
      "loss: 0.854377  [148800/525306]\n",
      "loss: 0.977175  [150400/525306]\n",
      "loss: 0.933256  [152000/525306]\n",
      "loss: 1.108121  [153600/525306]\n",
      "loss: 1.174555  [155200/525306]\n",
      "loss: 0.890053  [156800/525306]\n",
      "loss: 0.828483  [158400/525306]\n",
      "loss: 1.776427  [160000/525306]\n",
      "loss: 0.725599  [161600/525306]\n",
      "loss: 1.064390  [163200/525306]\n",
      "loss: 0.969525  [164800/525306]\n",
      "loss: 0.839231  [166400/525306]\n",
      "loss: 0.979332  [168000/525306]\n",
      "loss: 0.873949  [169600/525306]\n",
      "loss: 1.329080  [171200/525306]\n",
      "loss: 1.123040  [172800/525306]\n",
      "loss: 0.989572  [174400/525306]\n",
      "loss: 0.526624  [176000/525306]\n",
      "loss: 0.894294  [177600/525306]\n",
      "loss: 1.077913  [179200/525306]\n",
      "loss: 1.070057  [180800/525306]\n",
      "loss: 1.095533  [182400/525306]\n",
      "loss: 0.981147  [184000/525306]\n",
      "loss: 0.866306  [185600/525306]\n",
      "loss: 0.828104  [187200/525306]\n",
      "loss: 0.640513  [188800/525306]\n",
      "loss: 0.831742  [190400/525306]\n",
      "loss: 0.948957  [192000/525306]\n",
      "loss: 1.281391  [193600/525306]\n",
      "loss: 0.988105  [195200/525306]\n",
      "loss: 0.932987  [196800/525306]\n",
      "loss: 1.302300  [198400/525306]\n",
      "loss: 1.037002  [200000/525306]\n",
      "loss: 1.391336  [201600/525306]\n",
      "loss: 0.984564  [203200/525306]\n",
      "loss: 1.165716  [204800/525306]\n",
      "loss: 1.098134  [206400/525306]\n",
      "loss: 1.347580  [208000/525306]\n",
      "loss: 0.765822  [209600/525306]\n",
      "loss: 1.055811  [211200/525306]\n",
      "loss: 0.821950  [212800/525306]\n",
      "loss: 1.134406  [214400/525306]\n",
      "loss: 1.662264  [216000/525306]\n",
      "loss: 1.279812  [217600/525306]\n",
      "loss: 0.965731  [219200/525306]\n",
      "loss: 1.016678  [220800/525306]\n",
      "loss: 1.453064  [222400/525306]\n",
      "loss: 1.063713  [224000/525306]\n",
      "loss: 0.783372  [225600/525306]\n",
      "loss: 0.569910  [227200/525306]\n",
      "loss: 1.105162  [228800/525306]\n",
      "loss: 1.334986  [230400/525306]\n",
      "loss: 0.579782  [232000/525306]\n",
      "loss: 0.791244  [233600/525306]\n",
      "loss: 0.570681  [235200/525306]\n",
      "loss: 1.438658  [236800/525306]\n",
      "loss: 1.004400  [238400/525306]\n",
      "loss: 1.199470  [240000/525306]\n",
      "loss: 0.705443  [241600/525306]\n",
      "loss: 0.765025  [243200/525306]\n",
      "loss: 0.767952  [244800/525306]\n",
      "loss: 0.728902  [246400/525306]\n",
      "loss: 1.607996  [248000/525306]\n",
      "loss: 0.963081  [249600/525306]\n",
      "loss: 0.587318  [251200/525306]\n",
      "loss: 1.204369  [252800/525306]\n",
      "loss: 0.911393  [254400/525306]\n",
      "loss: 1.493070  [256000/525306]\n",
      "loss: 1.050843  [257600/525306]\n",
      "loss: 1.047042  [259200/525306]\n",
      "loss: 0.952013  [260800/525306]\n",
      "loss: 0.978484  [262400/525306]\n",
      "loss: 0.918835  [264000/525306]\n",
      "loss: 0.831980  [265600/525306]\n",
      "loss: 0.791108  [267200/525306]\n",
      "loss: 1.137967  [268800/525306]\n",
      "loss: 1.103441  [270400/525306]\n",
      "loss: 0.894470  [272000/525306]\n",
      "loss: 1.057346  [273600/525306]\n",
      "loss: 0.777323  [275200/525306]\n",
      "loss: 0.960288  [276800/525306]\n",
      "loss: 0.685917  [278400/525306]\n",
      "loss: 1.120189  [280000/525306]\n",
      "loss: 0.766939  [281600/525306]\n",
      "loss: 1.336289  [283200/525306]\n",
      "loss: 0.793467  [284800/525306]\n",
      "loss: 1.734702  [286400/525306]\n",
      "loss: 1.044441  [288000/525306]\n",
      "loss: 0.601408  [289600/525306]\n",
      "loss: 0.730462  [291200/525306]\n",
      "loss: 0.709715  [292800/525306]\n",
      "loss: 0.721622  [294400/525306]\n",
      "loss: 1.308234  [296000/525306]\n",
      "loss: 0.619967  [297600/525306]\n",
      "loss: 0.929106  [299200/525306]\n",
      "loss: 0.468175  [300800/525306]\n",
      "loss: 0.905178  [302400/525306]\n",
      "loss: 1.163659  [304000/525306]\n",
      "loss: 0.832852  [305600/525306]\n",
      "loss: 0.836270  [307200/525306]\n",
      "loss: 0.576004  [308800/525306]\n",
      "loss: 0.968956  [310400/525306]\n",
      "loss: 1.006617  [312000/525306]\n",
      "loss: 0.871108  [313600/525306]\n",
      "loss: 0.777331  [315200/525306]\n",
      "loss: 1.142631  [316800/525306]\n",
      "loss: 0.714583  [318400/525306]\n",
      "loss: 1.000264  [320000/525306]\n",
      "loss: 0.801850  [321600/525306]\n",
      "loss: 0.809910  [323200/525306]\n",
      "loss: 1.131112  [324800/525306]\n",
      "loss: 0.670278  [326400/525306]\n",
      "loss: 0.845947  [328000/525306]\n",
      "loss: 1.011945  [329600/525306]\n",
      "loss: 0.669242  [331200/525306]\n",
      "loss: 1.522818  [332800/525306]\n",
      "loss: 1.003827  [334400/525306]\n",
      "loss: 0.937723  [336000/525306]\n",
      "loss: 1.361707  [337600/525306]\n",
      "loss: 0.660175  [339200/525306]\n",
      "loss: 0.409201  [340800/525306]\n",
      "loss: 0.895649  [342400/525306]\n",
      "loss: 0.817913  [344000/525306]\n",
      "loss: 1.599140  [345600/525306]\n",
      "loss: 1.400952  [347200/525306]\n",
      "loss: 0.854385  [348800/525306]\n",
      "loss: 0.858184  [350400/525306]\n",
      "loss: 0.757903  [352000/525306]\n",
      "loss: 1.041079  [353600/525306]\n",
      "loss: 1.099087  [355200/525306]\n",
      "loss: 1.004532  [356800/525306]\n",
      "loss: 1.399937  [358400/525306]\n",
      "loss: 1.118958  [360000/525306]\n",
      "loss: 0.887233  [361600/525306]\n",
      "loss: 0.966691  [363200/525306]\n",
      "loss: 1.140929  [364800/525306]\n",
      "loss: 1.031432  [366400/525306]\n",
      "loss: 1.226144  [368000/525306]\n",
      "loss: 0.815100  [369600/525306]\n",
      "loss: 0.694922  [371200/525306]\n",
      "loss: 1.298308  [372800/525306]\n",
      "loss: 0.817908  [374400/525306]\n",
      "loss: 1.427461  [376000/525306]\n",
      "loss: 0.968878  [377600/525306]\n",
      "loss: 1.499347  [379200/525306]\n",
      "loss: 1.427777  [380800/525306]\n",
      "loss: 1.108760  [382400/525306]\n",
      "loss: 0.858661  [384000/525306]\n",
      "loss: 0.618882  [385600/525306]\n",
      "loss: 1.099557  [387200/525306]\n",
      "loss: 0.877734  [388800/525306]\n",
      "loss: 1.163599  [390400/525306]\n",
      "loss: 1.253843  [392000/525306]\n",
      "loss: 0.930374  [393600/525306]\n",
      "loss: 0.660787  [395200/525306]\n",
      "loss: 1.090256  [396800/525306]\n",
      "loss: 1.195593  [398400/525306]\n",
      "loss: 1.026587  [400000/525306]\n",
      "loss: 1.343185  [401600/525306]\n",
      "loss: 0.902547  [403200/525306]\n",
      "loss: 1.374955  [404800/525306]\n",
      "loss: 0.664800  [406400/525306]\n",
      "loss: 0.943853  [408000/525306]\n",
      "loss: 1.153158  [409600/525306]\n",
      "loss: 0.985220  [411200/525306]\n",
      "loss: 0.495508  [412800/525306]\n",
      "loss: 0.642564  [414400/525306]\n",
      "loss: 0.861782  [416000/525306]\n",
      "loss: 0.822767  [417600/525306]\n",
      "loss: 1.492287  [419200/525306]\n",
      "loss: 1.504394  [420800/525306]\n",
      "loss: 0.769168  [422400/525306]\n",
      "loss: 1.097764  [424000/525306]\n",
      "loss: 1.091117  [425600/525306]\n",
      "loss: 0.941960  [427200/525306]\n",
      "loss: 1.381152  [428800/525306]\n",
      "loss: 0.610011  [430400/525306]\n",
      "loss: 0.996736  [432000/525306]\n",
      "loss: 0.587357  [433600/525306]\n",
      "loss: 0.944185  [435200/525306]\n",
      "loss: 0.785015  [436800/525306]\n",
      "loss: 0.775173  [438400/525306]\n",
      "loss: 0.884342  [440000/525306]\n",
      "loss: 1.261108  [441600/525306]\n",
      "loss: 0.980607  [443200/525306]\n",
      "loss: 0.848472  [444800/525306]\n",
      "loss: 1.039141  [446400/525306]\n",
      "loss: 1.142100  [448000/525306]\n",
      "loss: 1.212905  [449600/525306]\n",
      "loss: 0.666779  [451200/525306]\n",
      "loss: 0.944151  [452800/525306]\n",
      "loss: 0.968665  [454400/525306]\n",
      "loss: 1.227311  [456000/525306]\n",
      "loss: 0.791183  [457600/525306]\n",
      "loss: 0.856486  [459200/525306]\n",
      "loss: 0.815400  [460800/525306]\n",
      "loss: 1.067824  [462400/525306]\n",
      "loss: 0.890096  [464000/525306]\n",
      "loss: 0.775195  [465600/525306]\n",
      "loss: 0.865203  [467200/525306]\n",
      "loss: 0.519674  [468800/525306]\n",
      "loss: 0.975414  [470400/525306]\n",
      "loss: 1.013654  [472000/525306]\n",
      "loss: 0.736168  [473600/525306]\n",
      "loss: 0.637641  [475200/525306]\n",
      "loss: 0.990301  [476800/525306]\n",
      "loss: 0.560089  [478400/525306]\n",
      "loss: 0.835751  [480000/525306]\n",
      "loss: 0.847320  [481600/525306]\n",
      "loss: 0.854148  [483200/525306]\n",
      "loss: 0.883509  [484800/525306]\n",
      "loss: 0.786612  [486400/525306]\n",
      "loss: 1.026218  [488000/525306]\n",
      "loss: 1.061552  [489600/525306]\n",
      "loss: 0.890430  [491200/525306]\n",
      "loss: 0.920341  [492800/525306]\n",
      "loss: 0.943277  [494400/525306]\n",
      "loss: 1.363355  [496000/525306]\n",
      "loss: 1.008736  [497600/525306]\n",
      "loss: 0.430304  [499200/525306]\n",
      "loss: 0.733760  [500800/525306]\n",
      "loss: 0.891774  [502400/525306]\n",
      "loss: 0.850478  [504000/525306]\n",
      "loss: 0.482400  [505600/525306]\n",
      "loss: 0.987401  [507200/525306]\n",
      "loss: 1.618078  [508800/525306]\n",
      "loss: 1.063712  [510400/525306]\n",
      "loss: 0.726008  [512000/525306]\n",
      "loss: 1.538342  [513600/525306]\n",
      "loss: 0.765603  [515200/525306]\n",
      "loss: 0.989156  [516800/525306]\n",
      "loss: 0.787423  [518400/525306]\n",
      "loss: 1.147940  [520000/525306]\n",
      "loss: 1.077784  [521600/525306]\n",
      "loss: 1.663752  [523200/525306]\n",
      "loss: 1.158456  [524800/525306]\n",
      "Train Accuracy: 63.8363%\n",
      "Test Error: \n",
      " Accuracy: 60.5%, Avg loss: 1.054782, F1-score: 66.98%, Macro_F1-Score:  35.17%  \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.714961  [    0/525306]\n",
      "loss: 0.465147  [ 1600/525306]\n",
      "loss: 0.936290  [ 3200/525306]\n",
      "loss: 0.910713  [ 4800/525306]\n",
      "loss: 1.768636  [ 6400/525306]\n",
      "loss: 1.600989  [ 8000/525306]\n",
      "loss: 0.880980  [ 9600/525306]\n",
      "loss: 0.818762  [11200/525306]\n",
      "loss: 0.463421  [12800/525306]\n",
      "loss: 0.811175  [14400/525306]\n",
      "loss: 0.762210  [16000/525306]\n",
      "loss: 0.790509  [17600/525306]\n",
      "loss: 1.046815  [19200/525306]\n",
      "loss: 0.821253  [20800/525306]\n",
      "loss: 0.855192  [22400/525306]\n",
      "loss: 0.671119  [24000/525306]\n",
      "loss: 0.753858  [25600/525306]\n",
      "loss: 0.651745  [27200/525306]\n",
      "loss: 0.804863  [28800/525306]\n",
      "loss: 1.077834  [30400/525306]\n",
      "loss: 0.736135  [32000/525306]\n",
      "loss: 0.849148  [33600/525306]\n",
      "loss: 1.063175  [35200/525306]\n",
      "loss: 1.033434  [36800/525306]\n",
      "loss: 0.679816  [38400/525306]\n",
      "loss: 0.935923  [40000/525306]\n",
      "loss: 0.651425  [41600/525306]\n",
      "loss: 0.759701  [43200/525306]\n",
      "loss: 1.099440  [44800/525306]\n",
      "loss: 1.360265  [46400/525306]\n",
      "loss: 1.505833  [48000/525306]\n",
      "loss: 0.565437  [49600/525306]\n",
      "loss: 1.014728  [51200/525306]\n",
      "loss: 0.796166  [52800/525306]\n",
      "loss: 0.930000  [54400/525306]\n",
      "loss: 0.791386  [56000/525306]\n",
      "loss: 0.987424  [57600/525306]\n",
      "loss: 0.701553  [59200/525306]\n",
      "loss: 1.221609  [60800/525306]\n",
      "loss: 0.916909  [62400/525306]\n",
      "loss: 0.902043  [64000/525306]\n",
      "loss: 1.621215  [65600/525306]\n",
      "loss: 1.310453  [67200/525306]\n",
      "loss: 0.891433  [68800/525306]\n",
      "loss: 1.330387  [70400/525306]\n",
      "loss: 0.961673  [72000/525306]\n",
      "loss: 0.752922  [73600/525306]\n",
      "loss: 1.228961  [75200/525306]\n",
      "loss: 1.013305  [76800/525306]\n",
      "loss: 1.162297  [78400/525306]\n",
      "loss: 0.871059  [80000/525306]\n",
      "loss: 1.776100  [81600/525306]\n",
      "loss: 1.493985  [83200/525306]\n",
      "loss: 1.573045  [84800/525306]\n",
      "loss: 0.647853  [86400/525306]\n",
      "loss: 0.899786  [88000/525306]\n",
      "loss: 0.842905  [89600/525306]\n",
      "loss: 0.745890  [91200/525306]\n",
      "loss: 0.658801  [92800/525306]\n",
      "loss: 0.460829  [94400/525306]\n",
      "loss: 0.984907  [96000/525306]\n",
      "loss: 0.813960  [97600/525306]\n",
      "loss: 0.885720  [99200/525306]\n",
      "loss: 1.150550  [100800/525306]\n",
      "loss: 0.940400  [102400/525306]\n",
      "loss: 0.915831  [104000/525306]\n",
      "loss: 1.024840  [105600/525306]\n",
      "loss: 0.847118  [107200/525306]\n",
      "loss: 1.271810  [108800/525306]\n",
      "loss: 0.671017  [110400/525306]\n",
      "loss: 0.831165  [112000/525306]\n",
      "loss: 0.925353  [113600/525306]\n",
      "loss: 0.679503  [115200/525306]\n",
      "loss: 0.711080  [116800/525306]\n",
      "loss: 0.775443  [118400/525306]\n",
      "loss: 1.362398  [120000/525306]\n",
      "loss: 1.022815  [121600/525306]\n",
      "loss: 0.915269  [123200/525306]\n",
      "loss: 0.593246  [124800/525306]\n",
      "loss: 0.598202  [126400/525306]\n",
      "loss: 1.161563  [128000/525306]\n",
      "loss: 0.594794  [129600/525306]\n",
      "loss: 0.873030  [131200/525306]\n",
      "loss: 1.206784  [132800/525306]\n",
      "loss: 0.940899  [134400/525306]\n",
      "loss: 0.903648  [136000/525306]\n",
      "loss: 1.269095  [137600/525306]\n",
      "loss: 0.918308  [139200/525306]\n",
      "loss: 1.204829  [140800/525306]\n",
      "loss: 0.799169  [142400/525306]\n",
      "loss: 0.852304  [144000/525306]\n",
      "loss: 0.459853  [145600/525306]\n",
      "loss: 0.850186  [147200/525306]\n",
      "loss: 1.177264  [148800/525306]\n",
      "loss: 1.147374  [150400/525306]\n",
      "loss: 0.833383  [152000/525306]\n",
      "loss: 0.686185  [153600/525306]\n",
      "loss: 0.805611  [155200/525306]\n",
      "loss: 0.755364  [156800/525306]\n",
      "loss: 0.710376  [158400/525306]\n",
      "loss: 0.985221  [160000/525306]\n",
      "loss: 0.779132  [161600/525306]\n",
      "loss: 1.178094  [163200/525306]\n",
      "loss: 0.436479  [164800/525306]\n",
      "loss: 1.561874  [166400/525306]\n",
      "loss: 0.766075  [168000/525306]\n",
      "loss: 1.368539  [169600/525306]\n",
      "loss: 1.086147  [171200/525306]\n",
      "loss: 1.385059  [172800/525306]\n",
      "loss: 0.739243  [174400/525306]\n",
      "loss: 1.038555  [176000/525306]\n",
      "loss: 0.690790  [177600/525306]\n",
      "loss: 1.017504  [179200/525306]\n",
      "loss: 0.800852  [180800/525306]\n",
      "loss: 0.452026  [182400/525306]\n",
      "loss: 0.959451  [184000/525306]\n",
      "loss: 0.836959  [185600/525306]\n",
      "loss: 0.742267  [187200/525306]\n",
      "loss: 1.027628  [188800/525306]\n",
      "loss: 1.718784  [190400/525306]\n",
      "loss: 0.834688  [192000/525306]\n",
      "loss: 0.813204  [193600/525306]\n",
      "loss: 0.931490  [195200/525306]\n",
      "loss: 1.413998  [196800/525306]\n",
      "loss: 0.586812  [198400/525306]\n",
      "loss: 1.095766  [200000/525306]\n",
      "loss: 1.094925  [201600/525306]\n",
      "loss: 0.968491  [203200/525306]\n",
      "loss: 0.753535  [204800/525306]\n",
      "loss: 0.946182  [206400/525306]\n",
      "loss: 1.558654  [208000/525306]\n",
      "loss: 0.941866  [209600/525306]\n",
      "loss: 1.043046  [211200/525306]\n",
      "loss: 0.980293  [212800/525306]\n",
      "loss: 0.961091  [214400/525306]\n",
      "loss: 1.067814  [216000/525306]\n",
      "loss: 1.157879  [217600/525306]\n",
      "loss: 1.066275  [219200/525306]\n",
      "loss: 0.711999  [220800/525306]\n",
      "loss: 0.576199  [222400/525306]\n",
      "loss: 0.875249  [224000/525306]\n",
      "loss: 0.714496  [225600/525306]\n",
      "loss: 0.986499  [227200/525306]\n",
      "loss: 1.372402  [228800/525306]\n",
      "loss: 1.395560  [230400/525306]\n",
      "loss: 1.321020  [232000/525306]\n",
      "loss: 1.038755  [233600/525306]\n",
      "loss: 1.342608  [235200/525306]\n",
      "loss: 1.020431  [236800/525306]\n",
      "loss: 0.527973  [238400/525306]\n",
      "loss: 1.446100  [240000/525306]\n",
      "loss: 0.861703  [241600/525306]\n",
      "loss: 1.234507  [243200/525306]\n",
      "loss: 1.043734  [244800/525306]\n",
      "loss: 0.644456  [246400/525306]\n",
      "loss: 1.407488  [248000/525306]\n",
      "loss: 0.951078  [249600/525306]\n",
      "loss: 0.784247  [251200/525306]\n",
      "loss: 1.017389  [252800/525306]\n",
      "loss: 0.691853  [254400/525306]\n",
      "loss: 0.682138  [256000/525306]\n",
      "loss: 0.784333  [257600/525306]\n",
      "loss: 0.327458  [259200/525306]\n",
      "loss: 0.767303  [260800/525306]\n",
      "loss: 1.138149  [262400/525306]\n",
      "loss: 0.543560  [264000/525306]\n",
      "loss: 1.121610  [265600/525306]\n",
      "loss: 0.525529  [267200/525306]\n",
      "loss: 0.679009  [268800/525306]\n",
      "loss: 0.816097  [270400/525306]\n",
      "loss: 0.996588  [272000/525306]\n",
      "loss: 0.726335  [273600/525306]\n",
      "loss: 0.982374  [275200/525306]\n",
      "loss: 0.752343  [276800/525306]\n",
      "loss: 0.971966  [278400/525306]\n",
      "loss: 1.189337  [280000/525306]\n",
      "loss: 0.667559  [281600/525306]\n",
      "loss: 0.799779  [283200/525306]\n",
      "loss: 1.147254  [284800/525306]\n",
      "loss: 0.601390  [286400/525306]\n",
      "loss: 0.678415  [288000/525306]\n",
      "loss: 1.090126  [289600/525306]\n",
      "loss: 1.400942  [291200/525306]\n",
      "loss: 1.077857  [292800/525306]\n",
      "loss: 0.821157  [294400/525306]\n",
      "loss: 1.287691  [296000/525306]\n",
      "loss: 0.593866  [297600/525306]\n",
      "loss: 1.022267  [299200/525306]\n",
      "loss: 1.128708  [300800/525306]\n",
      "loss: 0.973898  [302400/525306]\n",
      "loss: 0.919423  [304000/525306]\n",
      "loss: 1.057477  [305600/525306]\n",
      "loss: 0.938753  [307200/525306]\n",
      "loss: 0.973526  [308800/525306]\n",
      "loss: 0.793815  [310400/525306]\n",
      "loss: 0.942931  [312000/525306]\n",
      "loss: 0.835252  [313600/525306]\n",
      "loss: 0.899431  [315200/525306]\n",
      "loss: 1.010999  [316800/525306]\n",
      "loss: 0.666700  [318400/525306]\n",
      "loss: 1.067446  [320000/525306]\n",
      "loss: 0.997814  [321600/525306]\n",
      "loss: 0.987130  [323200/525306]\n",
      "loss: 0.610675  [324800/525306]\n",
      "loss: 1.468684  [326400/525306]\n",
      "loss: 0.536943  [328000/525306]\n",
      "loss: 1.112295  [329600/525306]\n",
      "loss: 1.045236  [331200/525306]\n",
      "loss: 0.913321  [332800/525306]\n",
      "loss: 0.815494  [334400/525306]\n",
      "loss: 0.742409  [336000/525306]\n",
      "loss: 0.921307  [337600/525306]\n",
      "loss: 0.970482  [339200/525306]\n",
      "loss: 1.039405  [340800/525306]\n",
      "loss: 0.919942  [342400/525306]\n",
      "loss: 0.740962  [344000/525306]\n",
      "loss: 1.230743  [345600/525306]\n",
      "loss: 0.823537  [347200/525306]\n",
      "loss: 0.784593  [348800/525306]\n",
      "loss: 1.103999  [350400/525306]\n",
      "loss: 0.440146  [352000/525306]\n",
      "loss: 1.069763  [353600/525306]\n",
      "loss: 0.694024  [355200/525306]\n",
      "loss: 0.905467  [356800/525306]\n",
      "loss: 1.083386  [358400/525306]\n",
      "loss: 1.174009  [360000/525306]\n",
      "loss: 0.952210  [361600/525306]\n",
      "loss: 1.041830  [363200/525306]\n",
      "loss: 1.461401  [364800/525306]\n",
      "loss: 0.869806  [366400/525306]\n",
      "loss: 0.789804  [368000/525306]\n",
      "loss: 0.922822  [369600/525306]\n",
      "loss: 1.038333  [371200/525306]\n",
      "loss: 0.759404  [372800/525306]\n",
      "loss: 1.005776  [374400/525306]\n",
      "loss: 0.837994  [376000/525306]\n",
      "loss: 1.165895  [377600/525306]\n",
      "loss: 0.688558  [379200/525306]\n",
      "loss: 1.194803  [380800/525306]\n",
      "loss: 0.929022  [382400/525306]\n",
      "loss: 0.634294  [384000/525306]\n",
      "loss: 0.899300  [385600/525306]\n",
      "loss: 0.803129  [387200/525306]\n",
      "loss: 0.806771  [388800/525306]\n",
      "loss: 1.200649  [390400/525306]\n",
      "loss: 1.042083  [392000/525306]\n",
      "loss: 0.512986  [393600/525306]\n",
      "loss: 0.818772  [395200/525306]\n",
      "loss: 0.624959  [396800/525306]\n",
      "loss: 1.098244  [398400/525306]\n",
      "loss: 0.950576  [400000/525306]\n",
      "loss: 0.858456  [401600/525306]\n",
      "loss: 0.806682  [403200/525306]\n",
      "loss: 1.111277  [404800/525306]\n",
      "loss: 0.844356  [406400/525306]\n",
      "loss: 0.794471  [408000/525306]\n",
      "loss: 0.688518  [409600/525306]\n",
      "loss: 1.214447  [411200/525306]\n",
      "loss: 0.773655  [412800/525306]\n",
      "loss: 0.668068  [414400/525306]\n",
      "loss: 1.455392  [416000/525306]\n",
      "loss: 0.837959  [417600/525306]\n",
      "loss: 1.177278  [419200/525306]\n",
      "loss: 1.307859  [420800/525306]\n",
      "loss: 0.940846  [422400/525306]\n",
      "loss: 0.970264  [424000/525306]\n",
      "loss: 0.667592  [425600/525306]\n",
      "loss: 0.893277  [427200/525306]\n",
      "loss: 0.672215  [428800/525306]\n",
      "loss: 1.172833  [430400/525306]\n",
      "loss: 1.302914  [432000/525306]\n",
      "loss: 0.761720  [433600/525306]\n",
      "loss: 1.566119  [435200/525306]\n",
      "loss: 0.989215  [436800/525306]\n",
      "loss: 0.891275  [438400/525306]\n",
      "loss: 0.542285  [440000/525306]\n",
      "loss: 0.355815  [441600/525306]\n",
      "loss: 0.679932  [443200/525306]\n",
      "loss: 0.714338  [444800/525306]\n",
      "loss: 0.873142  [446400/525306]\n",
      "loss: 1.072310  [448000/525306]\n",
      "loss: 0.708234  [449600/525306]\n",
      "loss: 1.217290  [451200/525306]\n",
      "loss: 0.965379  [452800/525306]\n",
      "loss: 0.732540  [454400/525306]\n",
      "loss: 0.697969  [456000/525306]\n",
      "loss: 1.200590  [457600/525306]\n",
      "loss: 1.122021  [459200/525306]\n",
      "loss: 0.643792  [460800/525306]\n",
      "loss: 1.028280  [462400/525306]\n",
      "loss: 0.986809  [464000/525306]\n",
      "loss: 0.801895  [465600/525306]\n",
      "loss: 0.436392  [467200/525306]\n",
      "loss: 0.852717  [468800/525306]\n",
      "loss: 0.777442  [470400/525306]\n",
      "loss: 0.780275  [472000/525306]\n",
      "loss: 1.093257  [473600/525306]\n",
      "loss: 0.769234  [475200/525306]\n",
      "loss: 1.060486  [476800/525306]\n",
      "loss: 1.082066  [478400/525306]\n",
      "loss: 1.049416  [480000/525306]\n",
      "loss: 0.855471  [481600/525306]\n",
      "loss: 0.704391  [483200/525306]\n",
      "loss: 0.526383  [484800/525306]\n",
      "loss: 0.676279  [486400/525306]\n",
      "loss: 0.609642  [488000/525306]\n",
      "loss: 0.864469  [489600/525306]\n",
      "loss: 0.738059  [491200/525306]\n",
      "loss: 0.857875  [492800/525306]\n",
      "loss: 0.819197  [494400/525306]\n",
      "loss: 0.573382  [496000/525306]\n",
      "loss: 1.136659  [497600/525306]\n",
      "loss: 1.009883  [499200/525306]\n",
      "loss: 1.033284  [500800/525306]\n",
      "loss: 0.863976  [502400/525306]\n",
      "loss: 1.323690  [504000/525306]\n",
      "loss: 0.969488  [505600/525306]\n",
      "loss: 0.948626  [507200/525306]\n",
      "loss: 0.877978  [508800/525306]\n",
      "loss: 0.700080  [510400/525306]\n",
      "loss: 0.857781  [512000/525306]\n",
      "loss: 1.019337  [513600/525306]\n",
      "loss: 0.534307  [515200/525306]\n",
      "loss: 1.023728  [516800/525306]\n",
      "loss: 0.558388  [518400/525306]\n",
      "loss: 0.652655  [520000/525306]\n",
      "loss: 1.079695  [521600/525306]\n",
      "loss: 0.407181  [523200/525306]\n",
      "loss: 0.546486  [524800/525306]\n",
      "Train Accuracy: 65.6501%\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 1.020439, F1-score: 67.66%, Macro_F1-Score:  36.84%  \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.821465  [    0/525306]\n",
      "loss: 1.041731  [ 1600/525306]\n",
      "loss: 0.561603  [ 3200/525306]\n",
      "loss: 0.558829  [ 4800/525306]\n",
      "loss: 0.457278  [ 6400/525306]\n",
      "loss: 0.644607  [ 8000/525306]\n",
      "loss: 1.115663  [ 9600/525306]\n",
      "loss: 0.755074  [11200/525306]\n",
      "loss: 0.865144  [12800/525306]\n",
      "loss: 0.571559  [14400/525306]\n",
      "loss: 0.744296  [16000/525306]\n",
      "loss: 0.803080  [17600/525306]\n",
      "loss: 1.075370  [19200/525306]\n",
      "loss: 0.659257  [20800/525306]\n",
      "loss: 0.834082  [22400/525306]\n",
      "loss: 0.922947  [24000/525306]\n",
      "loss: 1.179530  [25600/525306]\n",
      "loss: 1.241377  [27200/525306]\n",
      "loss: 1.064758  [28800/525306]\n",
      "loss: 0.742236  [30400/525306]\n",
      "loss: 1.050186  [32000/525306]\n",
      "loss: 1.058714  [33600/525306]\n",
      "loss: 0.920738  [35200/525306]\n",
      "loss: 0.700505  [36800/525306]\n",
      "loss: 0.792586  [38400/525306]\n",
      "loss: 0.638985  [40000/525306]\n",
      "loss: 0.704700  [41600/525306]\n",
      "loss: 0.973068  [43200/525306]\n",
      "loss: 0.615826  [44800/525306]\n",
      "loss: 0.859953  [46400/525306]\n",
      "loss: 0.982869  [48000/525306]\n",
      "loss: 0.690636  [49600/525306]\n",
      "loss: 1.039865  [51200/525306]\n",
      "loss: 0.365901  [52800/525306]\n",
      "loss: 0.747997  [54400/525306]\n",
      "loss: 0.653729  [56000/525306]\n",
      "loss: 0.835939  [57600/525306]\n",
      "loss: 0.925928  [59200/525306]\n",
      "loss: 0.857782  [60800/525306]\n",
      "loss: 1.377963  [62400/525306]\n",
      "loss: 0.929251  [64000/525306]\n",
      "loss: 0.952538  [65600/525306]\n",
      "loss: 0.856318  [67200/525306]\n",
      "loss: 0.812574  [68800/525306]\n",
      "loss: 0.894963  [70400/525306]\n",
      "loss: 0.764491  [72000/525306]\n",
      "loss: 0.834827  [73600/525306]\n",
      "loss: 0.908768  [75200/525306]\n",
      "loss: 1.532756  [76800/525306]\n",
      "loss: 1.485642  [78400/525306]\n",
      "loss: 0.698637  [80000/525306]\n",
      "loss: 1.191593  [81600/525306]\n",
      "loss: 0.459755  [83200/525306]\n",
      "loss: 0.854781  [84800/525306]\n",
      "loss: 0.939708  [86400/525306]\n",
      "loss: 1.638262  [88000/525306]\n",
      "loss: 0.642351  [89600/525306]\n",
      "loss: 1.108707  [91200/525306]\n",
      "loss: 1.421522  [92800/525306]\n",
      "loss: 0.850765  [94400/525306]\n",
      "loss: 0.960189  [96000/525306]\n",
      "loss: 0.834531  [97600/525306]\n",
      "loss: 0.578365  [99200/525306]\n",
      "loss: 1.028199  [100800/525306]\n",
      "loss: 1.214484  [102400/525306]\n",
      "loss: 1.029278  [104000/525306]\n",
      "loss: 0.799295  [105600/525306]\n",
      "loss: 0.660963  [107200/525306]\n",
      "loss: 0.676667  [108800/525306]\n",
      "loss: 0.570627  [110400/525306]\n",
      "loss: 1.095063  [112000/525306]\n",
      "loss: 0.585725  [113600/525306]\n",
      "loss: 0.577829  [115200/525306]\n",
      "loss: 1.099012  [116800/525306]\n",
      "loss: 0.872862  [118400/525306]\n",
      "loss: 0.809261  [120000/525306]\n",
      "loss: 1.002782  [121600/525306]\n",
      "loss: 0.655832  [123200/525306]\n",
      "loss: 0.795321  [124800/525306]\n",
      "loss: 0.834351  [126400/525306]\n",
      "loss: 1.019354  [128000/525306]\n",
      "loss: 1.094823  [129600/525306]\n",
      "loss: 0.868800  [131200/525306]\n",
      "loss: 0.738882  [132800/525306]\n",
      "loss: 0.803969  [134400/525306]\n",
      "loss: 1.173917  [136000/525306]\n",
      "loss: 0.601214  [137600/525306]\n",
      "loss: 0.958114  [139200/525306]\n",
      "loss: 0.937218  [140800/525306]\n",
      "loss: 0.819892  [142400/525306]\n",
      "loss: 1.271951  [144000/525306]\n",
      "loss: 0.550325  [145600/525306]\n",
      "loss: 0.541976  [147200/525306]\n",
      "loss: 0.989979  [148800/525306]\n",
      "loss: 0.577411  [150400/525306]\n",
      "loss: 1.150118  [152000/525306]\n",
      "loss: 0.416736  [153600/525306]\n",
      "loss: 0.588131  [155200/525306]\n",
      "loss: 0.856605  [156800/525306]\n",
      "loss: 0.583056  [158400/525306]\n",
      "loss: 1.179420  [160000/525306]\n",
      "loss: 0.433256  [161600/525306]\n",
      "loss: 0.564785  [163200/525306]\n",
      "loss: 0.887080  [164800/525306]\n",
      "loss: 1.164396  [166400/525306]\n",
      "loss: 0.800517  [168000/525306]\n",
      "loss: 1.161220  [169600/525306]\n",
      "loss: 0.756161  [171200/525306]\n",
      "loss: 1.416704  [172800/525306]\n",
      "loss: 1.082007  [174400/525306]\n",
      "loss: 0.983653  [176000/525306]\n",
      "loss: 0.747824  [177600/525306]\n",
      "loss: 0.890080  [179200/525306]\n",
      "loss: 0.963783  [180800/525306]\n",
      "loss: 1.187242  [182400/525306]\n",
      "loss: 1.092759  [184000/525306]\n",
      "loss: 0.634547  [185600/525306]\n",
      "loss: 1.209844  [187200/525306]\n",
      "loss: 0.821568  [188800/525306]\n",
      "loss: 0.625773  [190400/525306]\n",
      "loss: 1.021016  [192000/525306]\n",
      "loss: 0.990564  [193600/525306]\n",
      "loss: 0.447359  [195200/525306]\n",
      "loss: 0.751335  [196800/525306]\n",
      "loss: 1.106593  [198400/525306]\n",
      "loss: 0.936163  [200000/525306]\n",
      "loss: 0.680662  [201600/525306]\n",
      "loss: 0.639904  [203200/525306]\n",
      "loss: 0.810945  [204800/525306]\n",
      "loss: 0.645778  [206400/525306]\n",
      "loss: 0.634406  [208000/525306]\n",
      "loss: 1.305846  [209600/525306]\n",
      "loss: 0.753809  [211200/525306]\n",
      "loss: 1.903930  [212800/525306]\n",
      "loss: 0.917047  [214400/525306]\n",
      "loss: 0.722216  [216000/525306]\n",
      "loss: 0.830980  [217600/525306]\n",
      "loss: 0.929509  [219200/525306]\n",
      "loss: 1.154362  [220800/525306]\n",
      "loss: 1.194865  [222400/525306]\n",
      "loss: 1.013329  [224000/525306]\n",
      "loss: 0.713689  [225600/525306]\n",
      "loss: 1.293440  [227200/525306]\n",
      "loss: 0.782574  [228800/525306]\n",
      "loss: 0.834152  [230400/525306]\n",
      "loss: 0.586424  [232000/525306]\n",
      "loss: 0.895006  [233600/525306]\n",
      "loss: 0.942843  [235200/525306]\n",
      "loss: 0.869929  [236800/525306]\n",
      "loss: 0.808770  [238400/525306]\n",
      "loss: 0.534645  [240000/525306]\n",
      "loss: 0.585664  [241600/525306]\n",
      "loss: 0.922523  [243200/525306]\n",
      "loss: 0.560472  [244800/525306]\n",
      "loss: 0.847160  [246400/525306]\n",
      "loss: 0.728635  [248000/525306]\n",
      "loss: 0.858835  [249600/525306]\n",
      "loss: 0.724606  [251200/525306]\n",
      "loss: 0.845526  [252800/525306]\n",
      "loss: 0.697756  [254400/525306]\n",
      "loss: 1.151405  [256000/525306]\n",
      "loss: 1.045177  [257600/525306]\n",
      "loss: 0.825978  [259200/525306]\n",
      "loss: 0.649705  [260800/525306]\n",
      "loss: 0.655026  [262400/525306]\n",
      "loss: 1.022648  [264000/525306]\n",
      "loss: 0.914256  [265600/525306]\n",
      "loss: 0.857520  [267200/525306]\n",
      "loss: 0.752283  [268800/525306]\n",
      "loss: 1.107639  [270400/525306]\n",
      "loss: 0.654515  [272000/525306]\n",
      "loss: 0.632679  [273600/525306]\n",
      "loss: 0.902312  [275200/525306]\n",
      "loss: 0.849370  [276800/525306]\n",
      "loss: 1.026637  [278400/525306]\n",
      "loss: 0.670668  [280000/525306]\n",
      "loss: 1.735732  [281600/525306]\n",
      "loss: 0.604190  [283200/525306]\n",
      "loss: 1.085221  [284800/525306]\n",
      "loss: 0.884675  [286400/525306]\n",
      "loss: 0.756055  [288000/525306]\n",
      "loss: 0.590021  [289600/525306]\n",
      "loss: 0.709619  [291200/525306]\n",
      "loss: 0.628685  [292800/525306]\n",
      "loss: 0.572370  [294400/525306]\n",
      "loss: 0.589034  [296000/525306]\n",
      "loss: 0.844059  [297600/525306]\n",
      "loss: 0.498685  [299200/525306]\n",
      "loss: 1.347476  [300800/525306]\n",
      "loss: 0.891740  [302400/525306]\n",
      "loss: 0.988633  [304000/525306]\n",
      "loss: 0.721486  [305600/525306]\n",
      "loss: 1.086376  [307200/525306]\n",
      "loss: 0.999650  [308800/525306]\n",
      "loss: 0.302981  [310400/525306]\n",
      "loss: 0.781758  [312000/525306]\n",
      "loss: 0.732174  [313600/525306]\n",
      "loss: 0.618993  [315200/525306]\n",
      "loss: 0.904922  [316800/525306]\n",
      "loss: 1.077971  [318400/525306]\n",
      "loss: 1.144220  [320000/525306]\n",
      "loss: 0.706626  [321600/525306]\n",
      "loss: 0.587156  [323200/525306]\n",
      "loss: 0.992180  [324800/525306]\n",
      "loss: 0.779268  [326400/525306]\n",
      "loss: 0.409868  [328000/525306]\n",
      "loss: 1.136513  [329600/525306]\n",
      "loss: 0.776766  [331200/525306]\n",
      "loss: 1.099422  [332800/525306]\n",
      "loss: 0.807072  [334400/525306]\n",
      "loss: 1.070535  [336000/525306]\n",
      "loss: 0.630853  [337600/525306]\n",
      "loss: 0.813686  [339200/525306]\n",
      "loss: 0.503232  [340800/525306]\n",
      "loss: 1.467090  [342400/525306]\n",
      "loss: 1.161990  [344000/525306]\n",
      "loss: 1.023967  [345600/525306]\n",
      "loss: 1.023984  [347200/525306]\n",
      "loss: 1.370433  [348800/525306]\n",
      "loss: 1.123911  [350400/525306]\n",
      "loss: 1.164253  [352000/525306]\n",
      "loss: 1.021253  [353600/525306]\n",
      "loss: 1.096622  [355200/525306]\n",
      "loss: 1.074701  [356800/525306]\n",
      "loss: 0.479271  [358400/525306]\n",
      "loss: 0.693082  [360000/525306]\n",
      "loss: 0.683779  [361600/525306]\n",
      "loss: 0.542570  [363200/525306]\n",
      "loss: 0.556762  [364800/525306]\n",
      "loss: 1.131351  [366400/525306]\n",
      "loss: 0.654430  [368000/525306]\n",
      "loss: 0.763123  [369600/525306]\n",
      "loss: 0.737285  [371200/525306]\n",
      "loss: 0.999617  [372800/525306]\n",
      "loss: 1.128979  [374400/525306]\n",
      "loss: 1.139902  [376000/525306]\n",
      "loss: 0.974485  [377600/525306]\n",
      "loss: 0.616232  [379200/525306]\n",
      "loss: 0.923643  [380800/525306]\n",
      "loss: 1.047204  [382400/525306]\n",
      "loss: 1.016175  [384000/525306]\n",
      "loss: 0.926279  [385600/525306]\n",
      "loss: 0.743142  [387200/525306]\n",
      "loss: 0.716355  [388800/525306]\n",
      "loss: 1.228544  [390400/525306]\n",
      "loss: 0.722178  [392000/525306]\n",
      "loss: 1.147789  [393600/525306]\n",
      "loss: 0.834123  [395200/525306]\n",
      "loss: 0.971627  [396800/525306]\n",
      "loss: 0.376310  [398400/525306]\n",
      "loss: 0.977927  [400000/525306]\n",
      "loss: 0.931287  [401600/525306]\n",
      "loss: 0.542240  [403200/525306]\n",
      "loss: 0.721007  [404800/525306]\n",
      "loss: 0.508985  [406400/525306]\n",
      "loss: 0.751986  [408000/525306]\n",
      "loss: 0.929222  [409600/525306]\n",
      "loss: 0.877422  [411200/525306]\n",
      "loss: 0.873159  [412800/525306]\n",
      "loss: 0.822283  [414400/525306]\n",
      "loss: 0.862612  [416000/525306]\n",
      "loss: 0.743872  [417600/525306]\n",
      "loss: 0.659986  [419200/525306]\n",
      "loss: 0.951630  [420800/525306]\n",
      "loss: 0.896169  [422400/525306]\n",
      "loss: 0.766105  [424000/525306]\n",
      "loss: 0.819822  [425600/525306]\n",
      "loss: 0.720294  [427200/525306]\n",
      "loss: 0.719374  [428800/525306]\n",
      "loss: 0.818443  [430400/525306]\n",
      "loss: 0.364359  [432000/525306]\n",
      "loss: 0.964710  [433600/525306]\n",
      "loss: 0.719586  [435200/525306]\n",
      "loss: 0.903214  [436800/525306]\n",
      "loss: 0.849366  [438400/525306]\n",
      "loss: 0.634903  [440000/525306]\n",
      "loss: 1.214256  [441600/525306]\n",
      "loss: 0.618299  [443200/525306]\n",
      "loss: 0.604872  [444800/525306]\n",
      "loss: 1.713300  [446400/525306]\n",
      "loss: 0.911323  [448000/525306]\n",
      "loss: 1.333976  [449600/525306]\n",
      "loss: 0.469171  [451200/525306]\n",
      "loss: 0.657692  [452800/525306]\n",
      "loss: 0.798152  [454400/525306]\n",
      "loss: 0.899921  [456000/525306]\n",
      "loss: 0.743171  [457600/525306]\n",
      "loss: 1.127766  [459200/525306]\n",
      "loss: 0.649132  [460800/525306]\n",
      "loss: 0.532055  [462400/525306]\n",
      "loss: 0.689627  [464000/525306]\n",
      "loss: 0.789743  [465600/525306]\n",
      "loss: 0.719236  [467200/525306]\n",
      "loss: 0.887074  [468800/525306]\n",
      "loss: 0.861995  [470400/525306]\n",
      "loss: 0.943249  [472000/525306]\n",
      "loss: 1.061476  [473600/525306]\n",
      "loss: 1.113151  [475200/525306]\n",
      "loss: 1.264045  [476800/525306]\n",
      "loss: 1.128729  [478400/525306]\n",
      "loss: 0.738112  [480000/525306]\n",
      "loss: 0.680406  [481600/525306]\n",
      "loss: 0.653685  [483200/525306]\n",
      "loss: 0.445360  [484800/525306]\n",
      "loss: 1.201431  [486400/525306]\n",
      "loss: 0.946751  [488000/525306]\n",
      "loss: 0.713874  [489600/525306]\n",
      "loss: 0.557588  [491200/525306]\n",
      "loss: 0.680566  [492800/525306]\n",
      "loss: 0.905311  [494400/525306]\n",
      "loss: 0.604580  [496000/525306]\n",
      "loss: 1.009552  [497600/525306]\n",
      "loss: 0.694891  [499200/525306]\n",
      "loss: 0.632311  [500800/525306]\n",
      "loss: 0.690658  [502400/525306]\n",
      "loss: 0.734373  [504000/525306]\n",
      "loss: 1.150777  [505600/525306]\n",
      "loss: 0.984945  [507200/525306]\n",
      "loss: 0.696076  [508800/525306]\n",
      "loss: 1.209870  [510400/525306]\n",
      "loss: 1.024672  [512000/525306]\n",
      "loss: 0.641430  [513600/525306]\n",
      "loss: 0.885661  [515200/525306]\n",
      "loss: 0.907502  [516800/525306]\n",
      "loss: 1.155403  [518400/525306]\n",
      "loss: 1.180241  [520000/525306]\n",
      "loss: 0.821610  [521600/525306]\n",
      "loss: 1.202484  [523200/525306]\n",
      "loss: 0.839443  [524800/525306]\n",
      "Train Accuracy: 66.7082%\n",
      "Test Error: \n",
      " Accuracy: 61.6%, Avg loss: 1.014970, F1-score: 67.93%, Macro_F1-Score:  37.35%  \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.794818  [    0/525306]\n",
      "loss: 0.600501  [ 1600/525306]\n",
      "loss: 0.920943  [ 3200/525306]\n",
      "loss: 0.998145  [ 4800/525306]\n",
      "loss: 0.880700  [ 6400/525306]\n",
      "loss: 0.851560  [ 8000/525306]\n",
      "loss: 0.916098  [ 9600/525306]\n",
      "loss: 1.241583  [11200/525306]\n",
      "loss: 0.996859  [12800/525306]\n",
      "loss: 0.951671  [14400/525306]\n",
      "loss: 1.255091  [16000/525306]\n",
      "loss: 0.800272  [17600/525306]\n",
      "loss: 1.120645  [19200/525306]\n",
      "loss: 0.689167  [20800/525306]\n",
      "loss: 1.375887  [22400/525306]\n",
      "loss: 0.655406  [24000/525306]\n",
      "loss: 1.255967  [25600/525306]\n",
      "loss: 1.116886  [27200/525306]\n",
      "loss: 0.788533  [28800/525306]\n",
      "loss: 0.543407  [30400/525306]\n",
      "loss: 1.291870  [32000/525306]\n",
      "loss: 0.837843  [33600/525306]\n",
      "loss: 0.789482  [35200/525306]\n",
      "loss: 1.254704  [36800/525306]\n",
      "loss: 0.870331  [38400/525306]\n",
      "loss: 1.138911  [40000/525306]\n",
      "loss: 1.111002  [41600/525306]\n",
      "loss: 1.092618  [43200/525306]\n",
      "loss: 0.929947  [44800/525306]\n",
      "loss: 0.794510  [46400/525306]\n",
      "loss: 0.623009  [48000/525306]\n",
      "loss: 0.930188  [49600/525306]\n",
      "loss: 0.897581  [51200/525306]\n",
      "loss: 0.800769  [52800/525306]\n",
      "loss: 1.265198  [54400/525306]\n",
      "loss: 0.926523  [56000/525306]\n",
      "loss: 1.062411  [57600/525306]\n",
      "loss: 0.548230  [59200/525306]\n",
      "loss: 0.862997  [60800/525306]\n",
      "loss: 1.107335  [62400/525306]\n",
      "loss: 0.850864  [64000/525306]\n",
      "loss: 0.540142  [65600/525306]\n",
      "loss: 1.302702  [67200/525306]\n",
      "loss: 0.901980  [68800/525306]\n",
      "loss: 0.865049  [70400/525306]\n",
      "loss: 0.655116  [72000/525306]\n",
      "loss: 0.725303  [73600/525306]\n",
      "loss: 0.836756  [75200/525306]\n",
      "loss: 1.067345  [76800/525306]\n",
      "loss: 1.083570  [78400/525306]\n",
      "loss: 0.629296  [80000/525306]\n",
      "loss: 0.784619  [81600/525306]\n",
      "loss: 0.759418  [83200/525306]\n",
      "loss: 0.665960  [84800/525306]\n",
      "loss: 0.484727  [86400/525306]\n",
      "loss: 1.019421  [88000/525306]\n",
      "loss: 1.119012  [89600/525306]\n",
      "loss: 0.961151  [91200/525306]\n",
      "loss: 0.928999  [92800/525306]\n",
      "loss: 1.586216  [94400/525306]\n",
      "loss: 1.058088  [96000/525306]\n",
      "loss: 0.944054  [97600/525306]\n",
      "loss: 0.759766  [99200/525306]\n",
      "loss: 1.021633  [100800/525306]\n",
      "loss: 1.154527  [102400/525306]\n",
      "loss: 0.964197  [104000/525306]\n",
      "loss: 0.658551  [105600/525306]\n",
      "loss: 0.745168  [107200/525306]\n",
      "loss: 0.836100  [108800/525306]\n",
      "loss: 1.235960  [110400/525306]\n",
      "loss: 1.508541  [112000/525306]\n",
      "loss: 0.759507  [113600/525306]\n",
      "loss: 0.839160  [115200/525306]\n",
      "loss: 0.845626  [116800/525306]\n",
      "loss: 0.813366  [118400/525306]\n",
      "loss: 0.577053  [120000/525306]\n",
      "loss: 1.301946  [121600/525306]\n",
      "loss: 1.239991  [123200/525306]\n",
      "loss: 0.642274  [124800/525306]\n",
      "loss: 0.835116  [126400/525306]\n",
      "loss: 1.068228  [128000/525306]\n",
      "loss: 0.577006  [129600/525306]\n",
      "loss: 1.010661  [131200/525306]\n",
      "loss: 1.338467  [132800/525306]\n",
      "loss: 0.798216  [134400/525306]\n",
      "loss: 1.283783  [136000/525306]\n",
      "loss: 1.166708  [137600/525306]\n",
      "loss: 0.539726  [139200/525306]\n",
      "loss: 1.077578  [140800/525306]\n",
      "loss: 1.074978  [142400/525306]\n",
      "loss: 0.911573  [144000/525306]\n",
      "loss: 0.821140  [145600/525306]\n",
      "loss: 0.977040  [147200/525306]\n",
      "loss: 0.869129  [148800/525306]\n",
      "loss: 1.055264  [150400/525306]\n",
      "loss: 1.014841  [152000/525306]\n",
      "loss: 0.792782  [153600/525306]\n",
      "loss: 0.613955  [155200/525306]\n",
      "loss: 1.098566  [156800/525306]\n",
      "loss: 0.745649  [158400/525306]\n",
      "loss: 0.753983  [160000/525306]\n",
      "loss: 0.594122  [161600/525306]\n",
      "loss: 0.467184  [163200/525306]\n",
      "loss: 0.623535  [164800/525306]\n",
      "loss: 0.797832  [166400/525306]\n",
      "loss: 0.404108  [168000/525306]\n",
      "loss: 1.112333  [169600/525306]\n",
      "loss: 0.709297  [171200/525306]\n",
      "loss: 0.587022  [172800/525306]\n",
      "loss: 0.357358  [174400/525306]\n",
      "loss: 0.758453  [176000/525306]\n",
      "loss: 0.762460  [177600/525306]\n",
      "loss: 0.810783  [179200/525306]\n",
      "loss: 0.629587  [180800/525306]\n",
      "loss: 1.042925  [182400/525306]\n",
      "loss: 0.399449  [184000/525306]\n",
      "loss: 1.314940  [185600/525306]\n",
      "loss: 0.570846  [187200/525306]\n",
      "loss: 1.215456  [188800/525306]\n",
      "loss: 0.772562  [190400/525306]\n",
      "loss: 0.688148  [192000/525306]\n",
      "loss: 0.842658  [193600/525306]\n",
      "loss: 0.691675  [195200/525306]\n",
      "loss: 1.625567  [196800/525306]\n",
      "loss: 0.954136  [198400/525306]\n",
      "loss: 0.854488  [200000/525306]\n",
      "loss: 0.734673  [201600/525306]\n",
      "loss: 0.947200  [203200/525306]\n",
      "loss: 0.960170  [204800/525306]\n",
      "loss: 0.699390  [206400/525306]\n",
      "loss: 0.459997  [208000/525306]\n",
      "loss: 1.105315  [209600/525306]\n",
      "loss: 0.986363  [211200/525306]\n",
      "loss: 0.888488  [212800/525306]\n",
      "loss: 0.852057  [214400/525306]\n",
      "loss: 0.741507  [216000/525306]\n",
      "loss: 0.923197  [217600/525306]\n",
      "loss: 0.699601  [219200/525306]\n",
      "loss: 0.805115  [220800/525306]\n",
      "loss: 0.536340  [222400/525306]\n",
      "loss: 1.081095  [224000/525306]\n",
      "loss: 0.723051  [225600/525306]\n",
      "loss: 1.104884  [227200/525306]\n",
      "loss: 1.241244  [228800/525306]\n",
      "loss: 0.661823  [230400/525306]\n",
      "loss: 0.699527  [232000/525306]\n",
      "loss: 0.459862  [233600/525306]\n",
      "loss: 0.477453  [235200/525306]\n",
      "loss: 1.264719  [236800/525306]\n",
      "loss: 0.624585  [238400/525306]\n",
      "loss: 0.763347  [240000/525306]\n",
      "loss: 0.898211  [241600/525306]\n",
      "loss: 1.365745  [243200/525306]\n",
      "loss: 0.711629  [244800/525306]\n",
      "loss: 1.212651  [246400/525306]\n",
      "loss: 1.183646  [248000/525306]\n",
      "loss: 0.778874  [249600/525306]\n",
      "loss: 1.089885  [251200/525306]\n",
      "loss: 0.883723  [252800/525306]\n",
      "loss: 0.816054  [254400/525306]\n",
      "loss: 0.731020  [256000/525306]\n",
      "loss: 1.180410  [257600/525306]\n",
      "loss: 0.782129  [259200/525306]\n",
      "loss: 0.852462  [260800/525306]\n",
      "loss: 0.960058  [262400/525306]\n",
      "loss: 0.790395  [264000/525306]\n",
      "loss: 0.844382  [265600/525306]\n",
      "loss: 0.685378  [267200/525306]\n",
      "loss: 0.901534  [268800/525306]\n",
      "loss: 0.468081  [270400/525306]\n",
      "loss: 0.958582  [272000/525306]\n",
      "loss: 0.978345  [273600/525306]\n",
      "loss: 0.796611  [275200/525306]\n",
      "loss: 0.595857  [276800/525306]\n",
      "loss: 0.879579  [278400/525306]\n",
      "loss: 0.909827  [280000/525306]\n",
      "loss: 0.820015  [281600/525306]\n",
      "loss: 1.047701  [283200/525306]\n",
      "loss: 0.847217  [284800/525306]\n",
      "loss: 1.464276  [286400/525306]\n",
      "loss: 0.866217  [288000/525306]\n",
      "loss: 0.865594  [289600/525306]\n",
      "loss: 1.554911  [291200/525306]\n",
      "loss: 0.540774  [292800/525306]\n",
      "loss: 0.984290  [294400/525306]\n",
      "loss: 1.406598  [296000/525306]\n",
      "loss: 0.723363  [297600/525306]\n",
      "loss: 0.612626  [299200/525306]\n",
      "loss: 0.772868  [300800/525306]\n",
      "loss: 0.734053  [302400/525306]\n",
      "loss: 0.750603  [304000/525306]\n",
      "loss: 0.836058  [305600/525306]\n",
      "loss: 0.730842  [307200/525306]\n",
      "loss: 0.915411  [308800/525306]\n",
      "loss: 0.593052  [310400/525306]\n",
      "loss: 0.651174  [312000/525306]\n",
      "loss: 0.780185  [313600/525306]\n",
      "loss: 0.462989  [315200/525306]\n",
      "loss: 0.945980  [316800/525306]\n",
      "loss: 0.540830  [318400/525306]\n",
      "loss: 0.761494  [320000/525306]\n",
      "loss: 1.035078  [321600/525306]\n",
      "loss: 0.975304  [323200/525306]\n",
      "loss: 0.781409  [324800/525306]\n",
      "loss: 1.010331  [326400/525306]\n",
      "loss: 0.697126  [328000/525306]\n",
      "loss: 0.951174  [329600/525306]\n",
      "loss: 0.600090  [331200/525306]\n",
      "loss: 0.772343  [332800/525306]\n",
      "loss: 1.131232  [334400/525306]\n",
      "loss: 0.799911  [336000/525306]\n",
      "loss: 0.846947  [337600/525306]\n",
      "loss: 0.724485  [339200/525306]\n",
      "loss: 1.180232  [340800/525306]\n",
      "loss: 1.122006  [342400/525306]\n",
      "loss: 1.143726  [344000/525306]\n",
      "loss: 0.810646  [345600/525306]\n",
      "loss: 1.140358  [347200/525306]\n",
      "loss: 0.786631  [348800/525306]\n",
      "loss: 0.882808  [350400/525306]\n",
      "loss: 0.977056  [352000/525306]\n",
      "loss: 0.696850  [353600/525306]\n",
      "loss: 0.811135  [355200/525306]\n",
      "loss: 1.092738  [356800/525306]\n",
      "loss: 1.110813  [358400/525306]\n",
      "loss: 0.704382  [360000/525306]\n",
      "loss: 0.878159  [361600/525306]\n",
      "loss: 0.795734  [363200/525306]\n",
      "loss: 0.900128  [364800/525306]\n",
      "loss: 1.431287  [366400/525306]\n",
      "loss: 0.675338  [368000/525306]\n",
      "loss: 0.591298  [369600/525306]\n",
      "loss: 1.022318  [371200/525306]\n",
      "loss: 0.952588  [372800/525306]\n",
      "loss: 0.670497  [374400/525306]\n",
      "loss: 0.477776  [376000/525306]\n",
      "loss: 1.016861  [377600/525306]\n",
      "loss: 0.614618  [379200/525306]\n",
      "loss: 0.700449  [380800/525306]\n",
      "loss: 1.074178  [382400/525306]\n",
      "loss: 1.054025  [384000/525306]\n",
      "loss: 1.074048  [385600/525306]\n",
      "loss: 1.102912  [387200/525306]\n",
      "loss: 0.600234  [388800/525306]\n",
      "loss: 0.669051  [390400/525306]\n",
      "loss: 0.598510  [392000/525306]\n",
      "loss: 1.161900  [393600/525306]\n",
      "loss: 1.125606  [395200/525306]\n",
      "loss: 0.794759  [396800/525306]\n",
      "loss: 0.640918  [398400/525306]\n",
      "loss: 1.177254  [400000/525306]\n",
      "loss: 0.731229  [401600/525306]\n",
      "loss: 0.908136  [403200/525306]\n",
      "loss: 0.683471  [404800/525306]\n",
      "loss: 0.753787  [406400/525306]\n",
      "loss: 0.881370  [408000/525306]\n",
      "loss: 0.525006  [409600/525306]\n",
      "loss: 1.319463  [411200/525306]\n",
      "loss: 1.447222  [412800/525306]\n",
      "loss: 0.805239  [414400/525306]\n",
      "loss: 0.728519  [416000/525306]\n",
      "loss: 0.756853  [417600/525306]\n",
      "loss: 0.597381  [419200/525306]\n",
      "loss: 0.819566  [420800/525306]\n",
      "loss: 0.813387  [422400/525306]\n",
      "loss: 1.203790  [424000/525306]\n",
      "loss: 0.778025  [425600/525306]\n",
      "loss: 0.740232  [427200/525306]\n",
      "loss: 0.887335  [428800/525306]\n",
      "loss: 0.919947  [430400/525306]\n",
      "loss: 1.238803  [432000/525306]\n",
      "loss: 0.445554  [433600/525306]\n",
      "loss: 0.690440  [435200/525306]\n",
      "loss: 0.738757  [436800/525306]\n",
      "loss: 1.058136  [438400/525306]\n",
      "loss: 0.975882  [440000/525306]\n",
      "loss: 1.145996  [441600/525306]\n",
      "loss: 1.004602  [443200/525306]\n",
      "loss: 0.987724  [444800/525306]\n",
      "loss: 0.796724  [446400/525306]\n",
      "loss: 0.781264  [448000/525306]\n",
      "loss: 0.498778  [449600/525306]\n",
      "loss: 0.923411  [451200/525306]\n",
      "loss: 0.402886  [452800/525306]\n",
      "loss: 0.876150  [454400/525306]\n",
      "loss: 0.629755  [456000/525306]\n",
      "loss: 1.010540  [457600/525306]\n",
      "loss: 0.685459  [459200/525306]\n",
      "loss: 1.184731  [460800/525306]\n",
      "loss: 0.840849  [462400/525306]\n",
      "loss: 1.483225  [464000/525306]\n",
      "loss: 1.061592  [465600/525306]\n",
      "loss: 0.528863  [467200/525306]\n",
      "loss: 1.136685  [468800/525306]\n",
      "loss: 0.807204  [470400/525306]\n",
      "loss: 1.199597  [472000/525306]\n",
      "loss: 1.368171  [473600/525306]\n",
      "loss: 0.960886  [475200/525306]\n",
      "loss: 0.859699  [476800/525306]\n",
      "loss: 0.809410  [478400/525306]\n",
      "loss: 0.812989  [480000/525306]\n",
      "loss: 0.810433  [481600/525306]\n",
      "loss: 1.031745  [483200/525306]\n",
      "loss: 0.500550  [484800/525306]\n",
      "loss: 1.048218  [486400/525306]\n",
      "loss: 1.019439  [488000/525306]\n",
      "loss: 1.058744  [489600/525306]\n",
      "loss: 0.467785  [491200/525306]\n",
      "loss: 0.757061  [492800/525306]\n",
      "loss: 0.954603  [494400/525306]\n",
      "loss: 0.958443  [496000/525306]\n",
      "loss: 0.767353  [497600/525306]\n",
      "loss: 1.182659  [499200/525306]\n",
      "loss: 0.938580  [500800/525306]\n",
      "loss: 0.981428  [502400/525306]\n",
      "loss: 1.477500  [504000/525306]\n",
      "loss: 0.968491  [505600/525306]\n",
      "loss: 1.273786  [507200/525306]\n",
      "loss: 0.881767  [508800/525306]\n",
      "loss: 0.747773  [510400/525306]\n",
      "loss: 0.711006  [512000/525306]\n",
      "loss: 0.978190  [513600/525306]\n",
      "loss: 0.822685  [515200/525306]\n",
      "loss: 0.497745  [516800/525306]\n",
      "loss: 1.004499  [518400/525306]\n",
      "loss: 0.610933  [520000/525306]\n",
      "loss: 0.813880  [521600/525306]\n",
      "loss: 1.095061  [523200/525306]\n",
      "loss: 0.775783  [524800/525306]\n",
      "Train Accuracy: 67.2286%\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 0.973473, F1-score: 68.40%, Macro_F1-Score:  38.37%  \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.822974  [    0/525306]\n",
      "loss: 0.637862  [ 1600/525306]\n",
      "loss: 0.797460  [ 3200/525306]\n",
      "loss: 1.090729  [ 4800/525306]\n",
      "loss: 0.341657  [ 6400/525306]\n",
      "loss: 0.812304  [ 8000/525306]\n",
      "loss: 1.198785  [ 9600/525306]\n",
      "loss: 0.830972  [11200/525306]\n",
      "loss: 0.556826  [12800/525306]\n",
      "loss: 1.431697  [14400/525306]\n",
      "loss: 0.431086  [16000/525306]\n",
      "loss: 0.745953  [17600/525306]\n",
      "loss: 0.505329  [19200/525306]\n",
      "loss: 0.599029  [20800/525306]\n",
      "loss: 0.728218  [22400/525306]\n",
      "loss: 0.560264  [24000/525306]\n",
      "loss: 1.036693  [25600/525306]\n",
      "loss: 0.963406  [27200/525306]\n",
      "loss: 0.539745  [28800/525306]\n",
      "loss: 0.888187  [30400/525306]\n",
      "loss: 0.998824  [32000/525306]\n",
      "loss: 0.729705  [33600/525306]\n",
      "loss: 0.866869  [35200/525306]\n",
      "loss: 0.680325  [36800/525306]\n",
      "loss: 0.820887  [38400/525306]\n",
      "loss: 1.093414  [40000/525306]\n",
      "loss: 0.764925  [41600/525306]\n",
      "loss: 0.711006  [43200/525306]\n",
      "loss: 0.934823  [44800/525306]\n",
      "loss: 0.671474  [46400/525306]\n",
      "loss: 0.820888  [48000/525306]\n",
      "loss: 1.071640  [49600/525306]\n",
      "loss: 0.927972  [51200/525306]\n",
      "loss: 0.978644  [52800/525306]\n",
      "loss: 0.811593  [54400/525306]\n",
      "loss: 0.845300  [56000/525306]\n",
      "loss: 0.987341  [57600/525306]\n",
      "loss: 0.780407  [59200/525306]\n",
      "loss: 1.219749  [60800/525306]\n",
      "loss: 0.597586  [62400/525306]\n",
      "loss: 1.114780  [64000/525306]\n",
      "loss: 0.631640  [65600/525306]\n",
      "loss: 0.425371  [67200/525306]\n",
      "loss: 0.904215  [68800/525306]\n",
      "loss: 1.311211  [70400/525306]\n",
      "loss: 0.882448  [72000/525306]\n",
      "loss: 0.468171  [73600/525306]\n",
      "loss: 0.833807  [75200/525306]\n",
      "loss: 0.739049  [76800/525306]\n",
      "loss: 0.713162  [78400/525306]\n",
      "loss: 1.012987  [80000/525306]\n",
      "loss: 0.736755  [81600/525306]\n",
      "loss: 0.829737  [83200/525306]\n",
      "loss: 0.900774  [84800/525306]\n",
      "loss: 0.803251  [86400/525306]\n",
      "loss: 0.851853  [88000/525306]\n",
      "loss: 0.915224  [89600/525306]\n",
      "loss: 0.776592  [91200/525306]\n",
      "loss: 1.000485  [92800/525306]\n",
      "loss: 0.548170  [94400/525306]\n",
      "loss: 0.725526  [96000/525306]\n",
      "loss: 0.728939  [97600/525306]\n",
      "loss: 1.147737  [99200/525306]\n",
      "loss: 0.492345  [100800/525306]\n",
      "loss: 0.857221  [102400/525306]\n",
      "loss: 0.665287  [104000/525306]\n",
      "loss: 0.789444  [105600/525306]\n",
      "loss: 0.850423  [107200/525306]\n",
      "loss: 0.694122  [108800/525306]\n",
      "loss: 0.594889  [110400/525306]\n",
      "loss: 0.854516  [112000/525306]\n",
      "loss: 0.980956  [113600/525306]\n",
      "loss: 0.770489  [115200/525306]\n",
      "loss: 0.620463  [116800/525306]\n",
      "loss: 1.043152  [118400/525306]\n",
      "loss: 1.033372  [120000/525306]\n",
      "loss: 0.872588  [121600/525306]\n",
      "loss: 0.854430  [123200/525306]\n",
      "loss: 0.818555  [124800/525306]\n",
      "loss: 0.748516  [126400/525306]\n",
      "loss: 0.665752  [128000/525306]\n",
      "loss: 1.521490  [129600/525306]\n",
      "loss: 0.960867  [131200/525306]\n",
      "loss: 1.113831  [132800/525306]\n",
      "loss: 0.749596  [134400/525306]\n",
      "loss: 0.879574  [136000/525306]\n",
      "loss: 1.038484  [137600/525306]\n",
      "loss: 0.889488  [139200/525306]\n",
      "loss: 1.330698  [140800/525306]\n",
      "loss: 1.032852  [142400/525306]\n",
      "loss: 0.930695  [144000/525306]\n",
      "loss: 0.617288  [145600/525306]\n",
      "loss: 0.883328  [147200/525306]\n",
      "loss: 0.692844  [148800/525306]\n",
      "loss: 1.264085  [150400/525306]\n",
      "loss: 0.938916  [152000/525306]\n",
      "loss: 1.023741  [153600/525306]\n",
      "loss: 0.594966  [155200/525306]\n",
      "loss: 1.210108  [156800/525306]\n",
      "loss: 1.200191  [158400/525306]\n",
      "loss: 0.618093  [160000/525306]\n",
      "loss: 0.431697  [161600/525306]\n",
      "loss: 0.729427  [163200/525306]\n",
      "loss: 1.258777  [164800/525306]\n",
      "loss: 1.240721  [166400/525306]\n",
      "loss: 0.806617  [168000/525306]\n",
      "loss: 0.686972  [169600/525306]\n",
      "loss: 0.694219  [171200/525306]\n",
      "loss: 1.000312  [172800/525306]\n",
      "loss: 0.584601  [174400/525306]\n",
      "loss: 0.694179  [176000/525306]\n",
      "loss: 1.553300  [177600/525306]\n",
      "loss: 0.776020  [179200/525306]\n",
      "loss: 1.090862  [180800/525306]\n",
      "loss: 0.865539  [182400/525306]\n",
      "loss: 0.971611  [184000/525306]\n",
      "loss: 1.014553  [185600/525306]\n",
      "loss: 0.784156  [187200/525306]\n",
      "loss: 0.734218  [188800/525306]\n",
      "loss: 0.576349  [190400/525306]\n",
      "loss: 0.963273  [192000/525306]\n",
      "loss: 0.627859  [193600/525306]\n",
      "loss: 1.013832  [195200/525306]\n",
      "loss: 1.032112  [196800/525306]\n",
      "loss: 1.417586  [198400/525306]\n",
      "loss: 1.040730  [200000/525306]\n",
      "loss: 0.549512  [201600/525306]\n",
      "loss: 0.663136  [203200/525306]\n",
      "loss: 0.431000  [204800/525306]\n",
      "loss: 0.801791  [206400/525306]\n",
      "loss: 0.957616  [208000/525306]\n",
      "loss: 0.756022  [209600/525306]\n",
      "loss: 1.073055  [211200/525306]\n",
      "loss: 1.490441  [212800/525306]\n",
      "loss: 0.749420  [214400/525306]\n",
      "loss: 0.817398  [216000/525306]\n",
      "loss: 1.070516  [217600/525306]\n",
      "loss: 0.872840  [219200/525306]\n",
      "loss: 1.514529  [220800/525306]\n",
      "loss: 0.780369  [222400/525306]\n",
      "loss: 0.913875  [224000/525306]\n",
      "loss: 0.816191  [225600/525306]\n",
      "loss: 0.870204  [227200/525306]\n",
      "loss: 0.590607  [228800/525306]\n",
      "loss: 0.793734  [230400/525306]\n",
      "loss: 0.501793  [232000/525306]\n",
      "loss: 0.792645  [233600/525306]\n",
      "loss: 1.103913  [235200/525306]\n",
      "loss: 0.567028  [236800/525306]\n",
      "loss: 0.681113  [238400/525306]\n",
      "loss: 1.013651  [240000/525306]\n",
      "loss: 0.768454  [241600/525306]\n",
      "loss: 0.716807  [243200/525306]\n",
      "loss: 0.489761  [244800/525306]\n",
      "loss: 0.798314  [246400/525306]\n",
      "loss: 1.097785  [248000/525306]\n",
      "loss: 0.858825  [249600/525306]\n",
      "loss: 0.909989  [251200/525306]\n",
      "loss: 0.692595  [252800/525306]\n",
      "loss: 0.937889  [254400/525306]\n",
      "loss: 0.713238  [256000/525306]\n",
      "loss: 1.088229  [257600/525306]\n",
      "loss: 0.665744  [259200/525306]\n",
      "loss: 0.837762  [260800/525306]\n",
      "loss: 0.848242  [262400/525306]\n",
      "loss: 1.107555  [264000/525306]\n",
      "loss: 1.577618  [265600/525306]\n",
      "loss: 0.717314  [267200/525306]\n",
      "loss: 1.059107  [268800/525306]\n",
      "loss: 0.596497  [270400/525306]\n",
      "loss: 1.164569  [272000/525306]\n",
      "loss: 0.955669  [273600/525306]\n",
      "loss: 0.742450  [275200/525306]\n",
      "loss: 0.775477  [276800/525306]\n",
      "loss: 1.487696  [278400/525306]\n",
      "loss: 0.734221  [280000/525306]\n",
      "loss: 0.799833  [281600/525306]\n",
      "loss: 0.722676  [283200/525306]\n",
      "loss: 0.513555  [284800/525306]\n",
      "loss: 0.896103  [286400/525306]\n",
      "loss: 0.694771  [288000/525306]\n",
      "loss: 1.116009  [289600/525306]\n",
      "loss: 0.997395  [291200/525306]\n",
      "loss: 1.008095  [292800/525306]\n",
      "loss: 0.832418  [294400/525306]\n",
      "loss: 0.720296  [296000/525306]\n",
      "loss: 1.471975  [297600/525306]\n",
      "loss: 0.732349  [299200/525306]\n",
      "loss: 0.684696  [300800/525306]\n",
      "loss: 1.073167  [302400/525306]\n",
      "loss: 0.582512  [304000/525306]\n",
      "loss: 0.631409  [305600/525306]\n",
      "loss: 0.613226  [307200/525306]\n",
      "loss: 0.947251  [308800/525306]\n",
      "loss: 0.969597  [310400/525306]\n",
      "loss: 0.985513  [312000/525306]\n",
      "loss: 1.246322  [313600/525306]\n",
      "loss: 0.578167  [315200/525306]\n",
      "loss: 0.864444  [316800/525306]\n",
      "loss: 0.649260  [318400/525306]\n",
      "loss: 0.866910  [320000/525306]\n",
      "loss: 0.898311  [321600/525306]\n",
      "loss: 0.849882  [323200/525306]\n",
      "loss: 0.952766  [324800/525306]\n",
      "loss: 0.976654  [326400/525306]\n",
      "loss: 1.148323  [328000/525306]\n",
      "loss: 0.987357  [329600/525306]\n",
      "loss: 0.501064  [331200/525306]\n",
      "loss: 1.149478  [332800/525306]\n",
      "loss: 1.117236  [334400/525306]\n",
      "loss: 0.926545  [336000/525306]\n",
      "loss: 0.848337  [337600/525306]\n",
      "loss: 1.039397  [339200/525306]\n",
      "loss: 1.022102  [340800/525306]\n",
      "loss: 1.044731  [342400/525306]\n",
      "loss: 0.655934  [344000/525306]\n",
      "loss: 1.097009  [345600/525306]\n",
      "loss: 1.101588  [347200/525306]\n",
      "loss: 1.118241  [348800/525306]\n",
      "loss: 0.866918  [350400/525306]\n",
      "loss: 1.110761  [352000/525306]\n",
      "loss: 0.744695  [353600/525306]\n",
      "loss: 0.909201  [355200/525306]\n",
      "loss: 0.705051  [356800/525306]\n",
      "loss: 0.625767  [358400/525306]\n",
      "loss: 0.934585  [360000/525306]\n",
      "loss: 0.887424  [361600/525306]\n",
      "loss: 1.347335  [363200/525306]\n",
      "loss: 0.687352  [364800/525306]\n",
      "loss: 0.919945  [366400/525306]\n",
      "loss: 0.775341  [368000/525306]\n",
      "loss: 0.648063  [369600/525306]\n",
      "loss: 0.990560  [371200/525306]\n",
      "loss: 0.913475  [372800/525306]\n",
      "loss: 0.845932  [374400/525306]\n",
      "loss: 0.728325  [376000/525306]\n",
      "loss: 0.545974  [377600/525306]\n",
      "loss: 0.551390  [379200/525306]\n",
      "loss: 0.471489  [380800/525306]\n",
      "loss: 0.559456  [382400/525306]\n",
      "loss: 0.568045  [384000/525306]\n",
      "loss: 0.458415  [385600/525306]\n",
      "loss: 0.720414  [387200/525306]\n",
      "loss: 0.662753  [388800/525306]\n",
      "loss: 0.612176  [390400/525306]\n",
      "loss: 1.083325  [392000/525306]\n",
      "loss: 1.007771  [393600/525306]\n",
      "loss: 0.369387  [395200/525306]\n",
      "loss: 0.845556  [396800/525306]\n",
      "loss: 0.689529  [398400/525306]\n",
      "loss: 1.083478  [400000/525306]\n",
      "loss: 0.544234  [401600/525306]\n",
      "loss: 1.109950  [403200/525306]\n",
      "loss: 1.208651  [404800/525306]\n",
      "loss: 0.799947  [406400/525306]\n",
      "loss: 0.844208  [408000/525306]\n",
      "loss: 0.696794  [409600/525306]\n",
      "loss: 1.092133  [411200/525306]\n",
      "loss: 0.877313  [412800/525306]\n",
      "loss: 1.248833  [414400/525306]\n",
      "loss: 0.749375  [416000/525306]\n",
      "loss: 0.600928  [417600/525306]\n",
      "loss: 0.676731  [419200/525306]\n",
      "loss: 1.318780  [420800/525306]\n",
      "loss: 0.811108  [422400/525306]\n",
      "loss: 1.109951  [424000/525306]\n",
      "loss: 0.788631  [425600/525306]\n",
      "loss: 0.772786  [427200/525306]\n",
      "loss: 0.459928  [428800/525306]\n",
      "loss: 1.102184  [430400/525306]\n",
      "loss: 0.394606  [432000/525306]\n",
      "loss: 0.959930  [433600/525306]\n",
      "loss: 0.897344  [435200/525306]\n",
      "loss: 0.676612  [436800/525306]\n",
      "loss: 0.905308  [438400/525306]\n",
      "loss: 0.740579  [440000/525306]\n",
      "loss: 1.024633  [441600/525306]\n",
      "loss: 0.616825  [443200/525306]\n",
      "loss: 0.754252  [444800/525306]\n",
      "loss: 0.896797  [446400/525306]\n",
      "loss: 0.985985  [448000/525306]\n",
      "loss: 0.784020  [449600/525306]\n",
      "loss: 1.285827  [451200/525306]\n",
      "loss: 0.554607  [452800/525306]\n",
      "loss: 0.701472  [454400/525306]\n",
      "loss: 0.589993  [456000/525306]\n",
      "loss: 0.835102  [457600/525306]\n",
      "loss: 0.972106  [459200/525306]\n",
      "loss: 1.004652  [460800/525306]\n",
      "loss: 0.439589  [462400/525306]\n",
      "loss: 0.636878  [464000/525306]\n",
      "loss: 0.601988  [465600/525306]\n",
      "loss: 1.140782  [467200/525306]\n",
      "loss: 2.114282  [468800/525306]\n",
      "loss: 0.688165  [470400/525306]\n",
      "loss: 0.965856  [472000/525306]\n",
      "loss: 0.735735  [473600/525306]\n",
      "loss: 0.307543  [475200/525306]\n",
      "loss: 1.122138  [476800/525306]\n",
      "loss: 1.353345  [478400/525306]\n",
      "loss: 0.412743  [480000/525306]\n",
      "loss: 0.475485  [481600/525306]\n",
      "loss: 1.103667  [483200/525306]\n",
      "loss: 0.518802  [484800/525306]\n",
      "loss: 0.839063  [486400/525306]\n",
      "loss: 1.103879  [488000/525306]\n",
      "loss: 0.590782  [489600/525306]\n",
      "loss: 0.802197  [491200/525306]\n",
      "loss: 0.870629  [492800/525306]\n",
      "loss: 1.059830  [494400/525306]\n",
      "loss: 1.306211  [496000/525306]\n",
      "loss: 0.790883  [497600/525306]\n",
      "loss: 0.737622  [499200/525306]\n",
      "loss: 0.518758  [500800/525306]\n",
      "loss: 0.626413  [502400/525306]\n",
      "loss: 0.898568  [504000/525306]\n",
      "loss: 0.741469  [505600/525306]\n",
      "loss: 1.421115  [507200/525306]\n",
      "loss: 0.569560  [508800/525306]\n",
      "loss: 1.202951  [510400/525306]\n",
      "loss: 0.348085  [512000/525306]\n",
      "loss: 0.916346  [513600/525306]\n",
      "loss: 0.630718  [515200/525306]\n",
      "loss: 0.840624  [516800/525306]\n",
      "loss: 1.079490  [518400/525306]\n",
      "loss: 0.748839  [520000/525306]\n",
      "loss: 0.951421  [521600/525306]\n",
      "loss: 1.186906  [523200/525306]\n",
      "loss: 0.839850  [524800/525306]\n",
      "Train Accuracy: 67.7209%\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.022159, F1-score: 68.41%, Macro_F1-Score:  38.16%  \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.059913  [    0/525306]\n",
      "loss: 0.704770  [ 1600/525306]\n",
      "loss: 0.910723  [ 3200/525306]\n",
      "loss: 0.862413  [ 4800/525306]\n",
      "loss: 1.262504  [ 6400/525306]\n",
      "loss: 0.682064  [ 8000/525306]\n",
      "loss: 0.465260  [ 9600/525306]\n",
      "loss: 0.616723  [11200/525306]\n",
      "loss: 0.812232  [12800/525306]\n",
      "loss: 0.484186  [14400/525306]\n",
      "loss: 1.379447  [16000/525306]\n",
      "loss: 1.269714  [17600/525306]\n",
      "loss: 0.670492  [19200/525306]\n",
      "loss: 0.688594  [20800/525306]\n",
      "loss: 0.790174  [22400/525306]\n",
      "loss: 0.869011  [24000/525306]\n",
      "loss: 0.849809  [25600/525306]\n",
      "loss: 1.523898  [27200/525306]\n",
      "loss: 0.897908  [28800/525306]\n",
      "loss: 0.862309  [30400/525306]\n",
      "loss: 0.701604  [32000/525306]\n",
      "loss: 0.833247  [33600/525306]\n",
      "loss: 0.493530  [35200/525306]\n",
      "loss: 0.661698  [36800/525306]\n",
      "loss: 0.499871  [38400/525306]\n",
      "loss: 0.538115  [40000/525306]\n",
      "loss: 0.770364  [41600/525306]\n",
      "loss: 0.475726  [43200/525306]\n",
      "loss: 1.276498  [44800/525306]\n",
      "loss: 0.500153  [46400/525306]\n",
      "loss: 1.213326  [48000/525306]\n",
      "loss: 0.559739  [49600/525306]\n",
      "loss: 1.127739  [51200/525306]\n",
      "loss: 1.510836  [52800/525306]\n",
      "loss: 1.203085  [54400/525306]\n",
      "loss: 0.488596  [56000/525306]\n",
      "loss: 0.972312  [57600/525306]\n",
      "loss: 0.813572  [59200/525306]\n",
      "loss: 0.946751  [60800/525306]\n",
      "loss: 0.630428  [62400/525306]\n",
      "loss: 1.572181  [64000/525306]\n",
      "loss: 0.469533  [65600/525306]\n",
      "loss: 0.974280  [67200/525306]\n",
      "loss: 1.063965  [68800/525306]\n",
      "loss: 0.794768  [70400/525306]\n",
      "loss: 0.966347  [72000/525306]\n",
      "loss: 0.730144  [73600/525306]\n",
      "loss: 1.150277  [75200/525306]\n",
      "loss: 0.866476  [76800/525306]\n",
      "loss: 0.978006  [78400/525306]\n",
      "loss: 0.910940  [80000/525306]\n",
      "loss: 1.125426  [81600/525306]\n",
      "loss: 0.867594  [83200/525306]\n",
      "loss: 0.913093  [84800/525306]\n",
      "loss: 0.868661  [86400/525306]\n",
      "loss: 0.805006  [88000/525306]\n",
      "loss: 0.478325  [89600/525306]\n",
      "loss: 0.859287  [91200/525306]\n",
      "loss: 0.783770  [92800/525306]\n",
      "loss: 0.338401  [94400/525306]\n",
      "loss: 0.770364  [96000/525306]\n",
      "loss: 0.900394  [97600/525306]\n",
      "loss: 0.828315  [99200/525306]\n",
      "loss: 0.975734  [100800/525306]\n",
      "loss: 0.349664  [102400/525306]\n",
      "loss: 1.223256  [104000/525306]\n",
      "loss: 0.589166  [105600/525306]\n",
      "loss: 0.817674  [107200/525306]\n",
      "loss: 0.974977  [108800/525306]\n",
      "loss: 1.057120  [110400/525306]\n",
      "loss: 0.625648  [112000/525306]\n",
      "loss: 0.781420  [113600/525306]\n",
      "loss: 0.813744  [115200/525306]\n",
      "loss: 0.630013  [116800/525306]\n",
      "loss: 0.995544  [118400/525306]\n",
      "loss: 0.721629  [120000/525306]\n",
      "loss: 0.990714  [121600/525306]\n",
      "loss: 0.990501  [123200/525306]\n",
      "loss: 0.815296  [124800/525306]\n",
      "loss: 0.605476  [126400/525306]\n",
      "loss: 0.895341  [128000/525306]\n",
      "loss: 0.775417  [129600/525306]\n",
      "loss: 0.599404  [131200/525306]\n",
      "loss: 1.032865  [132800/525306]\n",
      "loss: 0.697378  [134400/525306]\n",
      "loss: 0.783159  [136000/525306]\n",
      "loss: 0.901321  [137600/525306]\n",
      "loss: 0.916621  [139200/525306]\n",
      "loss: 0.862643  [140800/525306]\n",
      "loss: 1.051771  [142400/525306]\n",
      "loss: 0.721314  [144000/525306]\n",
      "loss: 0.646679  [145600/525306]\n",
      "loss: 0.611404  [147200/525306]\n",
      "loss: 0.920496  [148800/525306]\n",
      "loss: 0.372963  [150400/525306]\n",
      "loss: 0.738821  [152000/525306]\n",
      "loss: 1.109936  [153600/525306]\n",
      "loss: 0.802391  [155200/525306]\n",
      "loss: 1.199525  [156800/525306]\n",
      "loss: 0.884404  [158400/525306]\n",
      "loss: 0.852002  [160000/525306]\n",
      "loss: 0.839161  [161600/525306]\n",
      "loss: 0.735946  [163200/525306]\n",
      "loss: 1.071973  [164800/525306]\n",
      "loss: 0.783497  [166400/525306]\n",
      "loss: 0.630246  [168000/525306]\n",
      "loss: 0.729421  [169600/525306]\n",
      "loss: 0.985466  [171200/525306]\n",
      "loss: 0.999164  [172800/525306]\n",
      "loss: 1.258664  [174400/525306]\n",
      "loss: 0.807855  [176000/525306]\n",
      "loss: 0.354813  [177600/525306]\n",
      "loss: 0.419917  [179200/525306]\n",
      "loss: 0.888154  [180800/525306]\n",
      "loss: 1.371912  [182400/525306]\n",
      "loss: 1.324293  [184000/525306]\n",
      "loss: 1.085480  [185600/525306]\n",
      "loss: 0.961946  [187200/525306]\n",
      "loss: 1.129570  [188800/525306]\n",
      "loss: 0.804724  [190400/525306]\n",
      "loss: 0.634378  [192000/525306]\n",
      "loss: 1.089960  [193600/525306]\n",
      "loss: 0.868975  [195200/525306]\n",
      "loss: 0.614198  [196800/525306]\n",
      "loss: 0.977085  [198400/525306]\n",
      "loss: 0.697462  [200000/525306]\n",
      "loss: 0.643286  [201600/525306]\n",
      "loss: 0.746471  [203200/525306]\n",
      "loss: 1.192721  [204800/525306]\n",
      "loss: 1.018782  [206400/525306]\n",
      "loss: 0.603517  [208000/525306]\n",
      "loss: 0.730747  [209600/525306]\n",
      "loss: 0.899952  [211200/525306]\n",
      "loss: 0.638567  [212800/525306]\n",
      "loss: 0.910913  [214400/525306]\n",
      "loss: 0.517504  [216000/525306]\n",
      "loss: 1.126257  [217600/525306]\n",
      "loss: 0.921607  [219200/525306]\n",
      "loss: 0.915478  [220800/525306]\n",
      "loss: 0.604272  [222400/525306]\n",
      "loss: 1.116373  [224000/525306]\n",
      "loss: 0.671253  [225600/525306]\n",
      "loss: 0.789571  [227200/525306]\n",
      "loss: 0.904439  [228800/525306]\n",
      "loss: 0.695281  [230400/525306]\n",
      "loss: 0.700953  [232000/525306]\n",
      "loss: 1.449205  [233600/525306]\n",
      "loss: 0.404628  [235200/525306]\n",
      "loss: 1.300494  [236800/525306]\n",
      "loss: 0.601452  [238400/525306]\n",
      "loss: 0.641284  [240000/525306]\n",
      "loss: 0.550643  [241600/525306]\n",
      "loss: 0.953211  [243200/525306]\n",
      "loss: 0.641731  [244800/525306]\n",
      "loss: 0.610990  [246400/525306]\n",
      "loss: 0.625807  [248000/525306]\n",
      "loss: 0.960535  [249600/525306]\n",
      "loss: 0.761032  [251200/525306]\n",
      "loss: 1.094719  [252800/525306]\n",
      "loss: 1.051925  [254400/525306]\n",
      "loss: 1.146043  [256000/525306]\n",
      "loss: 0.722335  [257600/525306]\n",
      "loss: 0.688895  [259200/525306]\n",
      "loss: 0.759821  [260800/525306]\n",
      "loss: 0.710248  [262400/525306]\n",
      "loss: 0.940553  [264000/525306]\n",
      "loss: 1.049293  [265600/525306]\n",
      "loss: 0.781336  [267200/525306]\n",
      "loss: 1.030679  [268800/525306]\n",
      "loss: 1.167408  [270400/525306]\n",
      "loss: 1.003164  [272000/525306]\n",
      "loss: 0.777592  [273600/525306]\n",
      "loss: 0.874058  [275200/525306]\n",
      "loss: 0.994193  [276800/525306]\n",
      "loss: 1.147734  [278400/525306]\n",
      "loss: 0.668622  [280000/525306]\n",
      "loss: 0.814402  [281600/525306]\n",
      "loss: 0.440441  [283200/525306]\n",
      "loss: 0.939474  [284800/525306]\n",
      "loss: 0.842357  [286400/525306]\n",
      "loss: 0.620035  [288000/525306]\n",
      "loss: 0.469917  [289600/525306]\n",
      "loss: 0.546981  [291200/525306]\n",
      "loss: 0.680202  [292800/525306]\n",
      "loss: 0.915863  [294400/525306]\n",
      "loss: 0.854810  [296000/525306]\n",
      "loss: 1.108008  [297600/525306]\n",
      "loss: 0.847990  [299200/525306]\n",
      "loss: 0.697548  [300800/525306]\n",
      "loss: 0.675683  [302400/525306]\n",
      "loss: 0.553391  [304000/525306]\n",
      "loss: 1.572195  [305600/525306]\n",
      "loss: 0.829720  [307200/525306]\n",
      "loss: 0.682721  [308800/525306]\n",
      "loss: 0.400548  [310400/525306]\n",
      "loss: 0.539882  [312000/525306]\n",
      "loss: 1.682363  [313600/525306]\n",
      "loss: 0.820170  [315200/525306]\n",
      "loss: 0.798215  [316800/525306]\n",
      "loss: 0.868201  [318400/525306]\n",
      "loss: 0.954236  [320000/525306]\n",
      "loss: 0.643559  [321600/525306]\n",
      "loss: 0.417559  [323200/525306]\n",
      "loss: 1.422580  [324800/525306]\n",
      "loss: 1.103691  [326400/525306]\n",
      "loss: 0.661245  [328000/525306]\n",
      "loss: 1.100523  [329600/525306]\n",
      "loss: 0.834252  [331200/525306]\n",
      "loss: 1.087613  [332800/525306]\n",
      "loss: 0.723816  [334400/525306]\n",
      "loss: 0.754341  [336000/525306]\n",
      "loss: 1.338371  [337600/525306]\n",
      "loss: 0.831898  [339200/525306]\n",
      "loss: 0.863199  [340800/525306]\n",
      "loss: 0.450234  [342400/525306]\n",
      "loss: 1.037308  [344000/525306]\n",
      "loss: 0.778607  [345600/525306]\n",
      "loss: 0.799591  [347200/525306]\n",
      "loss: 0.722094  [348800/525306]\n",
      "loss: 0.651514  [350400/525306]\n",
      "loss: 0.985852  [352000/525306]\n",
      "loss: 0.748086  [353600/525306]\n",
      "loss: 0.716513  [355200/525306]\n",
      "loss: 0.987544  [356800/525306]\n",
      "loss: 0.775444  [358400/525306]\n",
      "loss: 0.966267  [360000/525306]\n",
      "loss: 0.744058  [361600/525306]\n",
      "loss: 0.828429  [363200/525306]\n",
      "loss: 0.499174  [364800/525306]\n",
      "loss: 0.816269  [366400/525306]\n",
      "loss: 1.054674  [368000/525306]\n",
      "loss: 0.724198  [369600/525306]\n",
      "loss: 0.750169  [371200/525306]\n",
      "loss: 1.080563  [372800/525306]\n",
      "loss: 0.813421  [374400/525306]\n",
      "loss: 1.076059  [376000/525306]\n",
      "loss: 0.899522  [377600/525306]\n",
      "loss: 0.523179  [379200/525306]\n",
      "loss: 0.638097  [380800/525306]\n",
      "loss: 0.637818  [382400/525306]\n",
      "loss: 0.951215  [384000/525306]\n",
      "loss: 0.706090  [385600/525306]\n",
      "loss: 0.514610  [387200/525306]\n",
      "loss: 0.876070  [388800/525306]\n",
      "loss: 0.926946  [390400/525306]\n",
      "loss: 1.096151  [392000/525306]\n",
      "loss: 1.101820  [393600/525306]\n",
      "loss: 0.707033  [395200/525306]\n",
      "loss: 0.534106  [396800/525306]\n",
      "loss: 0.582264  [398400/525306]\n",
      "loss: 0.889829  [400000/525306]\n",
      "loss: 0.769186  [401600/525306]\n",
      "loss: 0.579129  [403200/525306]\n",
      "loss: 0.885670  [404800/525306]\n",
      "loss: 1.236291  [406400/525306]\n",
      "loss: 1.406819  [408000/525306]\n",
      "loss: 0.709919  [409600/525306]\n",
      "loss: 0.687799  [411200/525306]\n",
      "loss: 0.919374  [412800/525306]\n",
      "loss: 0.468054  [414400/525306]\n",
      "loss: 0.929896  [416000/525306]\n",
      "loss: 0.650841  [417600/525306]\n",
      "loss: 0.790236  [419200/525306]\n",
      "loss: 0.735754  [420800/525306]\n",
      "loss: 1.077904  [422400/525306]\n",
      "loss: 0.897225  [424000/525306]\n",
      "loss: 0.442606  [425600/525306]\n",
      "loss: 1.125120  [427200/525306]\n",
      "loss: 0.986301  [428800/525306]\n",
      "loss: 1.027006  [430400/525306]\n",
      "loss: 0.538149  [432000/525306]\n",
      "loss: 0.812594  [433600/525306]\n",
      "loss: 1.112961  [435200/525306]\n",
      "loss: 0.823689  [436800/525306]\n",
      "loss: 1.024164  [438400/525306]\n",
      "loss: 0.705403  [440000/525306]\n",
      "loss: 0.604494  [441600/525306]\n",
      "loss: 0.535548  [443200/525306]\n",
      "loss: 0.625565  [444800/525306]\n",
      "loss: 1.359062  [446400/525306]\n",
      "loss: 0.859984  [448000/525306]\n",
      "loss: 0.741084  [449600/525306]\n",
      "loss: 0.499893  [451200/525306]\n",
      "loss: 1.121846  [452800/525306]\n",
      "loss: 0.956470  [454400/525306]\n",
      "loss: 0.892424  [456000/525306]\n",
      "loss: 0.605674  [457600/525306]\n",
      "loss: 1.098341  [459200/525306]\n",
      "loss: 1.464537  [460800/525306]\n",
      "loss: 0.847543  [462400/525306]\n",
      "loss: 0.760847  [464000/525306]\n",
      "loss: 0.995260  [465600/525306]\n",
      "loss: 1.077123  [467200/525306]\n",
      "loss: 0.731721  [468800/525306]\n",
      "loss: 0.605991  [470400/525306]\n",
      "loss: 0.592816  [472000/525306]\n",
      "loss: 0.568588  [473600/525306]\n",
      "loss: 0.680624  [475200/525306]\n",
      "loss: 0.438338  [476800/525306]\n",
      "loss: 0.574296  [478400/525306]\n",
      "loss: 0.676389  [480000/525306]\n",
      "loss: 0.758850  [481600/525306]\n",
      "loss: 0.741097  [483200/525306]\n",
      "loss: 0.929628  [484800/525306]\n",
      "loss: 0.911359  [486400/525306]\n",
      "loss: 0.767224  [488000/525306]\n",
      "loss: 1.333583  [489600/525306]\n",
      "loss: 0.442428  [491200/525306]\n",
      "loss: 1.196254  [492800/525306]\n",
      "loss: 0.621772  [494400/525306]\n",
      "loss: 0.619275  [496000/525306]\n",
      "loss: 0.713821  [497600/525306]\n",
      "loss: 1.387385  [499200/525306]\n",
      "loss: 1.130472  [500800/525306]\n",
      "loss: 0.825371  [502400/525306]\n",
      "loss: 1.220565  [504000/525306]\n",
      "loss: 1.154498  [505600/525306]\n",
      "loss: 0.341389  [507200/525306]\n",
      "loss: 1.102673  [508800/525306]\n",
      "loss: 1.172660  [510400/525306]\n",
      "loss: 1.128003  [512000/525306]\n",
      "loss: 0.819360  [513600/525306]\n",
      "loss: 0.828437  [515200/525306]\n",
      "loss: 0.801030  [516800/525306]\n",
      "loss: 0.959026  [518400/525306]\n",
      "loss: 0.580936  [520000/525306]\n",
      "loss: 0.483269  [521600/525306]\n",
      "loss: 0.726419  [523200/525306]\n",
      "loss: 0.754807  [524800/525306]\n",
      "Train Accuracy: 68.1460%\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.992220, F1-score: 68.81%, Macro_F1-Score:  39.33%  \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.011896  [    0/525306]\n",
      "loss: 1.286908  [ 1600/525306]\n",
      "loss: 0.723273  [ 3200/525306]\n",
      "loss: 0.674009  [ 4800/525306]\n",
      "loss: 0.621229  [ 6400/525306]\n",
      "loss: 0.776060  [ 8000/525306]\n",
      "loss: 0.942262  [ 9600/525306]\n",
      "loss: 0.785038  [11200/525306]\n",
      "loss: 1.057663  [12800/525306]\n",
      "loss: 0.931415  [14400/525306]\n",
      "loss: 0.713744  [16000/525306]\n",
      "loss: 0.470357  [17600/525306]\n",
      "loss: 1.089951  [19200/525306]\n",
      "loss: 0.956753  [20800/525306]\n",
      "loss: 1.025941  [22400/525306]\n",
      "loss: 0.952736  [24000/525306]\n",
      "loss: 1.450349  [25600/525306]\n",
      "loss: 0.784586  [27200/525306]\n",
      "loss: 0.788069  [28800/525306]\n",
      "loss: 0.598335  [30400/525306]\n",
      "loss: 0.590674  [32000/525306]\n",
      "loss: 0.935377  [33600/525306]\n",
      "loss: 0.627623  [35200/525306]\n",
      "loss: 0.637293  [36800/525306]\n",
      "loss: 0.519884  [38400/525306]\n",
      "loss: 0.540212  [40000/525306]\n",
      "loss: 1.425034  [41600/525306]\n",
      "loss: 1.154320  [43200/525306]\n",
      "loss: 1.054879  [44800/525306]\n",
      "loss: 0.687720  [46400/525306]\n",
      "loss: 0.528009  [48000/525306]\n",
      "loss: 1.052945  [49600/525306]\n",
      "loss: 0.706314  [51200/525306]\n",
      "loss: 1.067073  [52800/525306]\n",
      "loss: 0.878761  [54400/525306]\n",
      "loss: 0.653950  [56000/525306]\n",
      "loss: 0.800248  [57600/525306]\n",
      "loss: 0.824981  [59200/525306]\n",
      "loss: 0.809691  [60800/525306]\n",
      "loss: 0.569003  [62400/525306]\n",
      "loss: 0.508351  [64000/525306]\n",
      "loss: 0.570121  [65600/525306]\n",
      "loss: 0.721235  [67200/525306]\n",
      "loss: 0.447686  [68800/525306]\n",
      "loss: 1.465041  [70400/525306]\n",
      "loss: 0.507943  [72000/525306]\n",
      "loss: 0.674400  [73600/525306]\n",
      "loss: 0.709131  [75200/525306]\n",
      "loss: 0.881509  [76800/525306]\n",
      "loss: 0.755176  [78400/525306]\n",
      "loss: 0.822236  [80000/525306]\n",
      "loss: 1.017309  [81600/525306]\n",
      "loss: 0.538250  [83200/525306]\n",
      "loss: 0.952148  [84800/525306]\n",
      "loss: 0.581910  [86400/525306]\n",
      "loss: 0.385874  [88000/525306]\n",
      "loss: 0.627439  [89600/525306]\n",
      "loss: 0.691607  [91200/525306]\n",
      "loss: 0.936214  [92800/525306]\n",
      "loss: 1.099867  [94400/525306]\n",
      "loss: 0.873961  [96000/525306]\n",
      "loss: 1.134973  [97600/525306]\n",
      "loss: 0.906096  [99200/525306]\n",
      "loss: 0.705367  [100800/525306]\n",
      "loss: 1.172467  [102400/525306]\n",
      "loss: 0.958011  [104000/525306]\n",
      "loss: 0.926951  [105600/525306]\n",
      "loss: 1.024628  [107200/525306]\n",
      "loss: 0.905397  [108800/525306]\n",
      "loss: 0.833704  [110400/525306]\n",
      "loss: 0.770637  [112000/525306]\n",
      "loss: 0.524623  [113600/525306]\n",
      "loss: 1.360325  [115200/525306]\n",
      "loss: 0.859846  [116800/525306]\n",
      "loss: 0.624443  [118400/525306]\n",
      "loss: 0.743269  [120000/525306]\n",
      "loss: 0.642313  [121600/525306]\n",
      "loss: 0.968496  [123200/525306]\n",
      "loss: 0.709537  [124800/525306]\n",
      "loss: 0.671932  [126400/525306]\n",
      "loss: 1.208341  [128000/525306]\n",
      "loss: 0.504426  [129600/525306]\n",
      "loss: 0.762264  [131200/525306]\n",
      "loss: 0.517511  [132800/525306]\n",
      "loss: 1.156626  [134400/525306]\n",
      "loss: 0.720901  [136000/525306]\n",
      "loss: 0.962662  [137600/525306]\n",
      "loss: 0.654071  [139200/525306]\n",
      "loss: 0.670222  [140800/525306]\n",
      "loss: 0.502534  [142400/525306]\n",
      "loss: 1.298935  [144000/525306]\n",
      "loss: 0.748786  [145600/525306]\n",
      "loss: 0.666095  [147200/525306]\n",
      "loss: 0.751833  [148800/525306]\n",
      "loss: 1.334303  [150400/525306]\n",
      "loss: 0.447321  [152000/525306]\n",
      "loss: 0.671569  [153600/525306]\n",
      "loss: 0.869106  [155200/525306]\n",
      "loss: 0.595480  [156800/525306]\n",
      "loss: 0.840104  [158400/525306]\n",
      "loss: 0.862734  [160000/525306]\n",
      "loss: 0.896300  [161600/525306]\n",
      "loss: 0.918336  [163200/525306]\n",
      "loss: 1.372038  [164800/525306]\n",
      "loss: 0.597067  [166400/525306]\n",
      "loss: 0.783842  [168000/525306]\n",
      "loss: 0.362502  [169600/525306]\n",
      "loss: 0.591514  [171200/525306]\n",
      "loss: 0.836115  [172800/525306]\n",
      "loss: 0.427637  [174400/525306]\n",
      "loss: 0.837844  [176000/525306]\n",
      "loss: 0.650242  [177600/525306]\n",
      "loss: 1.091356  [179200/525306]\n",
      "loss: 0.699764  [180800/525306]\n",
      "loss: 0.819097  [182400/525306]\n",
      "loss: 1.196600  [184000/525306]\n",
      "loss: 1.106168  [185600/525306]\n",
      "loss: 1.143456  [187200/525306]\n",
      "loss: 1.068560  [188800/525306]\n",
      "loss: 0.732333  [190400/525306]\n",
      "loss: 0.941838  [192000/525306]\n",
      "loss: 0.522432  [193600/525306]\n",
      "loss: 0.836625  [195200/525306]\n",
      "loss: 0.769204  [196800/525306]\n",
      "loss: 0.637179  [198400/525306]\n",
      "loss: 0.747024  [200000/525306]\n",
      "loss: 0.893163  [201600/525306]\n",
      "loss: 0.824872  [203200/525306]\n",
      "loss: 0.602611  [204800/525306]\n",
      "loss: 0.920525  [206400/525306]\n",
      "loss: 0.785807  [208000/525306]\n",
      "loss: 0.668893  [209600/525306]\n",
      "loss: 0.493479  [211200/525306]\n",
      "loss: 1.159500  [212800/525306]\n",
      "loss: 1.057627  [214400/525306]\n",
      "loss: 0.482788  [216000/525306]\n",
      "loss: 0.486009  [217600/525306]\n",
      "loss: 1.084317  [219200/525306]\n",
      "loss: 0.680070  [220800/525306]\n",
      "loss: 1.662202  [222400/525306]\n",
      "loss: 0.442510  [224000/525306]\n",
      "loss: 0.603384  [225600/525306]\n",
      "loss: 0.849706  [227200/525306]\n",
      "loss: 0.476312  [228800/525306]\n",
      "loss: 0.816841  [230400/525306]\n",
      "loss: 0.986645  [232000/525306]\n",
      "loss: 0.690561  [233600/525306]\n",
      "loss: 0.946523  [235200/525306]\n",
      "loss: 0.711928  [236800/525306]\n",
      "loss: 0.946106  [238400/525306]\n",
      "loss: 0.672024  [240000/525306]\n",
      "loss: 0.906907  [241600/525306]\n",
      "loss: 0.712640  [243200/525306]\n",
      "loss: 0.812963  [244800/525306]\n",
      "loss: 1.106559  [246400/525306]\n",
      "loss: 0.682444  [248000/525306]\n",
      "loss: 0.692760  [249600/525306]\n",
      "loss: 0.540186  [251200/525306]\n",
      "loss: 1.101190  [252800/525306]\n",
      "loss: 1.209220  [254400/525306]\n",
      "loss: 0.833698  [256000/525306]\n",
      "loss: 0.548381  [257600/525306]\n",
      "loss: 0.834703  [259200/525306]\n",
      "loss: 0.494470  [260800/525306]\n",
      "loss: 0.599410  [262400/525306]\n",
      "loss: 0.838728  [264000/525306]\n",
      "loss: 0.879647  [265600/525306]\n",
      "loss: 1.257069  [267200/525306]\n",
      "loss: 1.151743  [268800/525306]\n",
      "loss: 0.481988  [270400/525306]\n",
      "loss: 0.848218  [272000/525306]\n",
      "loss: 0.811019  [273600/525306]\n",
      "loss: 0.510969  [275200/525306]\n",
      "loss: 0.634111  [276800/525306]\n",
      "loss: 0.867157  [278400/525306]\n",
      "loss: 0.780408  [280000/525306]\n",
      "loss: 0.568774  [281600/525306]\n",
      "loss: 0.524267  [283200/525306]\n",
      "loss: 0.647444  [284800/525306]\n",
      "loss: 0.644074  [286400/525306]\n",
      "loss: 0.809939  [288000/525306]\n",
      "loss: 0.632500  [289600/525306]\n",
      "loss: 0.675145  [291200/525306]\n",
      "loss: 0.756734  [292800/525306]\n",
      "loss: 1.098475  [294400/525306]\n",
      "loss: 0.520478  [296000/525306]\n",
      "loss: 0.642562  [297600/525306]\n",
      "loss: 1.154464  [299200/525306]\n",
      "loss: 0.819227  [300800/525306]\n",
      "loss: 0.583932  [302400/525306]\n",
      "loss: 1.145069  [304000/525306]\n",
      "loss: 1.260864  [305600/525306]\n",
      "loss: 0.893601  [307200/525306]\n",
      "loss: 0.682141  [308800/525306]\n",
      "loss: 0.938423  [310400/525306]\n",
      "loss: 0.914125  [312000/525306]\n",
      "loss: 0.772168  [313600/525306]\n",
      "loss: 0.480006  [315200/525306]\n",
      "loss: 0.800468  [316800/525306]\n",
      "loss: 0.793480  [318400/525306]\n",
      "loss: 0.590201  [320000/525306]\n",
      "loss: 1.202415  [321600/525306]\n",
      "loss: 0.757341  [323200/525306]\n",
      "loss: 1.005714  [324800/525306]\n",
      "loss: 1.363562  [326400/525306]\n",
      "loss: 0.544185  [328000/525306]\n",
      "loss: 0.560280  [329600/525306]\n",
      "loss: 1.408281  [331200/525306]\n",
      "loss: 0.690895  [332800/525306]\n",
      "loss: 0.880639  [334400/525306]\n",
      "loss: 0.419247  [336000/525306]\n",
      "loss: 0.593391  [337600/525306]\n",
      "loss: 0.735485  [339200/525306]\n",
      "loss: 0.501801  [340800/525306]\n",
      "loss: 0.654378  [342400/525306]\n",
      "loss: 0.768981  [344000/525306]\n",
      "loss: 1.426641  [345600/525306]\n",
      "loss: 1.200772  [347200/525306]\n",
      "loss: 0.623697  [348800/525306]\n",
      "loss: 0.662029  [350400/525306]\n",
      "loss: 0.642436  [352000/525306]\n",
      "loss: 1.104288  [353600/525306]\n",
      "loss: 0.790850  [355200/525306]\n",
      "loss: 0.870374  [356800/525306]\n",
      "loss: 0.751994  [358400/525306]\n",
      "loss: 0.752653  [360000/525306]\n",
      "loss: 0.582808  [361600/525306]\n",
      "loss: 1.068834  [363200/525306]\n",
      "loss: 0.818621  [364800/525306]\n",
      "loss: 1.335459  [366400/525306]\n",
      "loss: 0.570667  [368000/525306]\n",
      "loss: 0.411586  [369600/525306]\n",
      "loss: 0.930384  [371200/525306]\n",
      "loss: 0.878108  [372800/525306]\n",
      "loss: 0.906938  [374400/525306]\n",
      "loss: 0.773144  [376000/525306]\n",
      "loss: 1.046318  [377600/525306]\n",
      "loss: 0.671787  [379200/525306]\n",
      "loss: 1.107083  [380800/525306]\n",
      "loss: 0.631268  [382400/525306]\n",
      "loss: 0.958513  [384000/525306]\n",
      "loss: 0.834842  [385600/525306]\n",
      "loss: 0.866490  [387200/525306]\n",
      "loss: 1.203286  [388800/525306]\n",
      "loss: 1.200093  [390400/525306]\n",
      "loss: 0.975644  [392000/525306]\n",
      "loss: 0.899706  [393600/525306]\n",
      "loss: 0.749947  [395200/525306]\n",
      "loss: 0.838116  [396800/525306]\n",
      "loss: 1.146512  [398400/525306]\n",
      "loss: 0.759278  [400000/525306]\n",
      "loss: 1.263531  [401600/525306]\n",
      "loss: 0.727020  [403200/525306]\n",
      "loss: 0.405681  [404800/525306]\n",
      "loss: 0.790664  [406400/525306]\n",
      "loss: 0.930315  [408000/525306]\n",
      "loss: 0.984146  [409600/525306]\n",
      "loss: 0.822663  [411200/525306]\n",
      "loss: 0.842406  [412800/525306]\n",
      "loss: 0.710151  [414400/525306]\n",
      "loss: 0.687602  [416000/525306]\n",
      "loss: 0.810623  [417600/525306]\n",
      "loss: 0.479045  [419200/525306]\n",
      "loss: 0.875846  [420800/525306]\n",
      "loss: 0.561854  [422400/525306]\n",
      "loss: 0.968024  [424000/525306]\n",
      "loss: 1.187828  [425600/525306]\n",
      "loss: 1.315213  [427200/525306]\n",
      "loss: 1.050146  [428800/525306]\n",
      "loss: 0.875702  [430400/525306]\n",
      "loss: 0.851001  [432000/525306]\n",
      "loss: 1.241789  [433600/525306]\n",
      "loss: 0.850742  [435200/525306]\n",
      "loss: 0.505609  [436800/525306]\n",
      "loss: 0.731974  [438400/525306]\n",
      "loss: 0.880547  [440000/525306]\n",
      "loss: 0.756741  [441600/525306]\n",
      "loss: 1.158076  [443200/525306]\n",
      "loss: 1.079317  [444800/525306]\n",
      "loss: 0.423638  [446400/525306]\n",
      "loss: 0.697153  [448000/525306]\n",
      "loss: 0.463235  [449600/525306]\n",
      "loss: 1.408468  [451200/525306]\n",
      "loss: 0.957791  [452800/525306]\n",
      "loss: 1.153343  [454400/525306]\n",
      "loss: 0.476780  [456000/525306]\n",
      "loss: 0.749886  [457600/525306]\n",
      "loss: 0.715208  [459200/525306]\n",
      "loss: 0.572623  [460800/525306]\n",
      "loss: 0.614453  [462400/525306]\n",
      "loss: 0.867828  [464000/525306]\n",
      "loss: 1.385668  [465600/525306]\n",
      "loss: 0.668797  [467200/525306]\n",
      "loss: 0.789008  [468800/525306]\n",
      "loss: 1.281044  [470400/525306]\n",
      "loss: 0.458367  [472000/525306]\n",
      "loss: 0.404661  [473600/525306]\n",
      "loss: 0.578335  [475200/525306]\n",
      "loss: 1.041752  [476800/525306]\n",
      "loss: 1.195583  [478400/525306]\n",
      "loss: 0.499964  [480000/525306]\n",
      "loss: 0.904900  [481600/525306]\n",
      "loss: 0.939713  [483200/525306]\n",
      "loss: 0.824398  [484800/525306]\n",
      "loss: 1.824888  [486400/525306]\n",
      "loss: 0.597691  [488000/525306]\n",
      "loss: 1.084150  [489600/525306]\n",
      "loss: 0.875326  [491200/525306]\n",
      "loss: 0.964815  [492800/525306]\n",
      "loss: 1.012518  [494400/525306]\n",
      "loss: 0.873040  [496000/525306]\n",
      "loss: 0.611450  [497600/525306]\n",
      "loss: 0.804573  [499200/525306]\n",
      "loss: 1.437557  [500800/525306]\n",
      "loss: 0.751583  [502400/525306]\n",
      "loss: 0.738735  [504000/525306]\n",
      "loss: 0.503322  [505600/525306]\n",
      "loss: 0.897802  [507200/525306]\n",
      "loss: 0.710920  [508800/525306]\n",
      "loss: 0.883414  [510400/525306]\n",
      "loss: 0.217511  [512000/525306]\n",
      "loss: 0.970235  [513600/525306]\n",
      "loss: 0.669608  [515200/525306]\n",
      "loss: 1.291570  [516800/525306]\n",
      "loss: 1.222063  [518400/525306]\n",
      "loss: 0.978683  [520000/525306]\n",
      "loss: 0.998626  [521600/525306]\n",
      "loss: 0.907674  [523200/525306]\n",
      "loss: 1.000845  [524800/525306]\n",
      "Train Accuracy: 68.5033%\n",
      "Test Error: \n",
      " Accuracy: 62.0%, Avg loss: 1.005130, F1-score: 68.04%, Macro_F1-Score:  37.51%  \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.722464  [    0/525306]\n",
      "loss: 1.178714  [ 1600/525306]\n",
      "loss: 0.568540  [ 3200/525306]\n",
      "loss: 1.236610  [ 4800/525306]\n",
      "loss: 0.549308  [ 6400/525306]\n",
      "loss: 0.559176  [ 8000/525306]\n",
      "loss: 0.739416  [ 9600/525306]\n",
      "loss: 1.259570  [11200/525306]\n",
      "loss: 0.716640  [12800/525306]\n",
      "loss: 0.527430  [14400/525306]\n",
      "loss: 0.883427  [16000/525306]\n",
      "loss: 0.796747  [17600/525306]\n",
      "loss: 0.811114  [19200/525306]\n",
      "loss: 1.342632  [20800/525306]\n",
      "loss: 0.644780  [22400/525306]\n",
      "loss: 0.784714  [24000/525306]\n",
      "loss: 0.746098  [25600/525306]\n",
      "loss: 1.361092  [27200/525306]\n",
      "loss: 0.745785  [28800/525306]\n",
      "loss: 0.926125  [30400/525306]\n",
      "loss: 0.570969  [32000/525306]\n",
      "loss: 0.936539  [33600/525306]\n",
      "loss: 1.338042  [35200/525306]\n",
      "loss: 1.026721  [36800/525306]\n",
      "loss: 0.645049  [38400/525306]\n",
      "loss: 0.746060  [40000/525306]\n",
      "loss: 0.355722  [41600/525306]\n",
      "loss: 0.989998  [43200/525306]\n",
      "loss: 0.874424  [44800/525306]\n",
      "loss: 1.019231  [46400/525306]\n",
      "loss: 0.971016  [48000/525306]\n",
      "loss: 0.684283  [49600/525306]\n",
      "loss: 0.912836  [51200/525306]\n",
      "loss: 1.049024  [52800/525306]\n",
      "loss: 0.613223  [54400/525306]\n",
      "loss: 0.715103  [56000/525306]\n",
      "loss: 0.765865  [57600/525306]\n",
      "loss: 0.722802  [59200/525306]\n",
      "loss: 0.729892  [60800/525306]\n",
      "loss: 0.687475  [62400/525306]\n",
      "loss: 0.696461  [64000/525306]\n",
      "loss: 0.860403  [65600/525306]\n",
      "loss: 0.371557  [67200/525306]\n",
      "loss: 0.668084  [68800/525306]\n",
      "loss: 1.216540  [70400/525306]\n",
      "loss: 0.608293  [72000/525306]\n",
      "loss: 0.870281  [73600/525306]\n",
      "loss: 0.270015  [75200/525306]\n",
      "loss: 0.912107  [76800/525306]\n",
      "loss: 1.470129  [78400/525306]\n",
      "loss: 0.508612  [80000/525306]\n",
      "loss: 1.050302  [81600/525306]\n",
      "loss: 0.862738  [83200/525306]\n",
      "loss: 0.504405  [84800/525306]\n",
      "loss: 1.185377  [86400/525306]\n",
      "loss: 0.846498  [88000/525306]\n",
      "loss: 0.298624  [89600/525306]\n",
      "loss: 0.735001  [91200/525306]\n",
      "loss: 0.973908  [92800/525306]\n",
      "loss: 0.935254  [94400/525306]\n",
      "loss: 0.968291  [96000/525306]\n",
      "loss: 0.637812  [97600/525306]\n",
      "loss: 1.208837  [99200/525306]\n",
      "loss: 0.502953  [100800/525306]\n",
      "loss: 0.555108  [102400/525306]\n",
      "loss: 0.582475  [104000/525306]\n",
      "loss: 0.571206  [105600/525306]\n",
      "loss: 0.441598  [107200/525306]\n",
      "loss: 0.792259  [108800/525306]\n",
      "loss: 1.110049  [110400/525306]\n",
      "loss: 0.857108  [112000/525306]\n",
      "loss: 0.762868  [113600/525306]\n",
      "loss: 0.655237  [115200/525306]\n",
      "loss: 0.632275  [116800/525306]\n",
      "loss: 1.039990  [118400/525306]\n",
      "loss: 0.680740  [120000/525306]\n",
      "loss: 1.044053  [121600/525306]\n",
      "loss: 0.695801  [123200/525306]\n",
      "loss: 0.905048  [124800/525306]\n",
      "loss: 0.740474  [126400/525306]\n",
      "loss: 0.631411  [128000/525306]\n",
      "loss: 0.468449  [129600/525306]\n",
      "loss: 0.922201  [131200/525306]\n",
      "loss: 0.399340  [132800/525306]\n",
      "loss: 0.703236  [134400/525306]\n",
      "loss: 0.555818  [136000/525306]\n",
      "loss: 1.084907  [137600/525306]\n",
      "loss: 0.718366  [139200/525306]\n",
      "loss: 0.965931  [140800/525306]\n",
      "loss: 1.006496  [142400/525306]\n",
      "loss: 0.753397  [144000/525306]\n",
      "loss: 0.751232  [145600/525306]\n",
      "loss: 0.985553  [147200/525306]\n",
      "loss: 0.754348  [148800/525306]\n",
      "loss: 0.715254  [150400/525306]\n",
      "loss: 0.847115  [152000/525306]\n",
      "loss: 0.434849  [153600/525306]\n",
      "loss: 1.028881  [155200/525306]\n",
      "loss: 0.842876  [156800/525306]\n",
      "loss: 0.496848  [158400/525306]\n",
      "loss: 0.904623  [160000/525306]\n",
      "loss: 0.696229  [161600/525306]\n",
      "loss: 0.750789  [163200/525306]\n",
      "loss: 1.080354  [164800/525306]\n",
      "loss: 0.878430  [166400/525306]\n",
      "loss: 0.967750  [168000/525306]\n",
      "loss: 0.903259  [169600/525306]\n",
      "loss: 0.578830  [171200/525306]\n",
      "loss: 0.687069  [172800/525306]\n",
      "loss: 0.660827  [174400/525306]\n",
      "loss: 0.639438  [176000/525306]\n",
      "loss: 0.588505  [177600/525306]\n",
      "loss: 0.720662  [179200/525306]\n",
      "loss: 0.601582  [180800/525306]\n",
      "loss: 0.731953  [182400/525306]\n",
      "loss: 0.769353  [184000/525306]\n",
      "loss: 0.815143  [185600/525306]\n",
      "loss: 0.919997  [187200/525306]\n",
      "loss: 0.746623  [188800/525306]\n",
      "loss: 1.009313  [190400/525306]\n",
      "loss: 0.820763  [192000/525306]\n",
      "loss: 0.713315  [193600/525306]\n",
      "loss: 0.689795  [195200/525306]\n",
      "loss: 0.876316  [196800/525306]\n",
      "loss: 0.604778  [198400/525306]\n",
      "loss: 0.981156  [200000/525306]\n",
      "loss: 0.839563  [201600/525306]\n",
      "loss: 1.001598  [203200/525306]\n",
      "loss: 0.907332  [204800/525306]\n",
      "loss: 1.033588  [206400/525306]\n",
      "loss: 1.102725  [208000/525306]\n",
      "loss: 0.756143  [209600/525306]\n",
      "loss: 0.720489  [211200/525306]\n",
      "loss: 1.028704  [212800/525306]\n",
      "loss: 0.583579  [214400/525306]\n",
      "loss: 0.583755  [216000/525306]\n",
      "loss: 0.728079  [217600/525306]\n",
      "loss: 0.517795  [219200/525306]\n",
      "loss: 1.019963  [220800/525306]\n",
      "loss: 1.560341  [222400/525306]\n",
      "loss: 0.656438  [224000/525306]\n",
      "loss: 0.895386  [225600/525306]\n",
      "loss: 1.115283  [227200/525306]\n",
      "loss: 0.415707  [228800/525306]\n",
      "loss: 0.692052  [230400/525306]\n",
      "loss: 0.851214  [232000/525306]\n",
      "loss: 0.864264  [233600/525306]\n",
      "loss: 1.040256  [235200/525306]\n",
      "loss: 0.747726  [236800/525306]\n",
      "loss: 0.413274  [238400/525306]\n",
      "loss: 0.540407  [240000/525306]\n",
      "loss: 1.011173  [241600/525306]\n",
      "loss: 1.352057  [243200/525306]\n",
      "loss: 1.145442  [244800/525306]\n",
      "loss: 0.868090  [246400/525306]\n",
      "loss: 0.888427  [248000/525306]\n",
      "loss: 0.525044  [249600/525306]\n",
      "loss: 0.519098  [251200/525306]\n",
      "loss: 0.611817  [252800/525306]\n",
      "loss: 0.951521  [254400/525306]\n",
      "loss: 0.979633  [256000/525306]\n",
      "loss: 1.243471  [257600/525306]\n",
      "loss: 0.761528  [259200/525306]\n",
      "loss: 0.884133  [260800/525306]\n",
      "loss: 0.956650  [262400/525306]\n",
      "loss: 0.808638  [264000/525306]\n",
      "loss: 0.769718  [265600/525306]\n",
      "loss: 0.648428  [267200/525306]\n",
      "loss: 0.828729  [268800/525306]\n",
      "loss: 1.050383  [270400/525306]\n",
      "loss: 0.933167  [272000/525306]\n",
      "loss: 0.557045  [273600/525306]\n",
      "loss: 0.328013  [275200/525306]\n",
      "loss: 0.497534  [276800/525306]\n",
      "loss: 1.107135  [278400/525306]\n",
      "loss: 0.730199  [280000/525306]\n",
      "loss: 0.889045  [281600/525306]\n",
      "loss: 0.803532  [283200/525306]\n",
      "loss: 0.651723  [284800/525306]\n",
      "loss: 1.087455  [286400/525306]\n",
      "loss: 1.088098  [288000/525306]\n",
      "loss: 0.970170  [289600/525306]\n",
      "loss: 1.229696  [291200/525306]\n",
      "loss: 0.744369  [292800/525306]\n",
      "loss: 0.836052  [294400/525306]\n",
      "loss: 0.749480  [296000/525306]\n",
      "loss: 0.964767  [297600/525306]\n",
      "loss: 0.676783  [299200/525306]\n",
      "loss: 0.493418  [300800/525306]\n",
      "loss: 0.782243  [302400/525306]\n",
      "loss: 0.481338  [304000/525306]\n",
      "loss: 0.921644  [305600/525306]\n",
      "loss: 0.895205  [307200/525306]\n",
      "loss: 0.697513  [308800/525306]\n",
      "loss: 0.412955  [310400/525306]\n",
      "loss: 1.042558  [312000/525306]\n",
      "loss: 0.880813  [313600/525306]\n",
      "loss: 0.447322  [315200/525306]\n",
      "loss: 0.869130  [316800/525306]\n",
      "loss: 0.707033  [318400/525306]\n",
      "loss: 0.906679  [320000/525306]\n",
      "loss: 1.032326  [321600/525306]\n",
      "loss: 0.490945  [323200/525306]\n",
      "loss: 0.649193  [324800/525306]\n",
      "loss: 0.466189  [326400/525306]\n",
      "loss: 0.653054  [328000/525306]\n",
      "loss: 0.683266  [329600/525306]\n",
      "loss: 0.633611  [331200/525306]\n",
      "loss: 0.403811  [332800/525306]\n",
      "loss: 0.686632  [334400/525306]\n",
      "loss: 0.967313  [336000/525306]\n",
      "loss: 0.844507  [337600/525306]\n",
      "loss: 0.958597  [339200/525306]\n",
      "loss: 0.757479  [340800/525306]\n",
      "loss: 1.105479  [342400/525306]\n",
      "loss: 0.611035  [344000/525306]\n",
      "loss: 0.348917  [345600/525306]\n",
      "loss: 0.450394  [347200/525306]\n",
      "loss: 0.651874  [348800/525306]\n",
      "loss: 0.515729  [350400/525306]\n",
      "loss: 0.691831  [352000/525306]\n",
      "loss: 1.091308  [353600/525306]\n",
      "loss: 0.814873  [355200/525306]\n",
      "loss: 1.036663  [356800/525306]\n",
      "loss: 0.969455  [358400/525306]\n",
      "loss: 1.227383  [360000/525306]\n",
      "loss: 0.806906  [361600/525306]\n",
      "loss: 2.149232  [363200/525306]\n",
      "loss: 0.813852  [364800/525306]\n",
      "loss: 1.575761  [366400/525306]\n",
      "loss: 0.546500  [368000/525306]\n",
      "loss: 0.553073  [369600/525306]\n",
      "loss: 0.723234  [371200/525306]\n",
      "loss: 0.935900  [372800/525306]\n",
      "loss: 0.550715  [374400/525306]\n",
      "loss: 0.920391  [376000/525306]\n",
      "loss: 1.304730  [377600/525306]\n",
      "loss: 1.387730  [379200/525306]\n",
      "loss: 0.767141  [380800/525306]\n",
      "loss: 0.790953  [382400/525306]\n",
      "loss: 0.759331  [384000/525306]\n",
      "loss: 0.454106  [385600/525306]\n",
      "loss: 0.730307  [387200/525306]\n",
      "loss: 1.054899  [388800/525306]\n",
      "loss: 1.101277  [390400/525306]\n",
      "loss: 1.105897  [392000/525306]\n",
      "loss: 0.593088  [393600/525306]\n",
      "loss: 0.707294  [395200/525306]\n",
      "loss: 0.899043  [396800/525306]\n",
      "loss: 0.610646  [398400/525306]\n",
      "loss: 0.619489  [400000/525306]\n",
      "loss: 1.085132  [401600/525306]\n",
      "loss: 0.957549  [403200/525306]\n",
      "loss: 0.896617  [404800/525306]\n",
      "loss: 0.419918  [406400/525306]\n",
      "loss: 0.720945  [408000/525306]\n",
      "loss: 0.681988  [409600/525306]\n",
      "loss: 0.650280  [411200/525306]\n",
      "loss: 1.171644  [412800/525306]\n",
      "loss: 0.576578  [414400/525306]\n",
      "loss: 1.090804  [416000/525306]\n",
      "loss: 0.926638  [417600/525306]\n",
      "loss: 0.674496  [419200/525306]\n",
      "loss: 1.376713  [420800/525306]\n",
      "loss: 1.243897  [422400/525306]\n",
      "loss: 0.720127  [424000/525306]\n",
      "loss: 0.665744  [425600/525306]\n",
      "loss: 0.625323  [427200/525306]\n",
      "loss: 0.866980  [428800/525306]\n",
      "loss: 1.263420  [430400/525306]\n",
      "loss: 0.727887  [432000/525306]\n",
      "loss: 0.800840  [433600/525306]\n",
      "loss: 0.768743  [435200/525306]\n",
      "loss: 0.808109  [436800/525306]\n",
      "loss: 0.856307  [438400/525306]\n",
      "loss: 0.854777  [440000/525306]\n",
      "loss: 0.766517  [441600/525306]\n",
      "loss: 1.120311  [443200/525306]\n",
      "loss: 0.561537  [444800/525306]\n",
      "loss: 0.753401  [446400/525306]\n",
      "loss: 0.743937  [448000/525306]\n",
      "loss: 0.288003  [449600/525306]\n",
      "loss: 1.026432  [451200/525306]\n",
      "loss: 0.678444  [452800/525306]\n",
      "loss: 0.585203  [454400/525306]\n",
      "loss: 0.577377  [456000/525306]\n",
      "loss: 0.728895  [457600/525306]\n",
      "loss: 0.988964  [459200/525306]\n",
      "loss: 0.944913  [460800/525306]\n",
      "loss: 1.142035  [462400/525306]\n",
      "loss: 0.942825  [464000/525306]\n",
      "loss: 0.732074  [465600/525306]\n",
      "loss: 1.356426  [467200/525306]\n",
      "loss: 0.620095  [468800/525306]\n",
      "loss: 0.628174  [470400/525306]\n",
      "loss: 0.678643  [472000/525306]\n",
      "loss: 0.469672  [473600/525306]\n",
      "loss: 0.895774  [475200/525306]\n",
      "loss: 1.276685  [476800/525306]\n",
      "loss: 0.788674  [478400/525306]\n",
      "loss: 0.784549  [480000/525306]\n",
      "loss: 0.588576  [481600/525306]\n",
      "loss: 0.886494  [483200/525306]\n",
      "loss: 0.655064  [484800/525306]\n",
      "loss: 0.768848  [486400/525306]\n",
      "loss: 0.549390  [488000/525306]\n",
      "loss: 0.989346  [489600/525306]\n",
      "loss: 0.866370  [491200/525306]\n",
      "loss: 0.898416  [492800/525306]\n",
      "loss: 0.751587  [494400/525306]\n",
      "loss: 1.061390  [496000/525306]\n",
      "loss: 0.848921  [497600/525306]\n",
      "loss: 1.107530  [499200/525306]\n",
      "loss: 0.906763  [500800/525306]\n",
      "loss: 0.850953  [502400/525306]\n",
      "loss: 0.758088  [504000/525306]\n",
      "loss: 0.704706  [505600/525306]\n",
      "loss: 1.201063  [507200/525306]\n",
      "loss: 0.749074  [508800/525306]\n",
      "loss: 1.009891  [510400/525306]\n",
      "loss: 0.617560  [512000/525306]\n",
      "loss: 0.814420  [513600/525306]\n",
      "loss: 0.765190  [515200/525306]\n",
      "loss: 0.550618  [516800/525306]\n",
      "loss: 1.056842  [518400/525306]\n",
      "loss: 0.929997  [520000/525306]\n",
      "loss: 0.931155  [521600/525306]\n",
      "loss: 0.622456  [523200/525306]\n",
      "loss: 1.216031  [524800/525306]\n",
      "Train Accuracy: 68.9168%\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.965760, F1-score: 68.73%, Macro_F1-Score:  39.13%  \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.934038  [    0/525306]\n",
      "loss: 0.644696  [ 1600/525306]\n",
      "loss: 0.710232  [ 3200/525306]\n",
      "loss: 0.812861  [ 4800/525306]\n",
      "loss: 0.602943  [ 6400/525306]\n",
      "loss: 1.002989  [ 8000/525306]\n",
      "loss: 0.802123  [ 9600/525306]\n",
      "loss: 0.639592  [11200/525306]\n",
      "loss: 0.812946  [12800/525306]\n",
      "loss: 0.561159  [14400/525306]\n",
      "loss: 0.574460  [16000/525306]\n",
      "loss: 0.610379  [17600/525306]\n",
      "loss: 1.295966  [19200/525306]\n",
      "loss: 0.691645  [20800/525306]\n",
      "loss: 1.254193  [22400/525306]\n",
      "loss: 0.656320  [24000/525306]\n",
      "loss: 1.891852  [25600/525306]\n",
      "loss: 1.217641  [27200/525306]\n",
      "loss: 0.658244  [28800/525306]\n",
      "loss: 0.857878  [30400/525306]\n",
      "loss: 0.599490  [32000/525306]\n",
      "loss: 0.781876  [33600/525306]\n",
      "loss: 0.761594  [35200/525306]\n",
      "loss: 0.525897  [36800/525306]\n",
      "loss: 1.135000  [38400/525306]\n",
      "loss: 0.771391  [40000/525306]\n",
      "loss: 1.174251  [41600/525306]\n",
      "loss: 0.623214  [43200/525306]\n",
      "loss: 0.695652  [44800/525306]\n",
      "loss: 1.282426  [46400/525306]\n",
      "loss: 1.127316  [48000/525306]\n",
      "loss: 0.548481  [49600/525306]\n",
      "loss: 0.796728  [51200/525306]\n",
      "loss: 0.910639  [52800/525306]\n",
      "loss: 0.749531  [54400/525306]\n",
      "loss: 1.023282  [56000/525306]\n",
      "loss: 0.660670  [57600/525306]\n",
      "loss: 0.684746  [59200/525306]\n",
      "loss: 0.814609  [60800/525306]\n",
      "loss: 0.686955  [62400/525306]\n",
      "loss: 0.780545  [64000/525306]\n",
      "loss: 1.021666  [65600/525306]\n",
      "loss: 1.297397  [67200/525306]\n",
      "loss: 0.599616  [68800/525306]\n",
      "loss: 0.959660  [70400/525306]\n",
      "loss: 0.478177  [72000/525306]\n",
      "loss: 0.965977  [73600/525306]\n",
      "loss: 1.170912  [75200/525306]\n",
      "loss: 0.577749  [76800/525306]\n",
      "loss: 0.458762  [78400/525306]\n",
      "loss: 0.612483  [80000/525306]\n",
      "loss: 0.809149  [81600/525306]\n",
      "loss: 1.347961  [83200/525306]\n",
      "loss: 0.698846  [84800/525306]\n",
      "loss: 0.688440  [86400/525306]\n",
      "loss: 0.837312  [88000/525306]\n",
      "loss: 0.804418  [89600/525306]\n",
      "loss: 0.742037  [91200/525306]\n",
      "loss: 0.762443  [92800/525306]\n",
      "loss: 0.539926  [94400/525306]\n",
      "loss: 1.068729  [96000/525306]\n",
      "loss: 0.885939  [97600/525306]\n",
      "loss: 0.820922  [99200/525306]\n",
      "loss: 0.609920  [100800/525306]\n",
      "loss: 1.047814  [102400/525306]\n",
      "loss: 0.430020  [104000/525306]\n",
      "loss: 0.325782  [105600/525306]\n",
      "loss: 1.005786  [107200/525306]\n",
      "loss: 0.792994  [108800/525306]\n",
      "loss: 1.082335  [110400/525306]\n",
      "loss: 0.733433  [112000/525306]\n",
      "loss: 0.820335  [113600/525306]\n",
      "loss: 0.754926  [115200/525306]\n",
      "loss: 0.607735  [116800/525306]\n",
      "loss: 0.992839  [118400/525306]\n",
      "loss: 1.186308  [120000/525306]\n",
      "loss: 1.056869  [121600/525306]\n",
      "loss: 0.799528  [123200/525306]\n",
      "loss: 0.500622  [124800/525306]\n",
      "loss: 0.818326  [126400/525306]\n",
      "loss: 0.606517  [128000/525306]\n",
      "loss: 0.771413  [129600/525306]\n",
      "loss: 1.072837  [131200/525306]\n",
      "loss: 0.558735  [132800/525306]\n",
      "loss: 0.758851  [134400/525306]\n",
      "loss: 0.575190  [136000/525306]\n",
      "loss: 0.417922  [137600/525306]\n",
      "loss: 1.261705  [139200/525306]\n",
      "loss: 0.625246  [140800/525306]\n",
      "loss: 0.633295  [142400/525306]\n",
      "loss: 1.054182  [144000/525306]\n",
      "loss: 1.028753  [145600/525306]\n",
      "loss: 0.879234  [147200/525306]\n",
      "loss: 0.599651  [148800/525306]\n",
      "loss: 0.735951  [150400/525306]\n",
      "loss: 0.826321  [152000/525306]\n",
      "loss: 0.883750  [153600/525306]\n",
      "loss: 1.088364  [155200/525306]\n",
      "loss: 1.107799  [156800/525306]\n",
      "loss: 1.116939  [158400/525306]\n",
      "loss: 0.753600  [160000/525306]\n",
      "loss: 0.733717  [161600/525306]\n",
      "loss: 1.073406  [163200/525306]\n",
      "loss: 0.612835  [164800/525306]\n",
      "loss: 1.459571  [166400/525306]\n",
      "loss: 1.021115  [168000/525306]\n",
      "loss: 1.200382  [169600/525306]\n",
      "loss: 0.862685  [171200/525306]\n",
      "loss: 0.830948  [172800/525306]\n",
      "loss: 1.174521  [174400/525306]\n",
      "loss: 0.942830  [176000/525306]\n",
      "loss: 1.116567  [177600/525306]\n",
      "loss: 0.861407  [179200/525306]\n",
      "loss: 0.680599  [180800/525306]\n",
      "loss: 0.937135  [182400/525306]\n",
      "loss: 0.830035  [184000/525306]\n",
      "loss: 1.225485  [185600/525306]\n",
      "loss: 0.897726  [187200/525306]\n",
      "loss: 0.704188  [188800/525306]\n",
      "loss: 0.930030  [190400/525306]\n",
      "loss: 0.469986  [192000/525306]\n",
      "loss: 0.868405  [193600/525306]\n",
      "loss: 0.598318  [195200/525306]\n",
      "loss: 0.445041  [196800/525306]\n",
      "loss: 0.929754  [198400/525306]\n",
      "loss: 1.127296  [200000/525306]\n",
      "loss: 1.006170  [201600/525306]\n",
      "loss: 0.899754  [203200/525306]\n",
      "loss: 0.650871  [204800/525306]\n",
      "loss: 0.991459  [206400/525306]\n",
      "loss: 0.756240  [208000/525306]\n",
      "loss: 0.511942  [209600/525306]\n",
      "loss: 0.899139  [211200/525306]\n",
      "loss: 0.718903  [212800/525306]\n",
      "loss: 0.775600  [214400/525306]\n",
      "loss: 0.546153  [216000/525306]\n",
      "loss: 0.851112  [217600/525306]\n",
      "loss: 0.944387  [219200/525306]\n",
      "loss: 1.392062  [220800/525306]\n",
      "loss: 0.359086  [222400/525306]\n",
      "loss: 0.555062  [224000/525306]\n",
      "loss: 0.812844  [225600/525306]\n",
      "loss: 0.649190  [227200/525306]\n",
      "loss: 0.499382  [228800/525306]\n",
      "loss: 0.518991  [230400/525306]\n",
      "loss: 0.569839  [232000/525306]\n",
      "loss: 0.997732  [233600/525306]\n",
      "loss: 0.376458  [235200/525306]\n",
      "loss: 0.932338  [236800/525306]\n",
      "loss: 0.821399  [238400/525306]\n",
      "loss: 0.873900  [240000/525306]\n",
      "loss: 0.964624  [241600/525306]\n",
      "loss: 0.936401  [243200/525306]\n",
      "loss: 0.553691  [244800/525306]\n",
      "loss: 0.820979  [246400/525306]\n",
      "loss: 0.929677  [248000/525306]\n",
      "loss: 0.880755  [249600/525306]\n",
      "loss: 0.674999  [251200/525306]\n",
      "loss: 0.841199  [252800/525306]\n",
      "loss: 0.763078  [254400/525306]\n",
      "loss: 0.448827  [256000/525306]\n",
      "loss: 0.795673  [257600/525306]\n",
      "loss: 0.972934  [259200/525306]\n",
      "loss: 0.864852  [260800/525306]\n",
      "loss: 0.677923  [262400/525306]\n",
      "loss: 0.767233  [264000/525306]\n",
      "loss: 0.936004  [265600/525306]\n",
      "loss: 0.627285  [267200/525306]\n",
      "loss: 0.348203  [268800/525306]\n",
      "loss: 1.106484  [270400/525306]\n",
      "loss: 0.634556  [272000/525306]\n",
      "loss: 0.905806  [273600/525306]\n",
      "loss: 0.993077  [275200/525306]\n",
      "loss: 0.370427  [276800/525306]\n",
      "loss: 1.198353  [278400/525306]\n",
      "loss: 1.172884  [280000/525306]\n",
      "loss: 0.467894  [281600/525306]\n",
      "loss: 0.648033  [283200/525306]\n",
      "loss: 0.920693  [284800/525306]\n",
      "loss: 0.442105  [286400/525306]\n",
      "loss: 1.785825  [288000/525306]\n",
      "loss: 0.891616  [289600/525306]\n",
      "loss: 0.628842  [291200/525306]\n",
      "loss: 0.840113  [292800/525306]\n",
      "loss: 0.543143  [294400/525306]\n",
      "loss: 0.731120  [296000/525306]\n",
      "loss: 0.905243  [297600/525306]\n",
      "loss: 1.347815  [299200/525306]\n",
      "loss: 1.015185  [300800/525306]\n",
      "loss: 1.205470  [302400/525306]\n",
      "loss: 0.916843  [304000/525306]\n",
      "loss: 0.932046  [305600/525306]\n",
      "loss: 1.129014  [307200/525306]\n",
      "loss: 0.797202  [308800/525306]\n",
      "loss: 1.105332  [310400/525306]\n",
      "loss: 0.843446  [312000/525306]\n",
      "loss: 0.653294  [313600/525306]\n",
      "loss: 0.636332  [315200/525306]\n",
      "loss: 1.152504  [316800/525306]\n",
      "loss: 0.432854  [318400/525306]\n",
      "loss: 1.121257  [320000/525306]\n",
      "loss: 1.062977  [321600/525306]\n",
      "loss: 0.707826  [323200/525306]\n",
      "loss: 0.774536  [324800/525306]\n",
      "loss: 0.958757  [326400/525306]\n",
      "loss: 0.517380  [328000/525306]\n",
      "loss: 0.912686  [329600/525306]\n",
      "loss: 0.884215  [331200/525306]\n",
      "loss: 0.622402  [332800/525306]\n",
      "loss: 0.527678  [334400/525306]\n",
      "loss: 0.218357  [336000/525306]\n",
      "loss: 0.908127  [337600/525306]\n",
      "loss: 0.966830  [339200/525306]\n",
      "loss: 0.717594  [340800/525306]\n",
      "loss: 0.578398  [342400/525306]\n",
      "loss: 0.874179  [344000/525306]\n",
      "loss: 1.607045  [345600/525306]\n",
      "loss: 0.808880  [347200/525306]\n",
      "loss: 0.645899  [348800/525306]\n",
      "loss: 0.993192  [350400/525306]\n",
      "loss: 0.890110  [352000/525306]\n",
      "loss: 0.780319  [353600/525306]\n",
      "loss: 0.640065  [355200/525306]\n",
      "loss: 0.765523  [356800/525306]\n",
      "loss: 0.656271  [358400/525306]\n",
      "loss: 1.227880  [360000/525306]\n",
      "loss: 0.761256  [361600/525306]\n",
      "loss: 0.645242  [363200/525306]\n",
      "loss: 0.580712  [364800/525306]\n",
      "loss: 0.831740  [366400/525306]\n",
      "loss: 0.415102  [368000/525306]\n",
      "loss: 1.130289  [369600/525306]\n",
      "loss: 1.081310  [371200/525306]\n",
      "loss: 0.850351  [372800/525306]\n",
      "loss: 1.089517  [374400/525306]\n",
      "loss: 1.029022  [376000/525306]\n",
      "loss: 0.455106  [377600/525306]\n",
      "loss: 0.576965  [379200/525306]\n",
      "loss: 0.564115  [380800/525306]\n",
      "loss: 1.316643  [382400/525306]\n",
      "loss: 1.045656  [384000/525306]\n",
      "loss: 0.867630  [385600/525306]\n",
      "loss: 0.857495  [387200/525306]\n",
      "loss: 0.833359  [388800/525306]\n",
      "loss: 0.666661  [390400/525306]\n",
      "loss: 1.246162  [392000/525306]\n",
      "loss: 0.899973  [393600/525306]\n",
      "loss: 0.552580  [395200/525306]\n",
      "loss: 0.632908  [396800/525306]\n",
      "loss: 0.967375  [398400/525306]\n",
      "loss: 0.481502  [400000/525306]\n",
      "loss: 1.087942  [401600/525306]\n",
      "loss: 1.010635  [403200/525306]\n",
      "loss: 0.544807  [404800/525306]\n",
      "loss: 0.705886  [406400/525306]\n",
      "loss: 1.097959  [408000/525306]\n",
      "loss: 0.753225  [409600/525306]\n",
      "loss: 0.962363  [411200/525306]\n",
      "loss: 1.018039  [412800/525306]\n",
      "loss: 0.829787  [414400/525306]\n",
      "loss: 1.150356  [416000/525306]\n",
      "loss: 0.675453  [417600/525306]\n",
      "loss: 0.492063  [419200/525306]\n",
      "loss: 0.794516  [420800/525306]\n",
      "loss: 0.991318  [422400/525306]\n",
      "loss: 0.670665  [424000/525306]\n",
      "loss: 0.776309  [425600/525306]\n",
      "loss: 0.627242  [427200/525306]\n",
      "loss: 0.426585  [428800/525306]\n",
      "loss: 0.969320  [430400/525306]\n",
      "loss: 1.123648  [432000/525306]\n",
      "loss: 0.963287  [433600/525306]\n",
      "loss: 0.816089  [435200/525306]\n",
      "loss: 0.916489  [436800/525306]\n",
      "loss: 0.712795  [438400/525306]\n",
      "loss: 0.866445  [440000/525306]\n",
      "loss: 1.060838  [441600/525306]\n",
      "loss: 0.873691  [443200/525306]\n",
      "loss: 0.273108  [444800/525306]\n",
      "loss: 0.596974  [446400/525306]\n",
      "loss: 0.495933  [448000/525306]\n",
      "loss: 1.005353  [449600/525306]\n",
      "loss: 1.098144  [451200/525306]\n",
      "loss: 0.830156  [452800/525306]\n",
      "loss: 0.531372  [454400/525306]\n",
      "loss: 0.908320  [456000/525306]\n",
      "loss: 0.674267  [457600/525306]\n",
      "loss: 1.326254  [459200/525306]\n",
      "loss: 0.702479  [460800/525306]\n",
      "loss: 1.114659  [462400/525306]\n",
      "loss: 0.824873  [464000/525306]\n",
      "loss: 0.803637  [465600/525306]\n",
      "loss: 0.579028  [467200/525306]\n",
      "loss: 0.903283  [468800/525306]\n",
      "loss: 0.761243  [470400/525306]\n",
      "loss: 0.883255  [472000/525306]\n",
      "loss: 0.483026  [473600/525306]\n",
      "loss: 0.664779  [475200/525306]\n",
      "loss: 0.908106  [476800/525306]\n",
      "loss: 1.039087  [478400/525306]\n",
      "loss: 1.350896  [480000/525306]\n",
      "loss: 1.190596  [481600/525306]\n",
      "loss: 0.601650  [483200/525306]\n",
      "loss: 0.996751  [484800/525306]\n",
      "loss: 1.373685  [486400/525306]\n",
      "loss: 1.074521  [488000/525306]\n",
      "loss: 0.708736  [489600/525306]\n",
      "loss: 0.810035  [491200/525306]\n",
      "loss: 0.678963  [492800/525306]\n",
      "loss: 0.921147  [494400/525306]\n",
      "loss: 0.816316  [496000/525306]\n",
      "loss: 1.126335  [497600/525306]\n",
      "loss: 0.844703  [499200/525306]\n",
      "loss: 0.936581  [500800/525306]\n",
      "loss: 0.485934  [502400/525306]\n",
      "loss: 0.884954  [504000/525306]\n",
      "loss: 0.723811  [505600/525306]\n",
      "loss: 0.626194  [507200/525306]\n",
      "loss: 0.652494  [508800/525306]\n",
      "loss: 0.929260  [510400/525306]\n",
      "loss: 0.840996  [512000/525306]\n",
      "loss: 1.328440  [513600/525306]\n",
      "loss: 0.673167  [515200/525306]\n",
      "loss: 0.940734  [516800/525306]\n",
      "loss: 0.725963  [518400/525306]\n",
      "loss: 0.602947  [520000/525306]\n",
      "loss: 0.860186  [521600/525306]\n",
      "loss: 0.497160  [523200/525306]\n",
      "loss: 0.461406  [524800/525306]\n",
      "Train Accuracy: 69.1565%\n",
      "Test Error: \n",
      " Accuracy: 62.4%, Avg loss: 0.929871, F1-score: 68.68%, Macro_F1-Score:  38.89%  \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.398165  [    0/525306]\n",
      "loss: 0.747028  [ 1600/525306]\n",
      "loss: 1.055016  [ 3200/525306]\n",
      "loss: 0.783209  [ 4800/525306]\n",
      "loss: 0.995729  [ 6400/525306]\n",
      "loss: 0.676468  [ 8000/525306]\n",
      "loss: 0.724220  [ 9600/525306]\n",
      "loss: 0.779336  [11200/525306]\n",
      "loss: 0.522315  [12800/525306]\n",
      "loss: 1.131364  [14400/525306]\n",
      "loss: 0.546862  [16000/525306]\n",
      "loss: 1.255072  [17600/525306]\n",
      "loss: 0.835935  [19200/525306]\n",
      "loss: 0.899096  [20800/525306]\n",
      "loss: 0.772774  [22400/525306]\n",
      "loss: 0.581116  [24000/525306]\n",
      "loss: 1.017596  [25600/525306]\n",
      "loss: 0.798629  [27200/525306]\n",
      "loss: 0.792743  [28800/525306]\n",
      "loss: 0.776131  [30400/525306]\n",
      "loss: 1.402569  [32000/525306]\n",
      "loss: 0.857058  [33600/525306]\n",
      "loss: 0.426693  [35200/525306]\n",
      "loss: 0.374809  [36800/525306]\n",
      "loss: 0.975598  [38400/525306]\n",
      "loss: 1.129899  [40000/525306]\n",
      "loss: 0.470424  [41600/525306]\n",
      "loss: 1.074777  [43200/525306]\n",
      "loss: 1.160413  [44800/525306]\n",
      "loss: 0.477609  [46400/525306]\n",
      "loss: 0.901936  [48000/525306]\n",
      "loss: 0.772619  [49600/525306]\n",
      "loss: 0.627421  [51200/525306]\n",
      "loss: 0.903221  [52800/525306]\n",
      "loss: 0.467849  [54400/525306]\n",
      "loss: 0.900579  [56000/525306]\n",
      "loss: 0.952130  [57600/525306]\n",
      "loss: 0.251337  [59200/525306]\n",
      "loss: 1.074722  [60800/525306]\n",
      "loss: 1.260136  [62400/525306]\n",
      "loss: 0.727506  [64000/525306]\n",
      "loss: 1.000761  [65600/525306]\n",
      "loss: 0.743381  [67200/525306]\n",
      "loss: 0.797145  [68800/525306]\n",
      "loss: 1.201890  [70400/525306]\n",
      "loss: 0.781908  [72000/525306]\n",
      "loss: 0.818225  [73600/525306]\n",
      "loss: 1.207102  [75200/525306]\n",
      "loss: 0.598650  [76800/525306]\n",
      "loss: 1.243630  [78400/525306]\n",
      "loss: 0.843152  [80000/525306]\n",
      "loss: 0.685559  [81600/525306]\n",
      "loss: 1.338281  [83200/525306]\n",
      "loss: 0.456924  [84800/525306]\n",
      "loss: 0.586565  [86400/525306]\n",
      "loss: 0.443609  [88000/525306]\n",
      "loss: 0.771640  [89600/525306]\n",
      "loss: 1.137244  [91200/525306]\n",
      "loss: 0.868478  [92800/525306]\n",
      "loss: 1.225683  [94400/525306]\n",
      "loss: 0.697321  [96000/525306]\n",
      "loss: 0.793728  [97600/525306]\n",
      "loss: 0.745053  [99200/525306]\n",
      "loss: 0.817973  [100800/525306]\n",
      "loss: 0.383929  [102400/525306]\n",
      "loss: 0.533400  [104000/525306]\n",
      "loss: 0.763759  [105600/525306]\n",
      "loss: 0.626662  [107200/525306]\n",
      "loss: 1.013889  [108800/525306]\n",
      "loss: 0.469600  [110400/525306]\n",
      "loss: 0.878432  [112000/525306]\n",
      "loss: 0.585768  [113600/525306]\n",
      "loss: 1.121763  [115200/525306]\n",
      "loss: 0.968938  [116800/525306]\n",
      "loss: 0.427527  [118400/525306]\n",
      "loss: 0.703122  [120000/525306]\n",
      "loss: 1.436286  [121600/525306]\n",
      "loss: 0.701783  [123200/525306]\n",
      "loss: 0.509146  [124800/525306]\n",
      "loss: 1.065825  [126400/525306]\n",
      "loss: 0.912815  [128000/525306]\n",
      "loss: 0.778360  [129600/525306]\n",
      "loss: 0.618464  [131200/525306]\n",
      "loss: 0.779291  [132800/525306]\n",
      "loss: 1.197403  [134400/525306]\n",
      "loss: 0.925166  [136000/525306]\n",
      "loss: 0.716339  [137600/525306]\n",
      "loss: 0.366058  [139200/525306]\n",
      "loss: 0.683908  [140800/525306]\n",
      "loss: 1.092828  [142400/525306]\n",
      "loss: 1.044969  [144000/525306]\n",
      "loss: 0.413368  [145600/525306]\n",
      "loss: 0.878129  [147200/525306]\n",
      "loss: 0.621763  [148800/525306]\n",
      "loss: 0.874931  [150400/525306]\n",
      "loss: 0.744122  [152000/525306]\n",
      "loss: 0.587137  [153600/525306]\n",
      "loss: 0.494129  [155200/525306]\n",
      "loss: 0.403038  [156800/525306]\n",
      "loss: 0.808955  [158400/525306]\n",
      "loss: 0.687024  [160000/525306]\n",
      "loss: 0.758651  [161600/525306]\n",
      "loss: 1.064163  [163200/525306]\n",
      "loss: 0.564744  [164800/525306]\n",
      "loss: 0.808756  [166400/525306]\n",
      "loss: 1.194229  [168000/525306]\n",
      "loss: 1.339340  [169600/525306]\n",
      "loss: 0.685870  [171200/525306]\n",
      "loss: 0.761454  [172800/525306]\n",
      "loss: 1.290824  [174400/525306]\n",
      "loss: 0.882309  [176000/525306]\n",
      "loss: 0.646603  [177600/525306]\n",
      "loss: 1.024736  [179200/525306]\n",
      "loss: 0.667279  [180800/525306]\n",
      "loss: 0.801873  [182400/525306]\n",
      "loss: 0.843072  [184000/525306]\n",
      "loss: 0.848982  [185600/525306]\n",
      "loss: 0.607580  [187200/525306]\n",
      "loss: 0.733770  [188800/525306]\n",
      "loss: 0.974471  [190400/525306]\n",
      "loss: 0.831851  [192000/525306]\n",
      "loss: 0.671838  [193600/525306]\n",
      "loss: 0.757388  [195200/525306]\n",
      "loss: 1.055064  [196800/525306]\n",
      "loss: 0.485979  [198400/525306]\n",
      "loss: 0.443289  [200000/525306]\n",
      "loss: 0.541142  [201600/525306]\n",
      "loss: 0.882071  [203200/525306]\n",
      "loss: 0.590896  [204800/525306]\n",
      "loss: 1.368532  [206400/525306]\n",
      "loss: 0.919591  [208000/525306]\n",
      "loss: 0.644811  [209600/525306]\n",
      "loss: 0.925930  [211200/525306]\n",
      "loss: 1.228875  [212800/525306]\n",
      "loss: 1.176637  [214400/525306]\n",
      "loss: 0.769570  [216000/525306]\n",
      "loss: 0.633042  [217600/525306]\n",
      "loss: 1.144457  [219200/525306]\n",
      "loss: 0.641457  [220800/525306]\n",
      "loss: 0.547858  [222400/525306]\n",
      "loss: 0.875282  [224000/525306]\n",
      "loss: 0.846965  [225600/525306]\n",
      "loss: 0.942398  [227200/525306]\n",
      "loss: 0.623264  [228800/525306]\n",
      "loss: 1.232539  [230400/525306]\n",
      "loss: 0.828867  [232000/525306]\n",
      "loss: 0.449765  [233600/525306]\n",
      "loss: 1.193354  [235200/525306]\n",
      "loss: 0.619914  [236800/525306]\n",
      "loss: 0.620812  [238400/525306]\n",
      "loss: 0.643870  [240000/525306]\n",
      "loss: 0.798262  [241600/525306]\n",
      "loss: 0.418833  [243200/525306]\n",
      "loss: 0.832140  [244800/525306]\n",
      "loss: 0.568363  [246400/525306]\n",
      "loss: 0.947463  [248000/525306]\n",
      "loss: 0.905084  [249600/525306]\n",
      "loss: 0.956937  [251200/525306]\n",
      "loss: 0.659916  [252800/525306]\n",
      "loss: 0.402192  [254400/525306]\n",
      "loss: 0.520786  [256000/525306]\n",
      "loss: 0.538812  [257600/525306]\n",
      "loss: 0.880213  [259200/525306]\n",
      "loss: 0.865225  [260800/525306]\n",
      "loss: 0.661438  [262400/525306]\n",
      "loss: 0.612532  [264000/525306]\n",
      "loss: 0.566976  [265600/525306]\n",
      "loss: 0.636574  [267200/525306]\n",
      "loss: 0.689885  [268800/525306]\n",
      "loss: 0.667551  [270400/525306]\n",
      "loss: 1.321170  [272000/525306]\n",
      "loss: 0.431950  [273600/525306]\n",
      "loss: 0.889614  [275200/525306]\n",
      "loss: 1.148349  [276800/525306]\n",
      "loss: 0.479657  [278400/525306]\n",
      "loss: 0.796075  [280000/525306]\n",
      "loss: 0.646703  [281600/525306]\n",
      "loss: 0.806723  [283200/525306]\n",
      "loss: 0.898654  [284800/525306]\n",
      "loss: 1.002593  [286400/525306]\n",
      "loss: 0.921401  [288000/525306]\n",
      "loss: 0.828513  [289600/525306]\n",
      "loss: 1.052576  [291200/525306]\n",
      "loss: 0.900295  [292800/525306]\n",
      "loss: 0.862296  [294400/525306]\n",
      "loss: 0.584927  [296000/525306]\n",
      "loss: 1.264345  [297600/525306]\n",
      "loss: 1.109871  [299200/525306]\n",
      "loss: 1.091383  [300800/525306]\n",
      "loss: 0.908321  [302400/525306]\n",
      "loss: 0.555826  [304000/525306]\n",
      "loss: 0.796918  [305600/525306]\n",
      "loss: 1.090126  [307200/525306]\n",
      "loss: 0.433864  [308800/525306]\n",
      "loss: 0.821796  [310400/525306]\n",
      "loss: 0.854048  [312000/525306]\n",
      "loss: 0.707833  [313600/525306]\n",
      "loss: 1.224251  [315200/525306]\n",
      "loss: 0.981252  [316800/525306]\n",
      "loss: 1.159440  [318400/525306]\n",
      "loss: 0.554540  [320000/525306]\n",
      "loss: 0.934701  [321600/525306]\n",
      "loss: 0.767476  [323200/525306]\n",
      "loss: 1.350678  [324800/525306]\n",
      "loss: 1.177066  [326400/525306]\n",
      "loss: 0.503056  [328000/525306]\n",
      "loss: 0.747605  [329600/525306]\n",
      "loss: 1.206397  [331200/525306]\n",
      "loss: 0.600711  [332800/525306]\n",
      "loss: 0.981600  [334400/525306]\n",
      "loss: 0.395901  [336000/525306]\n",
      "loss: 0.782933  [337600/525306]\n",
      "loss: 0.515359  [339200/525306]\n",
      "loss: 0.789089  [340800/525306]\n",
      "loss: 1.095359  [342400/525306]\n",
      "loss: 0.988973  [344000/525306]\n",
      "loss: 0.660392  [345600/525306]\n",
      "loss: 0.692739  [347200/525306]\n",
      "loss: 0.374250  [348800/525306]\n",
      "loss: 1.177049  [350400/525306]\n",
      "loss: 1.060485  [352000/525306]\n",
      "loss: 1.317365  [353600/525306]\n",
      "loss: 0.807765  [355200/525306]\n",
      "loss: 0.857665  [356800/525306]\n",
      "loss: 0.839666  [358400/525306]\n",
      "loss: 0.687476  [360000/525306]\n",
      "loss: 0.891076  [361600/525306]\n",
      "loss: 0.621116  [363200/525306]\n",
      "loss: 0.841799  [364800/525306]\n",
      "loss: 1.231090  [366400/525306]\n",
      "loss: 0.600839  [368000/525306]\n",
      "loss: 0.982756  [369600/525306]\n",
      "loss: 0.800074  [371200/525306]\n",
      "loss: 0.434635  [372800/525306]\n",
      "loss: 0.772081  [374400/525306]\n",
      "loss: 0.930507  [376000/525306]\n",
      "loss: 0.497488  [377600/525306]\n",
      "loss: 0.789494  [379200/525306]\n",
      "loss: 0.650197  [380800/525306]\n",
      "loss: 1.059277  [382400/525306]\n",
      "loss: 0.971115  [384000/525306]\n",
      "loss: 0.653771  [385600/525306]\n",
      "loss: 1.202888  [387200/525306]\n",
      "loss: 0.933833  [388800/525306]\n",
      "loss: 0.675121  [390400/525306]\n",
      "loss: 0.991240  [392000/525306]\n",
      "loss: 0.687116  [393600/525306]\n",
      "loss: 0.955800  [395200/525306]\n",
      "loss: 0.820572  [396800/525306]\n",
      "loss: 0.732414  [398400/525306]\n",
      "loss: 0.979354  [400000/525306]\n",
      "loss: 0.896192  [401600/525306]\n",
      "loss: 1.401449  [403200/525306]\n",
      "loss: 0.858115  [404800/525306]\n",
      "loss: 1.149149  [406400/525306]\n",
      "loss: 1.071745  [408000/525306]\n",
      "loss: 0.983089  [409600/525306]\n",
      "loss: 0.626665  [411200/525306]\n",
      "loss: 0.938753  [412800/525306]\n",
      "loss: 1.145289  [414400/525306]\n",
      "loss: 0.855590  [416000/525306]\n",
      "loss: 0.434959  [417600/525306]\n",
      "loss: 0.616347  [419200/525306]\n",
      "loss: 1.066998  [420800/525306]\n",
      "loss: 0.770340  [422400/525306]\n",
      "loss: 1.036375  [424000/525306]\n",
      "loss: 0.818292  [425600/525306]\n",
      "loss: 1.264730  [427200/525306]\n",
      "loss: 0.349692  [428800/525306]\n",
      "loss: 0.524441  [430400/525306]\n",
      "loss: 0.802353  [432000/525306]\n",
      "loss: 0.401632  [433600/525306]\n",
      "loss: 0.821081  [435200/525306]\n",
      "loss: 0.431172  [436800/525306]\n",
      "loss: 0.597547  [438400/525306]\n",
      "loss: 1.093682  [440000/525306]\n",
      "loss: 1.008215  [441600/525306]\n",
      "loss: 0.782094  [443200/525306]\n",
      "loss: 0.805013  [444800/525306]\n",
      "loss: 1.292488  [446400/525306]\n",
      "loss: 0.539331  [448000/525306]\n",
      "loss: 0.644013  [449600/525306]\n",
      "loss: 1.129238  [451200/525306]\n",
      "loss: 0.627298  [452800/525306]\n",
      "loss: 0.613824  [454400/525306]\n",
      "loss: 0.971207  [456000/525306]\n",
      "loss: 0.782705  [457600/525306]\n",
      "loss: 1.182975  [459200/525306]\n",
      "loss: 1.018633  [460800/525306]\n",
      "loss: 0.680179  [462400/525306]\n",
      "loss: 0.602429  [464000/525306]\n",
      "loss: 0.752745  [465600/525306]\n",
      "loss: 0.846764  [467200/525306]\n",
      "loss: 0.795478  [468800/525306]\n",
      "loss: 1.435465  [470400/525306]\n",
      "loss: 0.639365  [472000/525306]\n",
      "loss: 0.498533  [473600/525306]\n",
      "loss: 0.628514  [475200/525306]\n",
      "loss: 0.551076  [476800/525306]\n",
      "loss: 0.773860  [478400/525306]\n",
      "loss: 0.388281  [480000/525306]\n",
      "loss: 0.824458  [481600/525306]\n",
      "loss: 0.785310  [483200/525306]\n",
      "loss: 0.646906  [484800/525306]\n",
      "loss: 0.715598  [486400/525306]\n",
      "loss: 0.882229  [488000/525306]\n",
      "loss: 1.174710  [489600/525306]\n",
      "loss: 0.772123  [491200/525306]\n",
      "loss: 0.629877  [492800/525306]\n",
      "loss: 0.868686  [494400/525306]\n",
      "loss: 0.742085  [496000/525306]\n",
      "loss: 0.614435  [497600/525306]\n",
      "loss: 0.868092  [499200/525306]\n",
      "loss: 0.686409  [500800/525306]\n",
      "loss: 0.599512  [502400/525306]\n",
      "loss: 1.343693  [504000/525306]\n",
      "loss: 0.797646  [505600/525306]\n",
      "loss: 0.649194  [507200/525306]\n",
      "loss: 0.750005  [508800/525306]\n",
      "loss: 0.440277  [510400/525306]\n",
      "loss: 0.744945  [512000/525306]\n",
      "loss: 0.970457  [513600/525306]\n",
      "loss: 0.572106  [515200/525306]\n",
      "loss: 0.732030  [516800/525306]\n",
      "loss: 0.865619  [518400/525306]\n",
      "loss: 0.779564  [520000/525306]\n",
      "loss: 0.721217  [521600/525306]\n",
      "loss: 0.433182  [523200/525306]\n",
      "loss: 0.743721  [524800/525306]\n",
      "Train Accuracy: 69.4822%\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 0.942757, F1-score: 68.84%, Macro_F1-Score:  39.47%  \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.512832  [    0/525306]\n",
      "loss: 1.515359  [ 1600/525306]\n",
      "loss: 0.880242  [ 3200/525306]\n",
      "loss: 0.850021  [ 4800/525306]\n",
      "loss: 0.800494  [ 6400/525306]\n",
      "loss: 0.628372  [ 8000/525306]\n",
      "loss: 0.818103  [ 9600/525306]\n",
      "loss: 0.725772  [11200/525306]\n",
      "loss: 0.351302  [12800/525306]\n",
      "loss: 0.609168  [14400/525306]\n",
      "loss: 0.512167  [16000/525306]\n",
      "loss: 0.849138  [17600/525306]\n",
      "loss: 1.203045  [19200/525306]\n",
      "loss: 0.918319  [20800/525306]\n",
      "loss: 0.547666  [22400/525306]\n",
      "loss: 0.733219  [24000/525306]\n",
      "loss: 0.964890  [25600/525306]\n",
      "loss: 0.946108  [27200/525306]\n",
      "loss: 1.592360  [28800/525306]\n",
      "loss: 0.928358  [30400/525306]\n",
      "loss: 0.810557  [32000/525306]\n",
      "loss: 0.943573  [33600/525306]\n",
      "loss: 0.493531  [35200/525306]\n",
      "loss: 1.701011  [36800/525306]\n",
      "loss: 0.981568  [38400/525306]\n",
      "loss: 0.655777  [40000/525306]\n",
      "loss: 0.938204  [41600/525306]\n",
      "loss: 0.487781  [43200/525306]\n",
      "loss: 0.695260  [44800/525306]\n",
      "loss: 0.593225  [46400/525306]\n",
      "loss: 0.868303  [48000/525306]\n",
      "loss: 0.981811  [49600/525306]\n",
      "loss: 0.852593  [51200/525306]\n",
      "loss: 0.526130  [52800/525306]\n",
      "loss: 1.063471  [54400/525306]\n",
      "loss: 1.378048  [56000/525306]\n",
      "loss: 0.675012  [57600/525306]\n",
      "loss: 0.741979  [59200/525306]\n",
      "loss: 0.873704  [60800/525306]\n",
      "loss: 0.941828  [62400/525306]\n",
      "loss: 0.933322  [64000/525306]\n",
      "loss: 1.044343  [65600/525306]\n",
      "loss: 0.816525  [67200/525306]\n",
      "loss: 0.799434  [68800/525306]\n",
      "loss: 0.782391  [70400/525306]\n",
      "loss: 0.599669  [72000/525306]\n",
      "loss: 0.744219  [73600/525306]\n",
      "loss: 1.344185  [75200/525306]\n",
      "loss: 0.821225  [76800/525306]\n",
      "loss: 0.740212  [78400/525306]\n",
      "loss: 1.111019  [80000/525306]\n",
      "loss: 1.097333  [81600/525306]\n",
      "loss: 1.057631  [83200/525306]\n",
      "loss: 1.098284  [84800/525306]\n",
      "loss: 0.731635  [86400/525306]\n",
      "loss: 1.182869  [88000/525306]\n",
      "loss: 1.518340  [89600/525306]\n",
      "loss: 0.974378  [91200/525306]\n",
      "loss: 0.750333  [92800/525306]\n",
      "loss: 0.520371  [94400/525306]\n",
      "loss: 1.064364  [96000/525306]\n",
      "loss: 0.700217  [97600/525306]\n",
      "loss: 0.565797  [99200/525306]\n",
      "loss: 1.106520  [100800/525306]\n",
      "loss: 0.740585  [102400/525306]\n",
      "loss: 0.878956  [104000/525306]\n",
      "loss: 0.410612  [105600/525306]\n",
      "loss: 0.888401  [107200/525306]\n",
      "loss: 1.235988  [108800/525306]\n",
      "loss: 0.913372  [110400/525306]\n",
      "loss: 0.897514  [112000/525306]\n",
      "loss: 0.850318  [113600/525306]\n",
      "loss: 0.479125  [115200/525306]\n",
      "loss: 0.518866  [116800/525306]\n",
      "loss: 0.818081  [118400/525306]\n",
      "loss: 0.563420  [120000/525306]\n",
      "loss: 0.820723  [121600/525306]\n",
      "loss: 0.921544  [123200/525306]\n",
      "loss: 0.718971  [124800/525306]\n",
      "loss: 0.671774  [126400/525306]\n",
      "loss: 0.772262  [128000/525306]\n",
      "loss: 1.050409  [129600/525306]\n",
      "loss: 1.199057  [131200/525306]\n",
      "loss: 1.153480  [132800/525306]\n",
      "loss: 0.762028  [134400/525306]\n",
      "loss: 0.641145  [136000/525306]\n",
      "loss: 0.702173  [137600/525306]\n",
      "loss: 0.850193  [139200/525306]\n",
      "loss: 0.723452  [140800/525306]\n",
      "loss: 0.675830  [142400/525306]\n",
      "loss: 0.828922  [144000/525306]\n",
      "loss: 0.731260  [145600/525306]\n",
      "loss: 0.240107  [147200/525306]\n",
      "loss: 0.906427  [148800/525306]\n",
      "loss: 0.897610  [150400/525306]\n",
      "loss: 0.841045  [152000/525306]\n",
      "loss: 0.406556  [153600/525306]\n",
      "loss: 1.176440  [155200/525306]\n",
      "loss: 0.814742  [156800/525306]\n",
      "loss: 0.862591  [158400/525306]\n",
      "loss: 1.312835  [160000/525306]\n",
      "loss: 0.915456  [161600/525306]\n",
      "loss: 0.842485  [163200/525306]\n",
      "loss: 0.762905  [164800/525306]\n",
      "loss: 0.638176  [166400/525306]\n",
      "loss: 1.336195  [168000/525306]\n",
      "loss: 0.931260  [169600/525306]\n",
      "loss: 0.338008  [171200/525306]\n",
      "loss: 0.476220  [172800/525306]\n",
      "loss: 0.759683  [174400/525306]\n",
      "loss: 0.847912  [176000/525306]\n",
      "loss: 0.967744  [177600/525306]\n",
      "loss: 0.595832  [179200/525306]\n",
      "loss: 0.579192  [180800/525306]\n",
      "loss: 0.673534  [182400/525306]\n",
      "loss: 0.901561  [184000/525306]\n",
      "loss: 0.696977  [185600/525306]\n",
      "loss: 0.682470  [187200/525306]\n",
      "loss: 0.617937  [188800/525306]\n",
      "loss: 1.013624  [190400/525306]\n",
      "loss: 0.862158  [192000/525306]\n",
      "loss: 0.662788  [193600/525306]\n",
      "loss: 0.451212  [195200/525306]\n",
      "loss: 0.788327  [196800/525306]\n",
      "loss: 1.349423  [198400/525306]\n",
      "loss: 0.825642  [200000/525306]\n",
      "loss: 0.894470  [201600/525306]\n",
      "loss: 0.440744  [203200/525306]\n",
      "loss: 1.040188  [204800/525306]\n",
      "loss: 0.839432  [206400/525306]\n",
      "loss: 0.734884  [208000/525306]\n",
      "loss: 0.781444  [209600/525306]\n",
      "loss: 1.067678  [211200/525306]\n",
      "loss: 0.686179  [212800/525306]\n",
      "loss: 1.229710  [214400/525306]\n",
      "loss: 0.745655  [216000/525306]\n",
      "loss: 1.044963  [217600/525306]\n",
      "loss: 0.428800  [219200/525306]\n",
      "loss: 1.107063  [220800/525306]\n",
      "loss: 0.987181  [222400/525306]\n",
      "loss: 0.653743  [224000/525306]\n",
      "loss: 0.835417  [225600/525306]\n",
      "loss: 0.968285  [227200/525306]\n",
      "loss: 0.643028  [228800/525306]\n",
      "loss: 0.682357  [230400/525306]\n",
      "loss: 0.547612  [232000/525306]\n",
      "loss: 1.038965  [233600/525306]\n",
      "loss: 0.644832  [235200/525306]\n",
      "loss: 0.540125  [236800/525306]\n",
      "loss: 1.053016  [238400/525306]\n",
      "loss: 0.753209  [240000/525306]\n",
      "loss: 0.646232  [241600/525306]\n",
      "loss: 1.054897  [243200/525306]\n",
      "loss: 0.365116  [244800/525306]\n",
      "loss: 0.794330  [246400/525306]\n",
      "loss: 0.404136  [248000/525306]\n",
      "loss: 0.906899  [249600/525306]\n",
      "loss: 0.790901  [251200/525306]\n",
      "loss: 0.591017  [252800/525306]\n",
      "loss: 0.777383  [254400/525306]\n",
      "loss: 0.839164  [256000/525306]\n",
      "loss: 0.834077  [257600/525306]\n",
      "loss: 0.941915  [259200/525306]\n",
      "loss: 0.447226  [260800/525306]\n",
      "loss: 1.242247  [262400/525306]\n",
      "loss: 0.742515  [264000/525306]\n",
      "loss: 0.705332  [265600/525306]\n",
      "loss: 0.518604  [267200/525306]\n",
      "loss: 1.060974  [268800/525306]\n",
      "loss: 0.438203  [270400/525306]\n",
      "loss: 0.492891  [272000/525306]\n",
      "loss: 0.487686  [273600/525306]\n",
      "loss: 0.530180  [275200/525306]\n",
      "loss: 0.486957  [276800/525306]\n",
      "loss: 0.696216  [278400/525306]\n",
      "loss: 1.107231  [280000/525306]\n",
      "loss: 0.601029  [281600/525306]\n",
      "loss: 1.391078  [283200/525306]\n",
      "loss: 0.909405  [284800/525306]\n",
      "loss: 0.474454  [286400/525306]\n",
      "loss: 0.686789  [288000/525306]\n",
      "loss: 0.666294  [289600/525306]\n",
      "loss: 1.070116  [291200/525306]\n",
      "loss: 0.685879  [292800/525306]\n",
      "loss: 0.812415  [294400/525306]\n",
      "loss: 0.718784  [296000/525306]\n",
      "loss: 1.338964  [297600/525306]\n",
      "loss: 0.470018  [299200/525306]\n",
      "loss: 0.613242  [300800/525306]\n",
      "loss: 1.259781  [302400/525306]\n",
      "loss: 0.784697  [304000/525306]\n",
      "loss: 0.689785  [305600/525306]\n",
      "loss: 1.053325  [307200/525306]\n",
      "loss: 0.710461  [308800/525306]\n",
      "loss: 0.823555  [310400/525306]\n",
      "loss: 0.597495  [312000/525306]\n",
      "loss: 0.546838  [313600/525306]\n",
      "loss: 1.071425  [315200/525306]\n",
      "loss: 0.955859  [316800/525306]\n",
      "loss: 0.663604  [318400/525306]\n",
      "loss: 0.999373  [320000/525306]\n",
      "loss: 0.663954  [321600/525306]\n",
      "loss: 0.778524  [323200/525306]\n",
      "loss: 0.457289  [324800/525306]\n",
      "loss: 0.627418  [326400/525306]\n",
      "loss: 0.996167  [328000/525306]\n",
      "loss: 1.265811  [329600/525306]\n",
      "loss: 0.737310  [331200/525306]\n",
      "loss: 0.733771  [332800/525306]\n",
      "loss: 0.992029  [334400/525306]\n",
      "loss: 0.582114  [336000/525306]\n",
      "loss: 0.608926  [337600/525306]\n",
      "loss: 0.493915  [339200/525306]\n",
      "loss: 1.200794  [340800/525306]\n",
      "loss: 0.735706  [342400/525306]\n",
      "loss: 0.571739  [344000/525306]\n",
      "loss: 0.735454  [345600/525306]\n",
      "loss: 1.155662  [347200/525306]\n",
      "loss: 0.572978  [348800/525306]\n",
      "loss: 0.835896  [350400/525306]\n",
      "loss: 0.794360  [352000/525306]\n",
      "loss: 1.079126  [353600/525306]\n",
      "loss: 0.724407  [355200/525306]\n",
      "loss: 0.655316  [356800/525306]\n",
      "loss: 1.031986  [358400/525306]\n",
      "loss: 1.174691  [360000/525306]\n",
      "loss: 1.213178  [361600/525306]\n",
      "loss: 0.462324  [363200/525306]\n",
      "loss: 0.746869  [364800/525306]\n",
      "loss: 1.024753  [366400/525306]\n",
      "loss: 0.947665  [368000/525306]\n",
      "loss: 0.865664  [369600/525306]\n",
      "loss: 1.189585  [371200/525306]\n",
      "loss: 1.294904  [372800/525306]\n",
      "loss: 0.674919  [374400/525306]\n",
      "loss: 0.610046  [376000/525306]\n",
      "loss: 0.851763  [377600/525306]\n",
      "loss: 0.984326  [379200/525306]\n",
      "loss: 1.141692  [380800/525306]\n",
      "loss: 0.912888  [382400/525306]\n",
      "loss: 1.041921  [384000/525306]\n",
      "loss: 0.626943  [385600/525306]\n",
      "loss: 0.974442  [387200/525306]\n",
      "loss: 0.708312  [388800/525306]\n",
      "loss: 0.959968  [390400/525306]\n",
      "loss: 0.884345  [392000/525306]\n",
      "loss: 0.857163  [393600/525306]\n",
      "loss: 1.007525  [395200/525306]\n",
      "loss: 0.919762  [396800/525306]\n",
      "loss: 0.652819  [398400/525306]\n",
      "loss: 0.854347  [400000/525306]\n",
      "loss: 0.825933  [401600/525306]\n",
      "loss: 0.421417  [403200/525306]\n",
      "loss: 1.035723  [404800/525306]\n",
      "loss: 0.556136  [406400/525306]\n",
      "loss: 0.691822  [408000/525306]\n",
      "loss: 0.668325  [409600/525306]\n",
      "loss: 1.261483  [411200/525306]\n",
      "loss: 0.415046  [412800/525306]\n",
      "loss: 1.145284  [414400/525306]\n",
      "loss: 1.288644  [416000/525306]\n",
      "loss: 0.898000  [417600/525306]\n",
      "loss: 1.185275  [419200/525306]\n",
      "loss: 0.409537  [420800/525306]\n",
      "loss: 1.053032  [422400/525306]\n",
      "loss: 0.915565  [424000/525306]\n",
      "loss: 0.718654  [425600/525306]\n",
      "loss: 0.552046  [427200/525306]\n",
      "loss: 0.739661  [428800/525306]\n",
      "loss: 0.611078  [430400/525306]\n",
      "loss: 0.992674  [432000/525306]\n",
      "loss: 0.748378  [433600/525306]\n",
      "loss: 0.741455  [435200/525306]\n",
      "loss: 0.663095  [436800/525306]\n",
      "loss: 0.648378  [438400/525306]\n",
      "loss: 0.561545  [440000/525306]\n",
      "loss: 0.684353  [441600/525306]\n",
      "loss: 0.723123  [443200/525306]\n",
      "loss: 0.560312  [444800/525306]\n",
      "loss: 0.961042  [446400/525306]\n",
      "loss: 0.931291  [448000/525306]\n",
      "loss: 0.822396  [449600/525306]\n",
      "loss: 0.791464  [451200/525306]\n",
      "loss: 0.596610  [452800/525306]\n",
      "loss: 1.413783  [454400/525306]\n",
      "loss: 0.643737  [456000/525306]\n",
      "loss: 0.895047  [457600/525306]\n",
      "loss: 0.880791  [459200/525306]\n",
      "loss: 1.584089  [460800/525306]\n",
      "loss: 0.820816  [462400/525306]\n",
      "loss: 0.730909  [464000/525306]\n",
      "loss: 0.951794  [465600/525306]\n",
      "loss: 0.826954  [467200/525306]\n",
      "loss: 0.594972  [468800/525306]\n",
      "loss: 0.797932  [470400/525306]\n",
      "loss: 0.858309  [472000/525306]\n",
      "loss: 0.731960  [473600/525306]\n",
      "loss: 0.635784  [475200/525306]\n",
      "loss: 0.850142  [476800/525306]\n",
      "loss: 0.903288  [478400/525306]\n",
      "loss: 0.720284  [480000/525306]\n",
      "loss: 0.731875  [481600/525306]\n",
      "loss: 0.837129  [483200/525306]\n",
      "loss: 0.849460  [484800/525306]\n",
      "loss: 0.913308  [486400/525306]\n",
      "loss: 1.037325  [488000/525306]\n",
      "loss: 0.902199  [489600/525306]\n",
      "loss: 0.650607  [491200/525306]\n",
      "loss: 0.554464  [492800/525306]\n",
      "loss: 0.748797  [494400/525306]\n",
      "loss: 1.616077  [496000/525306]\n",
      "loss: 0.663514  [497600/525306]\n",
      "loss: 0.650601  [499200/525306]\n",
      "loss: 0.729396  [500800/525306]\n",
      "loss: 0.840609  [502400/525306]\n",
      "loss: 1.269904  [504000/525306]\n",
      "loss: 0.846912  [505600/525306]\n",
      "loss: 1.072525  [507200/525306]\n",
      "loss: 1.221895  [508800/525306]\n",
      "loss: 0.653683  [510400/525306]\n",
      "loss: 0.628108  [512000/525306]\n",
      "loss: 0.824229  [513600/525306]\n",
      "loss: 1.007742  [515200/525306]\n",
      "loss: 0.790838  [516800/525306]\n",
      "loss: 0.637731  [518400/525306]\n",
      "loss: 0.518026  [520000/525306]\n",
      "loss: 0.533009  [521600/525306]\n",
      "loss: 0.574016  [523200/525306]\n",
      "loss: 1.030993  [524800/525306]\n",
      "Train Accuracy: 69.5791%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.980769, F1-score: 68.13%, Macro_F1-Score:  37.91%  \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.704008  [    0/525306]\n",
      "loss: 0.827602  [ 1600/525306]\n",
      "loss: 0.988010  [ 3200/525306]\n",
      "loss: 0.887145  [ 4800/525306]\n",
      "loss: 0.402750  [ 6400/525306]\n",
      "loss: 0.996269  [ 8000/525306]\n",
      "loss: 0.421003  [ 9600/525306]\n",
      "loss: 0.952972  [11200/525306]\n",
      "loss: 0.829087  [12800/525306]\n",
      "loss: 0.854413  [14400/525306]\n",
      "loss: 0.392541  [16000/525306]\n",
      "loss: 0.665774  [17600/525306]\n",
      "loss: 0.264703  [19200/525306]\n",
      "loss: 0.954758  [20800/525306]\n",
      "loss: 1.018876  [22400/525306]\n",
      "loss: 0.626153  [24000/525306]\n",
      "loss: 0.434781  [25600/525306]\n",
      "loss: 1.237885  [27200/525306]\n",
      "loss: 1.106994  [28800/525306]\n",
      "loss: 0.571874  [30400/525306]\n",
      "loss: 0.921392  [32000/525306]\n",
      "loss: 1.115485  [33600/525306]\n",
      "loss: 0.860993  [35200/525306]\n",
      "loss: 0.629285  [36800/525306]\n",
      "loss: 0.586747  [38400/525306]\n",
      "loss: 0.611276  [40000/525306]\n",
      "loss: 0.695238  [41600/525306]\n",
      "loss: 0.768278  [43200/525306]\n",
      "loss: 0.660214  [44800/525306]\n",
      "loss: 0.787742  [46400/525306]\n",
      "loss: 0.708440  [48000/525306]\n",
      "loss: 0.523726  [49600/525306]\n",
      "loss: 0.621545  [51200/525306]\n",
      "loss: 0.852250  [52800/525306]\n",
      "loss: 0.942306  [54400/525306]\n",
      "loss: 0.843864  [56000/525306]\n",
      "loss: 0.701162  [57600/525306]\n",
      "loss: 0.850280  [59200/525306]\n",
      "loss: 0.965334  [60800/525306]\n",
      "loss: 0.624023  [62400/525306]\n",
      "loss: 0.986090  [64000/525306]\n",
      "loss: 0.976990  [65600/525306]\n",
      "loss: 0.708497  [67200/525306]\n",
      "loss: 1.364425  [68800/525306]\n",
      "loss: 0.773083  [70400/525306]\n",
      "loss: 0.703467  [72000/525306]\n",
      "loss: 0.977458  [73600/525306]\n",
      "loss: 0.964037  [75200/525306]\n",
      "loss: 0.436878  [76800/525306]\n",
      "loss: 0.666364  [78400/525306]\n",
      "loss: 0.804656  [80000/525306]\n",
      "loss: 0.504563  [81600/525306]\n",
      "loss: 0.954564  [83200/525306]\n",
      "loss: 0.594656  [84800/525306]\n",
      "loss: 0.284587  [86400/525306]\n",
      "loss: 0.614985  [88000/525306]\n",
      "loss: 0.608298  [89600/525306]\n",
      "loss: 0.579800  [91200/525306]\n",
      "loss: 1.116651  [92800/525306]\n",
      "loss: 0.698327  [94400/525306]\n",
      "loss: 0.934133  [96000/525306]\n",
      "loss: 0.938147  [97600/525306]\n",
      "loss: 0.542581  [99200/525306]\n",
      "loss: 0.838726  [100800/525306]\n",
      "loss: 0.946743  [102400/525306]\n",
      "loss: 1.055822  [104000/525306]\n",
      "loss: 0.533476  [105600/525306]\n",
      "loss: 0.618366  [107200/525306]\n",
      "loss: 0.821409  [108800/525306]\n",
      "loss: 0.798635  [110400/525306]\n",
      "loss: 1.027153  [112000/525306]\n",
      "loss: 0.996863  [113600/525306]\n",
      "loss: 0.784852  [115200/525306]\n",
      "loss: 0.400653  [116800/525306]\n",
      "loss: 0.892861  [118400/525306]\n",
      "loss: 0.923855  [120000/525306]\n",
      "loss: 1.019894  [121600/525306]\n",
      "loss: 0.531850  [123200/525306]\n",
      "loss: 0.702674  [124800/525306]\n",
      "loss: 0.695175  [126400/525306]\n",
      "loss: 0.803296  [128000/525306]\n",
      "loss: 1.197070  [129600/525306]\n",
      "loss: 1.015766  [131200/525306]\n",
      "loss: 0.698653  [132800/525306]\n",
      "loss: 0.596792  [134400/525306]\n",
      "loss: 0.825707  [136000/525306]\n",
      "loss: 1.103754  [137600/525306]\n",
      "loss: 0.661688  [139200/525306]\n",
      "loss: 0.732958  [140800/525306]\n",
      "loss: 0.679393  [142400/525306]\n",
      "loss: 0.702367  [144000/525306]\n",
      "loss: 0.879804  [145600/525306]\n",
      "loss: 0.992187  [147200/525306]\n",
      "loss: 0.380960  [148800/525306]\n",
      "loss: 0.559391  [150400/525306]\n",
      "loss: 0.783323  [152000/525306]\n",
      "loss: 0.748123  [153600/525306]\n",
      "loss: 1.055667  [155200/525306]\n",
      "loss: 1.496810  [156800/525306]\n",
      "loss: 1.083651  [158400/525306]\n",
      "loss: 1.267542  [160000/525306]\n",
      "loss: 0.817115  [161600/525306]\n",
      "loss: 0.751471  [163200/525306]\n",
      "loss: 1.581911  [164800/525306]\n",
      "loss: 0.873252  [166400/525306]\n",
      "loss: 0.812819  [168000/525306]\n",
      "loss: 0.830471  [169600/525306]\n",
      "loss: 0.778264  [171200/525306]\n",
      "loss: 0.902985  [172800/525306]\n",
      "loss: 0.886696  [174400/525306]\n",
      "loss: 0.916528  [176000/525306]\n",
      "loss: 0.373103  [177600/525306]\n",
      "loss: 0.863870  [179200/525306]\n",
      "loss: 0.668896  [180800/525306]\n",
      "loss: 1.173143  [182400/525306]\n",
      "loss: 0.661976  [184000/525306]\n",
      "loss: 1.004670  [185600/525306]\n",
      "loss: 1.509201  [187200/525306]\n",
      "loss: 1.117328  [188800/525306]\n",
      "loss: 1.233647  [190400/525306]\n",
      "loss: 0.687056  [192000/525306]\n",
      "loss: 1.114348  [193600/525306]\n",
      "loss: 0.973341  [195200/525306]\n",
      "loss: 1.166429  [196800/525306]\n",
      "loss: 1.194791  [198400/525306]\n",
      "loss: 0.724504  [200000/525306]\n",
      "loss: 0.633222  [201600/525306]\n",
      "loss: 0.716177  [203200/525306]\n",
      "loss: 0.526093  [204800/525306]\n",
      "loss: 0.543487  [206400/525306]\n",
      "loss: 0.687162  [208000/525306]\n",
      "loss: 1.102098  [209600/525306]\n",
      "loss: 0.606424  [211200/525306]\n",
      "loss: 0.388195  [212800/525306]\n",
      "loss: 1.412112  [214400/525306]\n",
      "loss: 0.674140  [216000/525306]\n",
      "loss: 1.014934  [217600/525306]\n",
      "loss: 0.809357  [219200/525306]\n",
      "loss: 0.911523  [220800/525306]\n",
      "loss: 0.546579  [222400/525306]\n",
      "loss: 0.640660  [224000/525306]\n",
      "loss: 1.113912  [225600/525306]\n",
      "loss: 1.024237  [227200/525306]\n",
      "loss: 0.523471  [228800/525306]\n",
      "loss: 0.834609  [230400/525306]\n",
      "loss: 1.117022  [232000/525306]\n",
      "loss: 0.549389  [233600/525306]\n",
      "loss: 1.281032  [235200/525306]\n",
      "loss: 0.895148  [236800/525306]\n",
      "loss: 1.065142  [238400/525306]\n",
      "loss: 1.058705  [240000/525306]\n",
      "loss: 0.580429  [241600/525306]\n",
      "loss: 0.802837  [243200/525306]\n",
      "loss: 1.083633  [244800/525306]\n",
      "loss: 0.890829  [246400/525306]\n",
      "loss: 0.719524  [248000/525306]\n",
      "loss: 0.913240  [249600/525306]\n",
      "loss: 0.607263  [251200/525306]\n",
      "loss: 1.106848  [252800/525306]\n",
      "loss: 0.584559  [254400/525306]\n",
      "loss: 0.681908  [256000/525306]\n",
      "loss: 0.877967  [257600/525306]\n",
      "loss: 0.968126  [259200/525306]\n",
      "loss: 0.493806  [260800/525306]\n",
      "loss: 1.005679  [262400/525306]\n",
      "loss: 0.628272  [264000/525306]\n",
      "loss: 0.311035  [265600/525306]\n",
      "loss: 0.906225  [267200/525306]\n",
      "loss: 0.696697  [268800/525306]\n",
      "loss: 0.429411  [270400/525306]\n",
      "loss: 1.293162  [272000/525306]\n",
      "loss: 1.083602  [273600/525306]\n",
      "loss: 0.785444  [275200/525306]\n",
      "loss: 0.695068  [276800/525306]\n",
      "loss: 1.374945  [278400/525306]\n",
      "loss: 0.707420  [280000/525306]\n",
      "loss: 1.071052  [281600/525306]\n",
      "loss: 0.834192  [283200/525306]\n",
      "loss: 0.454139  [284800/525306]\n",
      "loss: 0.597917  [286400/525306]\n",
      "loss: 0.742875  [288000/525306]\n",
      "loss: 0.728184  [289600/525306]\n",
      "loss: 0.399104  [291200/525306]\n",
      "loss: 0.981914  [292800/525306]\n",
      "loss: 0.820113  [294400/525306]\n",
      "loss: 0.924383  [296000/525306]\n",
      "loss: 0.689581  [297600/525306]\n",
      "loss: 1.198289  [299200/525306]\n",
      "loss: 0.866097  [300800/525306]\n",
      "loss: 0.891173  [302400/525306]\n",
      "loss: 0.709179  [304000/525306]\n",
      "loss: 0.579222  [305600/525306]\n",
      "loss: 0.682983  [307200/525306]\n",
      "loss: 0.762829  [308800/525306]\n",
      "loss: 0.946212  [310400/525306]\n",
      "loss: 0.739442  [312000/525306]\n",
      "loss: 1.062108  [313600/525306]\n",
      "loss: 0.740747  [315200/525306]\n",
      "loss: 0.388856  [316800/525306]\n",
      "loss: 1.260637  [318400/525306]\n",
      "loss: 0.848890  [320000/525306]\n",
      "loss: 0.550851  [321600/525306]\n",
      "loss: 0.866745  [323200/525306]\n",
      "loss: 0.589677  [324800/525306]\n",
      "loss: 0.587550  [326400/525306]\n",
      "loss: 1.017952  [328000/525306]\n",
      "loss: 1.367419  [329600/525306]\n",
      "loss: 1.100468  [331200/525306]\n",
      "loss: 0.533720  [332800/525306]\n",
      "loss: 0.583708  [334400/525306]\n",
      "loss: 0.888051  [336000/525306]\n",
      "loss: 0.381048  [337600/525306]\n",
      "loss: 0.505747  [339200/525306]\n",
      "loss: 0.773410  [340800/525306]\n",
      "loss: 0.863914  [342400/525306]\n",
      "loss: 0.794285  [344000/525306]\n",
      "loss: 0.602775  [345600/525306]\n",
      "loss: 0.924445  [347200/525306]\n",
      "loss: 0.738914  [348800/525306]\n",
      "loss: 0.903151  [350400/525306]\n",
      "loss: 0.543491  [352000/525306]\n",
      "loss: 1.245870  [353600/525306]\n",
      "loss: 0.627870  [355200/525306]\n",
      "loss: 1.283558  [356800/525306]\n",
      "loss: 0.986174  [358400/525306]\n",
      "loss: 0.626503  [360000/525306]\n",
      "loss: 0.543967  [361600/525306]\n",
      "loss: 1.248487  [363200/525306]\n",
      "loss: 1.007071  [364800/525306]\n",
      "loss: 0.779159  [366400/525306]\n",
      "loss: 0.790739  [368000/525306]\n",
      "loss: 0.654250  [369600/525306]\n",
      "loss: 0.779454  [371200/525306]\n",
      "loss: 1.245362  [372800/525306]\n",
      "loss: 0.715586  [374400/525306]\n",
      "loss: 0.873042  [376000/525306]\n",
      "loss: 1.323100  [377600/525306]\n",
      "loss: 0.521839  [379200/525306]\n",
      "loss: 0.777525  [380800/525306]\n",
      "loss: 0.813641  [382400/525306]\n",
      "loss: 0.553495  [384000/525306]\n",
      "loss: 0.836827  [385600/525306]\n",
      "loss: 1.201787  [387200/525306]\n",
      "loss: 0.925069  [388800/525306]\n",
      "loss: 0.724468  [390400/525306]\n",
      "loss: 0.669117  [392000/525306]\n",
      "loss: 0.702382  [393600/525306]\n",
      "loss: 0.845832  [395200/525306]\n",
      "loss: 0.870387  [396800/525306]\n",
      "loss: 1.041484  [398400/525306]\n",
      "loss: 0.892133  [400000/525306]\n",
      "loss: 0.531468  [401600/525306]\n",
      "loss: 1.161981  [403200/525306]\n",
      "loss: 0.725387  [404800/525306]\n",
      "loss: 0.487453  [406400/525306]\n",
      "loss: 0.947244  [408000/525306]\n",
      "loss: 1.045295  [409600/525306]\n",
      "loss: 0.719548  [411200/525306]\n",
      "loss: 0.720984  [412800/525306]\n",
      "loss: 0.604104  [414400/525306]\n",
      "loss: 0.579717  [416000/525306]\n",
      "loss: 0.782959  [417600/525306]\n",
      "loss: 1.015918  [419200/525306]\n",
      "loss: 0.725133  [420800/525306]\n",
      "loss: 0.804252  [422400/525306]\n",
      "loss: 0.678558  [424000/525306]\n",
      "loss: 1.511641  [425600/525306]\n",
      "loss: 1.023062  [427200/525306]\n",
      "loss: 0.314988  [428800/525306]\n",
      "loss: 0.888299  [430400/525306]\n",
      "loss: 0.800556  [432000/525306]\n",
      "loss: 0.557649  [433600/525306]\n",
      "loss: 0.721857  [435200/525306]\n",
      "loss: 0.455675  [436800/525306]\n",
      "loss: 0.739239  [438400/525306]\n",
      "loss: 0.697638  [440000/525306]\n",
      "loss: 0.843446  [441600/525306]\n",
      "loss: 0.508435  [443200/525306]\n",
      "loss: 0.862731  [444800/525306]\n",
      "loss: 0.931433  [446400/525306]\n",
      "loss: 0.926914  [448000/525306]\n",
      "loss: 1.203441  [449600/525306]\n",
      "loss: 0.883877  [451200/525306]\n",
      "loss: 0.985317  [452800/525306]\n",
      "loss: 0.718279  [454400/525306]\n",
      "loss: 0.747452  [456000/525306]\n",
      "loss: 1.036468  [457600/525306]\n",
      "loss: 0.580665  [459200/525306]\n",
      "loss: 0.597799  [460800/525306]\n",
      "loss: 0.743891  [462400/525306]\n",
      "loss: 0.917316  [464000/525306]\n",
      "loss: 0.731417  [465600/525306]\n",
      "loss: 0.734067  [467200/525306]\n",
      "loss: 0.436398  [468800/525306]\n",
      "loss: 0.677538  [470400/525306]\n",
      "loss: 0.607902  [472000/525306]\n",
      "loss: 0.424658  [473600/525306]\n",
      "loss: 1.408955  [475200/525306]\n",
      "loss: 0.609358  [476800/525306]\n",
      "loss: 0.575734  [478400/525306]\n",
      "loss: 0.755451  [480000/525306]\n",
      "loss: 0.945028  [481600/525306]\n",
      "loss: 0.690778  [483200/525306]\n",
      "loss: 0.782014  [484800/525306]\n",
      "loss: 0.802389  [486400/525306]\n",
      "loss: 1.033116  [488000/525306]\n",
      "loss: 0.954652  [489600/525306]\n",
      "loss: 0.508254  [491200/525306]\n",
      "loss: 0.790209  [492800/525306]\n",
      "loss: 0.748411  [494400/525306]\n",
      "loss: 0.516257  [496000/525306]\n",
      "loss: 0.483920  [497600/525306]\n",
      "loss: 0.318916  [499200/525306]\n",
      "loss: 0.753010  [500800/525306]\n",
      "loss: 0.945458  [502400/525306]\n",
      "loss: 1.026428  [504000/525306]\n",
      "loss: 0.682034  [505600/525306]\n",
      "loss: 0.825627  [507200/525306]\n",
      "loss: 0.510186  [508800/525306]\n",
      "loss: 0.533836  [510400/525306]\n",
      "loss: 1.091924  [512000/525306]\n",
      "loss: 0.435388  [513600/525306]\n",
      "loss: 0.904358  [515200/525306]\n",
      "loss: 0.562381  [516800/525306]\n",
      "loss: 0.719687  [518400/525306]\n",
      "loss: 1.249481  [520000/525306]\n",
      "loss: 0.888676  [521600/525306]\n",
      "loss: 0.976621  [523200/525306]\n",
      "loss: 1.093971  [524800/525306]\n",
      "Train Accuracy: 69.8260%\n",
      "Test Error: \n",
      " Accuracy: 63.1%, Avg loss: 0.949970, F1-score: 69.06%, Macro_F1-Score:  40.21%  \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.736990  [    0/525306]\n",
      "loss: 0.775959  [ 1600/525306]\n",
      "loss: 0.963371  [ 3200/525306]\n",
      "loss: 0.653904  [ 4800/525306]\n",
      "loss: 0.439694  [ 6400/525306]\n",
      "loss: 0.649777  [ 8000/525306]\n",
      "loss: 0.872795  [ 9600/525306]\n",
      "loss: 0.737169  [11200/525306]\n",
      "loss: 1.263237  [12800/525306]\n",
      "loss: 0.328958  [14400/525306]\n",
      "loss: 0.709545  [16000/525306]\n",
      "loss: 0.875947  [17600/525306]\n",
      "loss: 0.781527  [19200/525306]\n",
      "loss: 0.734368  [20800/525306]\n",
      "loss: 0.818895  [22400/525306]\n",
      "loss: 0.760231  [24000/525306]\n",
      "loss: 0.788775  [25600/525306]\n",
      "loss: 0.637442  [27200/525306]\n",
      "loss: 0.564922  [28800/525306]\n",
      "loss: 0.715885  [30400/525306]\n",
      "loss: 0.868386  [32000/525306]\n",
      "loss: 1.044387  [33600/525306]\n",
      "loss: 0.769379  [35200/525306]\n",
      "loss: 1.082283  [36800/525306]\n",
      "loss: 0.423051  [38400/525306]\n",
      "loss: 0.640761  [40000/525306]\n",
      "loss: 0.919576  [41600/525306]\n",
      "loss: 0.671136  [43200/525306]\n",
      "loss: 1.067594  [44800/525306]\n",
      "loss: 1.042254  [46400/525306]\n",
      "loss: 0.534444  [48000/525306]\n",
      "loss: 0.529889  [49600/525306]\n",
      "loss: 0.781566  [51200/525306]\n",
      "loss: 1.155717  [52800/525306]\n",
      "loss: 0.624192  [54400/525306]\n",
      "loss: 0.884866  [56000/525306]\n",
      "loss: 0.838241  [57600/525306]\n",
      "loss: 0.961211  [59200/525306]\n",
      "loss: 0.839274  [60800/525306]\n",
      "loss: 0.710601  [62400/525306]\n",
      "loss: 0.698125  [64000/525306]\n",
      "loss: 1.002480  [65600/525306]\n",
      "loss: 0.666479  [67200/525306]\n",
      "loss: 0.950461  [68800/525306]\n",
      "loss: 0.558269  [70400/525306]\n",
      "loss: 0.331591  [72000/525306]\n",
      "loss: 0.869132  [73600/525306]\n",
      "loss: 0.569058  [75200/525306]\n",
      "loss: 0.531176  [76800/525306]\n",
      "loss: 0.698953  [78400/525306]\n",
      "loss: 0.535058  [80000/525306]\n",
      "loss: 1.034132  [81600/525306]\n",
      "loss: 1.395312  [83200/525306]\n",
      "loss: 0.724243  [84800/525306]\n",
      "loss: 0.397137  [86400/525306]\n",
      "loss: 0.617273  [88000/525306]\n",
      "loss: 0.601256  [89600/525306]\n",
      "loss: 0.831242  [91200/525306]\n",
      "loss: 0.820543  [92800/525306]\n",
      "loss: 0.653928  [94400/525306]\n",
      "loss: 0.700160  [96000/525306]\n",
      "loss: 0.477673  [97600/525306]\n",
      "loss: 0.861929  [99200/525306]\n",
      "loss: 1.012839  [100800/525306]\n",
      "loss: 0.683940  [102400/525306]\n",
      "loss: 0.840522  [104000/525306]\n",
      "loss: 0.743554  [105600/525306]\n",
      "loss: 0.766096  [107200/525306]\n",
      "loss: 1.269812  [108800/525306]\n",
      "loss: 0.845348  [110400/525306]\n",
      "loss: 0.574354  [112000/525306]\n",
      "loss: 0.875464  [113600/525306]\n",
      "loss: 0.683980  [115200/525306]\n",
      "loss: 1.039104  [116800/525306]\n",
      "loss: 1.228571  [118400/525306]\n",
      "loss: 0.716924  [120000/525306]\n",
      "loss: 0.627064  [121600/525306]\n",
      "loss: 0.789926  [123200/525306]\n",
      "loss: 0.926051  [124800/525306]\n",
      "loss: 0.773282  [126400/525306]\n",
      "loss: 0.792015  [128000/525306]\n",
      "loss: 1.295000  [129600/525306]\n",
      "loss: 0.452913  [131200/525306]\n",
      "loss: 0.884476  [132800/525306]\n",
      "loss: 0.710612  [134400/525306]\n",
      "loss: 0.833723  [136000/525306]\n",
      "loss: 0.678354  [137600/525306]\n",
      "loss: 0.695580  [139200/525306]\n",
      "loss: 0.811767  [140800/525306]\n",
      "loss: 0.714237  [142400/525306]\n",
      "loss: 0.420200  [144000/525306]\n",
      "loss: 0.888848  [145600/525306]\n",
      "loss: 0.630910  [147200/525306]\n",
      "loss: 1.186227  [148800/525306]\n",
      "loss: 0.702773  [150400/525306]\n",
      "loss: 1.273210  [152000/525306]\n",
      "loss: 1.038519  [153600/525306]\n",
      "loss: 0.388710  [155200/525306]\n",
      "loss: 1.244832  [156800/525306]\n",
      "loss: 0.983570  [158400/525306]\n",
      "loss: 0.517419  [160000/525306]\n",
      "loss: 0.699293  [161600/525306]\n",
      "loss: 1.800761  [163200/525306]\n",
      "loss: 0.970770  [164800/525306]\n",
      "loss: 0.649766  [166400/525306]\n",
      "loss: 0.703111  [168000/525306]\n",
      "loss: 0.892194  [169600/525306]\n",
      "loss: 0.877458  [171200/525306]\n",
      "loss: 0.994155  [172800/525306]\n",
      "loss: 0.685151  [174400/525306]\n",
      "loss: 1.091623  [176000/525306]\n",
      "loss: 0.718398  [177600/525306]\n",
      "loss: 0.498389  [179200/525306]\n",
      "loss: 0.508597  [180800/525306]\n",
      "loss: 0.717500  [182400/525306]\n",
      "loss: 0.834314  [184000/525306]\n",
      "loss: 1.070925  [185600/525306]\n",
      "loss: 0.761999  [187200/525306]\n",
      "loss: 0.648142  [188800/525306]\n",
      "loss: 0.970424  [190400/525306]\n",
      "loss: 0.528537  [192000/525306]\n",
      "loss: 0.444884  [193600/525306]\n",
      "loss: 0.835938  [195200/525306]\n",
      "loss: 0.796828  [196800/525306]\n",
      "loss: 0.234277  [198400/525306]\n",
      "loss: 1.176118  [200000/525306]\n",
      "loss: 0.615651  [201600/525306]\n",
      "loss: 0.672751  [203200/525306]\n",
      "loss: 1.248598  [204800/525306]\n",
      "loss: 0.447681  [206400/525306]\n",
      "loss: 0.927770  [208000/525306]\n",
      "loss: 0.848532  [209600/525306]\n",
      "loss: 0.920703  [211200/525306]\n",
      "loss: 0.781279  [212800/525306]\n",
      "loss: 0.715921  [214400/525306]\n",
      "loss: 1.144580  [216000/525306]\n",
      "loss: 0.468572  [217600/525306]\n",
      "loss: 1.224846  [219200/525306]\n",
      "loss: 1.080873  [220800/525306]\n",
      "loss: 1.128718  [222400/525306]\n",
      "loss: 1.119142  [224000/525306]\n",
      "loss: 0.858370  [225600/525306]\n",
      "loss: 0.919131  [227200/525306]\n",
      "loss: 0.798463  [228800/525306]\n",
      "loss: 1.295469  [230400/525306]\n",
      "loss: 0.816390  [232000/525306]\n",
      "loss: 0.755060  [233600/525306]\n",
      "loss: 0.733557  [235200/525306]\n",
      "loss: 1.067285  [236800/525306]\n",
      "loss: 1.147479  [238400/525306]\n",
      "loss: 1.182693  [240000/525306]\n",
      "loss: 1.100751  [241600/525306]\n",
      "loss: 1.008607  [243200/525306]\n",
      "loss: 0.925737  [244800/525306]\n",
      "loss: 0.827642  [246400/525306]\n",
      "loss: 0.753278  [248000/525306]\n",
      "loss: 0.880180  [249600/525306]\n",
      "loss: 0.577346  [251200/525306]\n",
      "loss: 0.846732  [252800/525306]\n",
      "loss: 0.457755  [254400/525306]\n",
      "loss: 0.731143  [256000/525306]\n",
      "loss: 0.777889  [257600/525306]\n",
      "loss: 0.558277  [259200/525306]\n",
      "loss: 1.214413  [260800/525306]\n",
      "loss: 0.711237  [262400/525306]\n",
      "loss: 0.622561  [264000/525306]\n",
      "loss: 0.678089  [265600/525306]\n",
      "loss: 1.121887  [267200/525306]\n",
      "loss: 0.669531  [268800/525306]\n",
      "loss: 0.740155  [270400/525306]\n",
      "loss: 0.532492  [272000/525306]\n",
      "loss: 0.794279  [273600/525306]\n",
      "loss: 1.120947  [275200/525306]\n",
      "loss: 0.982770  [276800/525306]\n",
      "loss: 0.791074  [278400/525306]\n",
      "loss: 1.060539  [280000/525306]\n",
      "loss: 0.769905  [281600/525306]\n",
      "loss: 1.319358  [283200/525306]\n",
      "loss: 0.602554  [284800/525306]\n",
      "loss: 0.803478  [286400/525306]\n",
      "loss: 0.594028  [288000/525306]\n",
      "loss: 0.562339  [289600/525306]\n",
      "loss: 0.518328  [291200/525306]\n",
      "loss: 1.022645  [292800/525306]\n",
      "loss: 0.925080  [294400/525306]\n",
      "loss: 0.800532  [296000/525306]\n",
      "loss: 0.900150  [297600/525306]\n",
      "loss: 0.752650  [299200/525306]\n",
      "loss: 0.620890  [300800/525306]\n",
      "loss: 0.494293  [302400/525306]\n",
      "loss: 0.773652  [304000/525306]\n",
      "loss: 0.721228  [305600/525306]\n",
      "loss: 0.597685  [307200/525306]\n",
      "loss: 0.908137  [308800/525306]\n",
      "loss: 0.549865  [310400/525306]\n",
      "loss: 0.941227  [312000/525306]\n",
      "loss: 0.503513  [313600/525306]\n",
      "loss: 0.679169  [315200/525306]\n",
      "loss: 0.715698  [316800/525306]\n",
      "loss: 0.395071  [318400/525306]\n",
      "loss: 0.559582  [320000/525306]\n",
      "loss: 0.953529  [321600/525306]\n",
      "loss: 0.599367  [323200/525306]\n",
      "loss: 0.755571  [324800/525306]\n",
      "loss: 0.962882  [326400/525306]\n",
      "loss: 1.272615  [328000/525306]\n",
      "loss: 1.001714  [329600/525306]\n",
      "loss: 1.408476  [331200/525306]\n",
      "loss: 1.160838  [332800/525306]\n",
      "loss: 1.016340  [334400/525306]\n",
      "loss: 1.148745  [336000/525306]\n",
      "loss: 0.849155  [337600/525306]\n",
      "loss: 0.720229  [339200/525306]\n",
      "loss: 0.594092  [340800/525306]\n",
      "loss: 1.016372  [342400/525306]\n",
      "loss: 1.175117  [344000/525306]\n",
      "loss: 0.469362  [345600/525306]\n",
      "loss: 0.841879  [347200/525306]\n",
      "loss: 0.870779  [348800/525306]\n",
      "loss: 1.107268  [350400/525306]\n",
      "loss: 0.609392  [352000/525306]\n",
      "loss: 0.695469  [353600/525306]\n",
      "loss: 0.583902  [355200/525306]\n",
      "loss: 1.000158  [356800/525306]\n",
      "loss: 1.040851  [358400/525306]\n",
      "loss: 0.617635  [360000/525306]\n",
      "loss: 1.050022  [361600/525306]\n",
      "loss: 0.608371  [363200/525306]\n",
      "loss: 0.796955  [364800/525306]\n",
      "loss: 1.277637  [366400/525306]\n",
      "loss: 1.046523  [368000/525306]\n",
      "loss: 0.878095  [369600/525306]\n",
      "loss: 1.029906  [371200/525306]\n",
      "loss: 0.508644  [372800/525306]\n",
      "loss: 0.791183  [374400/525306]\n",
      "loss: 0.921458  [376000/525306]\n",
      "loss: 0.662725  [377600/525306]\n",
      "loss: 0.592136  [379200/525306]\n",
      "loss: 0.316332  [380800/525306]\n",
      "loss: 0.629434  [382400/525306]\n",
      "loss: 0.945157  [384000/525306]\n",
      "loss: 0.657596  [385600/525306]\n",
      "loss: 0.286578  [387200/525306]\n",
      "loss: 0.863453  [388800/525306]\n",
      "loss: 0.815549  [390400/525306]\n",
      "loss: 0.475354  [392000/525306]\n",
      "loss: 0.361205  [393600/525306]\n",
      "loss: 0.845437  [395200/525306]\n",
      "loss: 0.714431  [396800/525306]\n",
      "loss: 0.619381  [398400/525306]\n",
      "loss: 0.470697  [400000/525306]\n",
      "loss: 0.658180  [401600/525306]\n",
      "loss: 0.764207  [403200/525306]\n",
      "loss: 1.046965  [404800/525306]\n",
      "loss: 0.408724  [406400/525306]\n",
      "loss: 0.777301  [408000/525306]\n",
      "loss: 0.573418  [409600/525306]\n",
      "loss: 0.918664  [411200/525306]\n",
      "loss: 1.337820  [412800/525306]\n",
      "loss: 0.463887  [414400/525306]\n",
      "loss: 0.755541  [416000/525306]\n",
      "loss: 0.777328  [417600/525306]\n",
      "loss: 0.719190  [419200/525306]\n",
      "loss: 0.745474  [420800/525306]\n",
      "loss: 1.222561  [422400/525306]\n",
      "loss: 0.728672  [424000/525306]\n",
      "loss: 0.931477  [425600/525306]\n",
      "loss: 1.000281  [427200/525306]\n",
      "loss: 0.721290  [428800/525306]\n",
      "loss: 1.109673  [430400/525306]\n",
      "loss: 0.811260  [432000/525306]\n",
      "loss: 0.653094  [433600/525306]\n",
      "loss: 0.465851  [435200/525306]\n",
      "loss: 0.923707  [436800/525306]\n",
      "loss: 1.184024  [438400/525306]\n",
      "loss: 0.644721  [440000/525306]\n",
      "loss: 1.035838  [441600/525306]\n",
      "loss: 0.595786  [443200/525306]\n",
      "loss: 0.950847  [444800/525306]\n",
      "loss: 0.756962  [446400/525306]\n",
      "loss: 0.520562  [448000/525306]\n",
      "loss: 0.664603  [449600/525306]\n",
      "loss: 1.020187  [451200/525306]\n",
      "loss: 1.296723  [452800/525306]\n",
      "loss: 1.145566  [454400/525306]\n",
      "loss: 0.822516  [456000/525306]\n",
      "loss: 0.683642  [457600/525306]\n",
      "loss: 0.831418  [459200/525306]\n",
      "loss: 0.792353  [460800/525306]\n",
      "loss: 0.868462  [462400/525306]\n",
      "loss: 0.861258  [464000/525306]\n",
      "loss: 0.518929  [465600/525306]\n",
      "loss: 0.564750  [467200/525306]\n",
      "loss: 1.113776  [468800/525306]\n",
      "loss: 0.852063  [470400/525306]\n",
      "loss: 0.934464  [472000/525306]\n",
      "loss: 0.829749  [473600/525306]\n",
      "loss: 0.437145  [475200/525306]\n",
      "loss: 1.073573  [476800/525306]\n",
      "loss: 1.521347  [478400/525306]\n",
      "loss: 0.630627  [480000/525306]\n",
      "loss: 1.011954  [481600/525306]\n",
      "loss: 0.792767  [483200/525306]\n",
      "loss: 0.841096  [484800/525306]\n",
      "loss: 0.762122  [486400/525306]\n",
      "loss: 1.008938  [488000/525306]\n",
      "loss: 0.584536  [489600/525306]\n",
      "loss: 0.840728  [491200/525306]\n",
      "loss: 0.525455  [492800/525306]\n",
      "loss: 1.696542  [494400/525306]\n",
      "loss: 1.050635  [496000/525306]\n",
      "loss: 1.135226  [497600/525306]\n",
      "loss: 0.516998  [499200/525306]\n",
      "loss: 1.128716  [500800/525306]\n",
      "loss: 0.541216  [502400/525306]\n",
      "loss: 0.862931  [504000/525306]\n",
      "loss: 0.800031  [505600/525306]\n",
      "loss: 0.674690  [507200/525306]\n",
      "loss: 0.821387  [508800/525306]\n",
      "loss: 1.225569  [510400/525306]\n",
      "loss: 0.885420  [512000/525306]\n",
      "loss: 0.566725  [513600/525306]\n",
      "loss: 0.678717  [515200/525306]\n",
      "loss: 1.031090  [516800/525306]\n",
      "loss: 0.725683  [518400/525306]\n",
      "loss: 0.886567  [520000/525306]\n",
      "loss: 0.993630  [521600/525306]\n",
      "loss: 0.620017  [523200/525306]\n",
      "loss: 0.715295  [524800/525306]\n",
      "Train Accuracy: 69.9293%\n",
      "Test Error: \n",
      " Accuracy: 61.9%, Avg loss: 0.947963, F1-score: 68.41%, Macro_F1-Score:  38.18%  \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.704918  [    0/525306]\n",
      "loss: 0.759292  [ 1600/525306]\n",
      "loss: 0.581971  [ 3200/525306]\n",
      "loss: 1.232085  [ 4800/525306]\n",
      "loss: 0.636080  [ 6400/525306]\n",
      "loss: 0.696688  [ 8000/525306]\n",
      "loss: 0.844785  [ 9600/525306]\n",
      "loss: 0.812805  [11200/525306]\n",
      "loss: 0.586082  [12800/525306]\n",
      "loss: 0.731743  [14400/525306]\n",
      "loss: 1.022805  [16000/525306]\n",
      "loss: 0.722988  [17600/525306]\n",
      "loss: 0.599435  [19200/525306]\n",
      "loss: 0.615398  [20800/525306]\n",
      "loss: 0.632155  [22400/525306]\n",
      "loss: 1.152981  [24000/525306]\n",
      "loss: 0.954838  [25600/525306]\n",
      "loss: 0.661423  [27200/525306]\n",
      "loss: 0.942817  [28800/525306]\n",
      "loss: 1.050572  [30400/525306]\n",
      "loss: 0.712321  [32000/525306]\n",
      "loss: 0.528843  [33600/525306]\n",
      "loss: 0.708563  [35200/525306]\n",
      "loss: 0.689797  [36800/525306]\n",
      "loss: 1.366424  [38400/525306]\n",
      "loss: 0.896758  [40000/525306]\n",
      "loss: 1.073565  [41600/525306]\n",
      "loss: 0.810028  [43200/525306]\n",
      "loss: 0.971068  [44800/525306]\n",
      "loss: 0.758434  [46400/525306]\n",
      "loss: 1.365514  [48000/525306]\n",
      "loss: 0.644840  [49600/525306]\n",
      "loss: 0.774605  [51200/525306]\n",
      "loss: 1.094238  [52800/525306]\n",
      "loss: 0.859402  [54400/525306]\n",
      "loss: 0.842123  [56000/525306]\n",
      "loss: 1.088496  [57600/525306]\n",
      "loss: 0.731796  [59200/525306]\n",
      "loss: 0.584034  [60800/525306]\n",
      "loss: 0.989856  [62400/525306]\n",
      "loss: 0.763270  [64000/525306]\n",
      "loss: 0.924953  [65600/525306]\n",
      "loss: 0.623244  [67200/525306]\n",
      "loss: 0.429373  [68800/525306]\n",
      "loss: 0.893991  [70400/525306]\n",
      "loss: 0.819219  [72000/525306]\n",
      "loss: 1.046193  [73600/525306]\n",
      "loss: 0.964458  [75200/525306]\n",
      "loss: 0.604386  [76800/525306]\n",
      "loss: 0.756628  [78400/525306]\n",
      "loss: 1.022103  [80000/525306]\n",
      "loss: 0.849764  [81600/525306]\n",
      "loss: 0.762249  [83200/525306]\n",
      "loss: 1.083915  [84800/525306]\n",
      "loss: 1.099880  [86400/525306]\n",
      "loss: 0.940103  [88000/525306]\n",
      "loss: 0.847065  [89600/525306]\n",
      "loss: 0.594587  [91200/525306]\n",
      "loss: 0.823157  [92800/525306]\n",
      "loss: 0.827798  [94400/525306]\n",
      "loss: 0.811234  [96000/525306]\n",
      "loss: 0.781363  [97600/525306]\n",
      "loss: 0.630809  [99200/525306]\n",
      "loss: 0.853672  [100800/525306]\n",
      "loss: 0.363186  [102400/525306]\n",
      "loss: 0.818639  [104000/525306]\n",
      "loss: 1.092172  [105600/525306]\n",
      "loss: 0.749850  [107200/525306]\n",
      "loss: 1.283983  [108800/525306]\n",
      "loss: 0.896089  [110400/525306]\n",
      "loss: 1.085778  [112000/525306]\n",
      "loss: 1.043145  [113600/525306]\n",
      "loss: 0.861660  [115200/525306]\n",
      "loss: 1.111795  [116800/525306]\n",
      "loss: 0.530756  [118400/525306]\n",
      "loss: 1.028105  [120000/525306]\n",
      "loss: 0.817020  [121600/525306]\n",
      "loss: 1.076214  [123200/525306]\n",
      "loss: 0.552488  [124800/525306]\n",
      "loss: 0.698274  [126400/525306]\n",
      "loss: 1.319723  [128000/525306]\n",
      "loss: 0.547722  [129600/525306]\n",
      "loss: 0.793500  [131200/525306]\n",
      "loss: 0.914327  [132800/525306]\n",
      "loss: 0.992628  [134400/525306]\n",
      "loss: 0.797331  [136000/525306]\n",
      "loss: 1.077608  [137600/525306]\n",
      "loss: 0.888742  [139200/525306]\n",
      "loss: 0.496162  [140800/525306]\n",
      "loss: 0.803596  [142400/525306]\n",
      "loss: 1.258462  [144000/525306]\n",
      "loss: 0.785137  [145600/525306]\n",
      "loss: 1.065203  [147200/525306]\n",
      "loss: 0.595094  [148800/525306]\n",
      "loss: 0.831750  [150400/525306]\n",
      "loss: 1.280687  [152000/525306]\n",
      "loss: 0.784915  [153600/525306]\n",
      "loss: 0.523511  [155200/525306]\n",
      "loss: 0.774060  [156800/525306]\n",
      "loss: 0.955806  [158400/525306]\n",
      "loss: 0.512490  [160000/525306]\n",
      "loss: 0.604159  [161600/525306]\n",
      "loss: 0.974324  [163200/525306]\n",
      "loss: 0.761304  [164800/525306]\n",
      "loss: 0.475370  [166400/525306]\n",
      "loss: 0.843759  [168000/525306]\n",
      "loss: 0.330262  [169600/525306]\n",
      "loss: 1.532601  [171200/525306]\n",
      "loss: 0.877483  [172800/525306]\n",
      "loss: 0.695582  [174400/525306]\n",
      "loss: 0.403637  [176000/525306]\n",
      "loss: 1.594968  [177600/525306]\n",
      "loss: 0.633771  [179200/525306]\n",
      "loss: 0.456287  [180800/525306]\n",
      "loss: 0.978948  [182400/525306]\n",
      "loss: 0.895109  [184000/525306]\n",
      "loss: 0.902588  [185600/525306]\n",
      "loss: 0.852796  [187200/525306]\n",
      "loss: 0.839059  [188800/525306]\n",
      "loss: 0.713387  [190400/525306]\n",
      "loss: 0.951286  [192000/525306]\n",
      "loss: 0.191286  [193600/525306]\n",
      "loss: 0.521264  [195200/525306]\n",
      "loss: 0.795126  [196800/525306]\n",
      "loss: 1.041880  [198400/525306]\n",
      "loss: 0.578864  [200000/525306]\n",
      "loss: 0.490708  [201600/525306]\n",
      "loss: 0.935728  [203200/525306]\n",
      "loss: 1.408886  [204800/525306]\n",
      "loss: 0.720180  [206400/525306]\n",
      "loss: 1.015549  [208000/525306]\n",
      "loss: 0.884863  [209600/525306]\n",
      "loss: 0.709848  [211200/525306]\n",
      "loss: 0.574845  [212800/525306]\n",
      "loss: 1.120487  [214400/525306]\n",
      "loss: 0.740064  [216000/525306]\n",
      "loss: 0.742253  [217600/525306]\n",
      "loss: 1.144840  [219200/525306]\n",
      "loss: 0.318059  [220800/525306]\n",
      "loss: 0.828258  [222400/525306]\n",
      "loss: 0.767623  [224000/525306]\n",
      "loss: 0.726462  [225600/525306]\n",
      "loss: 0.606265  [227200/525306]\n",
      "loss: 0.778176  [228800/525306]\n",
      "loss: 0.688162  [230400/525306]\n",
      "loss: 0.738828  [232000/525306]\n",
      "loss: 0.730425  [233600/525306]\n",
      "loss: 0.527493  [235200/525306]\n",
      "loss: 0.991707  [236800/525306]\n",
      "loss: 1.078047  [238400/525306]\n",
      "loss: 0.563422  [240000/525306]\n",
      "loss: 1.495133  [241600/525306]\n",
      "loss: 1.026095  [243200/525306]\n",
      "loss: 0.956865  [244800/525306]\n",
      "loss: 1.162121  [246400/525306]\n",
      "loss: 0.650888  [248000/525306]\n",
      "loss: 0.730017  [249600/525306]\n",
      "loss: 1.105693  [251200/525306]\n",
      "loss: 0.926739  [252800/525306]\n",
      "loss: 0.640043  [254400/525306]\n",
      "loss: 0.743572  [256000/525306]\n",
      "loss: 0.943654  [257600/525306]\n",
      "loss: 0.925819  [259200/525306]\n",
      "loss: 0.503829  [260800/525306]\n",
      "loss: 0.682091  [262400/525306]\n",
      "loss: 0.960107  [264000/525306]\n",
      "loss: 0.914288  [265600/525306]\n",
      "loss: 0.955609  [267200/525306]\n",
      "loss: 0.647841  [268800/525306]\n",
      "loss: 0.620917  [270400/525306]\n",
      "loss: 0.530685  [272000/525306]\n",
      "loss: 0.394345  [273600/525306]\n",
      "loss: 0.819010  [275200/525306]\n",
      "loss: 1.013153  [276800/525306]\n",
      "loss: 0.779853  [278400/525306]\n",
      "loss: 0.756239  [280000/525306]\n",
      "loss: 0.779373  [281600/525306]\n",
      "loss: 0.942674  [283200/525306]\n",
      "loss: 0.659597  [284800/525306]\n",
      "loss: 1.090639  [286400/525306]\n",
      "loss: 1.458342  [288000/525306]\n",
      "loss: 0.922566  [289600/525306]\n",
      "loss: 0.933092  [291200/525306]\n",
      "loss: 0.731757  [292800/525306]\n",
      "loss: 0.594523  [294400/525306]\n",
      "loss: 0.525873  [296000/525306]\n",
      "loss: 0.940918  [297600/525306]\n",
      "loss: 0.907212  [299200/525306]\n",
      "loss: 0.852695  [300800/525306]\n",
      "loss: 0.854682  [302400/525306]\n",
      "loss: 1.034510  [304000/525306]\n",
      "loss: 1.074307  [305600/525306]\n",
      "loss: 0.422025  [307200/525306]\n",
      "loss: 0.514286  [308800/525306]\n",
      "loss: 1.037018  [310400/525306]\n",
      "loss: 0.895757  [312000/525306]\n",
      "loss: 0.576702  [313600/525306]\n",
      "loss: 0.754526  [315200/525306]\n",
      "loss: 0.744487  [316800/525306]\n",
      "loss: 0.407541  [318400/525306]\n",
      "loss: 1.091616  [320000/525306]\n",
      "loss: 0.425780  [321600/525306]\n",
      "loss: 0.713430  [323200/525306]\n",
      "loss: 0.746408  [324800/525306]\n",
      "loss: 1.196145  [326400/525306]\n",
      "loss: 0.768848  [328000/525306]\n",
      "loss: 1.299391  [329600/525306]\n",
      "loss: 0.426996  [331200/525306]\n",
      "loss: 0.803401  [332800/525306]\n",
      "loss: 0.550472  [334400/525306]\n",
      "loss: 1.183665  [336000/525306]\n",
      "loss: 1.250328  [337600/525306]\n",
      "loss: 0.515979  [339200/525306]\n",
      "loss: 0.868802  [340800/525306]\n",
      "loss: 0.523446  [342400/525306]\n",
      "loss: 0.787012  [344000/525306]\n",
      "loss: 0.570511  [345600/525306]\n",
      "loss: 0.482366  [347200/525306]\n",
      "loss: 1.049035  [348800/525306]\n",
      "loss: 0.466384  [350400/525306]\n",
      "loss: 0.542680  [352000/525306]\n",
      "loss: 0.968309  [353600/525306]\n",
      "loss: 0.702937  [355200/525306]\n",
      "loss: 0.542815  [356800/525306]\n",
      "loss: 0.785694  [358400/525306]\n",
      "loss: 0.815514  [360000/525306]\n",
      "loss: 0.727625  [361600/525306]\n",
      "loss: 1.256824  [363200/525306]\n",
      "loss: 0.972796  [364800/525306]\n",
      "loss: 0.812884  [366400/525306]\n",
      "loss: 1.024437  [368000/525306]\n",
      "loss: 0.676919  [369600/525306]\n",
      "loss: 0.420117  [371200/525306]\n",
      "loss: 0.725261  [372800/525306]\n",
      "loss: 0.888436  [374400/525306]\n",
      "loss: 0.801625  [376000/525306]\n",
      "loss: 0.989084  [377600/525306]\n",
      "loss: 1.164145  [379200/525306]\n",
      "loss: 0.732767  [380800/525306]\n",
      "loss: 0.714833  [382400/525306]\n",
      "loss: 0.976537  [384000/525306]\n",
      "loss: 0.736775  [385600/525306]\n",
      "loss: 1.283026  [387200/525306]\n",
      "loss: 0.722012  [388800/525306]\n",
      "loss: 0.528834  [390400/525306]\n",
      "loss: 0.456861  [392000/525306]\n",
      "loss: 0.596887  [393600/525306]\n",
      "loss: 0.863398  [395200/525306]\n",
      "loss: 0.506394  [396800/525306]\n",
      "loss: 0.942761  [398400/525306]\n",
      "loss: 0.912218  [400000/525306]\n",
      "loss: 0.573062  [401600/525306]\n",
      "loss: 0.849680  [403200/525306]\n",
      "loss: 0.642775  [404800/525306]\n",
      "loss: 0.662096  [406400/525306]\n",
      "loss: 1.535046  [408000/525306]\n",
      "loss: 0.750342  [409600/525306]\n",
      "loss: 0.598728  [411200/525306]\n",
      "loss: 0.678982  [412800/525306]\n",
      "loss: 0.762292  [414400/525306]\n",
      "loss: 0.660087  [416000/525306]\n",
      "loss: 0.840194  [417600/525306]\n",
      "loss: 0.770769  [419200/525306]\n",
      "loss: 1.339272  [420800/525306]\n",
      "loss: 0.981302  [422400/525306]\n",
      "loss: 0.733582  [424000/525306]\n",
      "loss: 0.776113  [425600/525306]\n",
      "loss: 0.777534  [427200/525306]\n",
      "loss: 0.469200  [428800/525306]\n",
      "loss: 0.537673  [430400/525306]\n",
      "loss: 0.825014  [432000/525306]\n",
      "loss: 0.729644  [433600/525306]\n",
      "loss: 0.580773  [435200/525306]\n",
      "loss: 0.626273  [436800/525306]\n",
      "loss: 0.379808  [438400/525306]\n",
      "loss: 0.735292  [440000/525306]\n",
      "loss: 0.746627  [441600/525306]\n",
      "loss: 1.292517  [443200/525306]\n",
      "loss: 0.486912  [444800/525306]\n",
      "loss: 0.784474  [446400/525306]\n",
      "loss: 1.036973  [448000/525306]\n",
      "loss: 0.542415  [449600/525306]\n",
      "loss: 0.763597  [451200/525306]\n",
      "loss: 0.468802  [452800/525306]\n",
      "loss: 0.848713  [454400/525306]\n",
      "loss: 0.942996  [456000/525306]\n",
      "loss: 1.004538  [457600/525306]\n",
      "loss: 1.027622  [459200/525306]\n",
      "loss: 0.832895  [460800/525306]\n",
      "loss: 0.649597  [462400/525306]\n",
      "loss: 0.900835  [464000/525306]\n",
      "loss: 0.582609  [465600/525306]\n",
      "loss: 1.219406  [467200/525306]\n",
      "loss: 0.650983  [468800/525306]\n",
      "loss: 0.556637  [470400/525306]\n",
      "loss: 0.533121  [472000/525306]\n",
      "loss: 0.755722  [473600/525306]\n",
      "loss: 0.861718  [475200/525306]\n",
      "loss: 0.890991  [476800/525306]\n",
      "loss: 0.774397  [478400/525306]\n",
      "loss: 0.513237  [480000/525306]\n",
      "loss: 0.495087  [481600/525306]\n",
      "loss: 0.665560  [483200/525306]\n",
      "loss: 0.660757  [484800/525306]\n",
      "loss: 0.609816  [486400/525306]\n",
      "loss: 0.754217  [488000/525306]\n",
      "loss: 0.502970  [489600/525306]\n",
      "loss: 0.845839  [491200/525306]\n",
      "loss: 1.293627  [492800/525306]\n",
      "loss: 0.598804  [494400/525306]\n",
      "loss: 0.469246  [496000/525306]\n",
      "loss: 0.926703  [497600/525306]\n",
      "loss: 0.340973  [499200/525306]\n",
      "loss: 0.900389  [500800/525306]\n",
      "loss: 0.752495  [502400/525306]\n",
      "loss: 0.787661  [504000/525306]\n",
      "loss: 0.951176  [505600/525306]\n",
      "loss: 0.777893  [507200/525306]\n",
      "loss: 0.696120  [508800/525306]\n",
      "loss: 0.425333  [510400/525306]\n",
      "loss: 0.714128  [512000/525306]\n",
      "loss: 0.785801  [513600/525306]\n",
      "loss: 0.746326  [515200/525306]\n",
      "loss: 0.648196  [516800/525306]\n",
      "loss: 0.865183  [518400/525306]\n",
      "loss: 0.431797  [520000/525306]\n",
      "loss: 0.809595  [521600/525306]\n",
      "loss: 0.503482  [523200/525306]\n",
      "loss: 0.812798  [524800/525306]\n",
      "Train Accuracy: 70.1054%\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.991885, F1-score: 67.88%, Macro_F1-Score:  37.48%  \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.202343  [    0/525306]\n",
      "loss: 0.704720  [ 1600/525306]\n",
      "loss: 0.512727  [ 3200/525306]\n",
      "loss: 0.491369  [ 4800/525306]\n",
      "loss: 0.429957  [ 6400/525306]\n",
      "loss: 0.885060  [ 8000/525306]\n",
      "loss: 1.356804  [ 9600/525306]\n",
      "loss: 0.604065  [11200/525306]\n",
      "loss: 1.034884  [12800/525306]\n",
      "loss: 0.901317  [14400/525306]\n",
      "loss: 1.050755  [16000/525306]\n",
      "loss: 0.598096  [17600/525306]\n",
      "loss: 0.321414  [19200/525306]\n",
      "loss: 0.951526  [20800/525306]\n",
      "loss: 0.670298  [22400/525306]\n",
      "loss: 0.716422  [24000/525306]\n",
      "loss: 0.869704  [25600/525306]\n",
      "loss: 1.005019  [27200/525306]\n",
      "loss: 0.821028  [28800/525306]\n",
      "loss: 0.727403  [30400/525306]\n",
      "loss: 0.911289  [32000/525306]\n",
      "loss: 0.639380  [33600/525306]\n",
      "loss: 1.172134  [35200/525306]\n",
      "loss: 1.172833  [36800/525306]\n",
      "loss: 1.034314  [38400/525306]\n",
      "loss: 0.505381  [40000/525306]\n",
      "loss: 1.032146  [41600/525306]\n",
      "loss: 0.800320  [43200/525306]\n",
      "loss: 0.809576  [44800/525306]\n",
      "loss: 0.861291  [46400/525306]\n",
      "loss: 0.760116  [48000/525306]\n",
      "loss: 0.621525  [49600/525306]\n",
      "loss: 0.337185  [51200/525306]\n",
      "loss: 0.908618  [52800/525306]\n",
      "loss: 0.551889  [54400/525306]\n",
      "loss: 0.685870  [56000/525306]\n",
      "loss: 0.835242  [57600/525306]\n",
      "loss: 0.456608  [59200/525306]\n",
      "loss: 0.699290  [60800/525306]\n",
      "loss: 0.777779  [62400/525306]\n",
      "loss: 0.934865  [64000/525306]\n",
      "loss: 0.581410  [65600/525306]\n",
      "loss: 0.621955  [67200/525306]\n",
      "loss: 0.878558  [68800/525306]\n",
      "loss: 0.944451  [70400/525306]\n",
      "loss: 0.565485  [72000/525306]\n",
      "loss: 1.034572  [73600/525306]\n",
      "loss: 0.391621  [75200/525306]\n",
      "loss: 0.733459  [76800/525306]\n",
      "loss: 0.934161  [78400/525306]\n",
      "loss: 0.992908  [80000/525306]\n",
      "loss: 0.551249  [81600/525306]\n",
      "loss: 0.450879  [83200/525306]\n",
      "loss: 0.511767  [84800/525306]\n",
      "loss: 0.706464  [86400/525306]\n",
      "loss: 0.458807  [88000/525306]\n",
      "loss: 0.690522  [89600/525306]\n",
      "loss: 0.870216  [91200/525306]\n",
      "loss: 1.029453  [92800/525306]\n",
      "loss: 0.851182  [94400/525306]\n",
      "loss: 0.527553  [96000/525306]\n",
      "loss: 0.997261  [97600/525306]\n",
      "loss: 1.101619  [99200/525306]\n",
      "loss: 0.690125  [100800/525306]\n",
      "loss: 0.559910  [102400/525306]\n",
      "loss: 0.784470  [104000/525306]\n",
      "loss: 0.751214  [105600/525306]\n",
      "loss: 0.952536  [107200/525306]\n",
      "loss: 0.976496  [108800/525306]\n",
      "loss: 0.918436  [110400/525306]\n",
      "loss: 1.087047  [112000/525306]\n",
      "loss: 0.888716  [113600/525306]\n",
      "loss: 0.969717  [115200/525306]\n",
      "loss: 0.928357  [116800/525306]\n",
      "loss: 1.403703  [118400/525306]\n",
      "loss: 0.656080  [120000/525306]\n",
      "loss: 0.952647  [121600/525306]\n",
      "loss: 0.674664  [123200/525306]\n",
      "loss: 0.721357  [124800/525306]\n",
      "loss: 0.846411  [126400/525306]\n",
      "loss: 1.233661  [128000/525306]\n",
      "loss: 0.716522  [129600/525306]\n",
      "loss: 0.787930  [131200/525306]\n",
      "loss: 0.577669  [132800/525306]\n",
      "loss: 0.363138  [134400/525306]\n",
      "loss: 0.746105  [136000/525306]\n",
      "loss: 0.661156  [137600/525306]\n",
      "loss: 0.706608  [139200/525306]\n",
      "loss: 0.583576  [140800/525306]\n",
      "loss: 0.890007  [142400/525306]\n",
      "loss: 0.937109  [144000/525306]\n",
      "loss: 0.886443  [145600/525306]\n",
      "loss: 1.233806  [147200/525306]\n",
      "loss: 0.925979  [148800/525306]\n",
      "loss: 0.768097  [150400/525306]\n",
      "loss: 0.739484  [152000/525306]\n",
      "loss: 0.961850  [153600/525306]\n",
      "loss: 1.040571  [155200/525306]\n",
      "loss: 0.896282  [156800/525306]\n",
      "loss: 0.796979  [158400/525306]\n",
      "loss: 0.897947  [160000/525306]\n",
      "loss: 0.629872  [161600/525306]\n",
      "loss: 0.872173  [163200/525306]\n",
      "loss: 0.512646  [164800/525306]\n",
      "loss: 0.412109  [166400/525306]\n",
      "loss: 0.829948  [168000/525306]\n",
      "loss: 1.327008  [169600/525306]\n",
      "loss: 0.992895  [171200/525306]\n",
      "loss: 1.171016  [172800/525306]\n",
      "loss: 1.108541  [174400/525306]\n",
      "loss: 1.060278  [176000/525306]\n",
      "loss: 0.689431  [177600/525306]\n",
      "loss: 0.702183  [179200/525306]\n",
      "loss: 1.768622  [180800/525306]\n",
      "loss: 0.750633  [182400/525306]\n",
      "loss: 0.585823  [184000/525306]\n",
      "loss: 0.725603  [185600/525306]\n",
      "loss: 0.505745  [187200/525306]\n",
      "loss: 0.725463  [188800/525306]\n",
      "loss: 1.100374  [190400/525306]\n",
      "loss: 1.222945  [192000/525306]\n",
      "loss: 0.724683  [193600/525306]\n",
      "loss: 0.618885  [195200/525306]\n",
      "loss: 0.703509  [196800/525306]\n",
      "loss: 0.920316  [198400/525306]\n",
      "loss: 0.591220  [200000/525306]\n",
      "loss: 0.849070  [201600/525306]\n",
      "loss: 0.947167  [203200/525306]\n",
      "loss: 0.329718  [204800/525306]\n",
      "loss: 0.536172  [206400/525306]\n",
      "loss: 1.033939  [208000/525306]\n",
      "loss: 1.294425  [209600/525306]\n",
      "loss: 0.613909  [211200/525306]\n",
      "loss: 0.781410  [212800/525306]\n",
      "loss: 0.796643  [214400/525306]\n",
      "loss: 0.813000  [216000/525306]\n",
      "loss: 0.681963  [217600/525306]\n",
      "loss: 0.874493  [219200/525306]\n",
      "loss: 1.439357  [220800/525306]\n",
      "loss: 0.559630  [222400/525306]\n",
      "loss: 0.768363  [224000/525306]\n",
      "loss: 1.094697  [225600/525306]\n",
      "loss: 0.666319  [227200/525306]\n",
      "loss: 0.881634  [228800/525306]\n",
      "loss: 0.797590  [230400/525306]\n",
      "loss: 1.471160  [232000/525306]\n",
      "loss: 1.399158  [233600/525306]\n",
      "loss: 1.230675  [235200/525306]\n",
      "loss: 1.239819  [236800/525306]\n",
      "loss: 0.575989  [238400/525306]\n",
      "loss: 0.925958  [240000/525306]\n",
      "loss: 0.671464  [241600/525306]\n",
      "loss: 0.815640  [243200/525306]\n",
      "loss: 0.813764  [244800/525306]\n",
      "loss: 0.816853  [246400/525306]\n",
      "loss: 0.542765  [248000/525306]\n",
      "loss: 0.473765  [249600/525306]\n",
      "loss: 1.106066  [251200/525306]\n",
      "loss: 0.973525  [252800/525306]\n",
      "loss: 0.671451  [254400/525306]\n",
      "loss: 0.826452  [256000/525306]\n",
      "loss: 0.849002  [257600/525306]\n",
      "loss: 0.825479  [259200/525306]\n",
      "loss: 0.581277  [260800/525306]\n",
      "loss: 0.707413  [262400/525306]\n",
      "loss: 0.422508  [264000/525306]\n",
      "loss: 0.757234  [265600/525306]\n",
      "loss: 0.635997  [267200/525306]\n",
      "loss: 0.817857  [268800/525306]\n",
      "loss: 1.066843  [270400/525306]\n",
      "loss: 0.972244  [272000/525306]\n",
      "loss: 0.733879  [273600/525306]\n",
      "loss: 0.763825  [275200/525306]\n",
      "loss: 0.716120  [276800/525306]\n",
      "loss: 0.632407  [278400/525306]\n",
      "loss: 1.358628  [280000/525306]\n",
      "loss: 0.850550  [281600/525306]\n",
      "loss: 0.632129  [283200/525306]\n",
      "loss: 0.621457  [284800/525306]\n",
      "loss: 0.507283  [286400/525306]\n",
      "loss: 0.876882  [288000/525306]\n",
      "loss: 0.607111  [289600/525306]\n",
      "loss: 1.294920  [291200/525306]\n",
      "loss: 0.775534  [292800/525306]\n",
      "loss: 0.925295  [294400/525306]\n",
      "loss: 0.848938  [296000/525306]\n",
      "loss: 1.092460  [297600/525306]\n",
      "loss: 0.721762  [299200/525306]\n",
      "loss: 0.589460  [300800/525306]\n",
      "loss: 0.655756  [302400/525306]\n",
      "loss: 0.821010  [304000/525306]\n",
      "loss: 0.773542  [305600/525306]\n",
      "loss: 0.456263  [307200/525306]\n",
      "loss: 0.581449  [308800/525306]\n",
      "loss: 0.682676  [310400/525306]\n",
      "loss: 1.119239  [312000/525306]\n",
      "loss: 0.910643  [313600/525306]\n",
      "loss: 0.595064  [315200/525306]\n",
      "loss: 1.010385  [316800/525306]\n",
      "loss: 0.798906  [318400/525306]\n",
      "loss: 0.632382  [320000/525306]\n",
      "loss: 0.480727  [321600/525306]\n",
      "loss: 0.520113  [323200/525306]\n",
      "loss: 0.562824  [324800/525306]\n",
      "loss: 1.433681  [326400/525306]\n",
      "loss: 0.331764  [328000/525306]\n",
      "loss: 0.648754  [329600/525306]\n",
      "loss: 0.484353  [331200/525306]\n",
      "loss: 0.768664  [332800/525306]\n",
      "loss: 0.921252  [334400/525306]\n",
      "loss: 1.398056  [336000/525306]\n",
      "loss: 0.909919  [337600/525306]\n",
      "loss: 0.585829  [339200/525306]\n",
      "loss: 0.737922  [340800/525306]\n",
      "loss: 1.367010  [342400/525306]\n",
      "loss: 1.044461  [344000/525306]\n",
      "loss: 0.814074  [345600/525306]\n",
      "loss: 0.440109  [347200/525306]\n",
      "loss: 0.847413  [348800/525306]\n",
      "loss: 1.139432  [350400/525306]\n",
      "loss: 0.635163  [352000/525306]\n",
      "loss: 0.902416  [353600/525306]\n",
      "loss: 1.005137  [355200/525306]\n",
      "loss: 1.128063  [356800/525306]\n",
      "loss: 0.872980  [358400/525306]\n",
      "loss: 0.606060  [360000/525306]\n",
      "loss: 1.021079  [361600/525306]\n",
      "loss: 1.091338  [363200/525306]\n",
      "loss: 0.667482  [364800/525306]\n",
      "loss: 0.586935  [366400/525306]\n",
      "loss: 0.720301  [368000/525306]\n",
      "loss: 1.077540  [369600/525306]\n",
      "loss: 0.883982  [371200/525306]\n",
      "loss: 0.665904  [372800/525306]\n",
      "loss: 0.823695  [374400/525306]\n",
      "loss: 0.712371  [376000/525306]\n",
      "loss: 1.042238  [377600/525306]\n",
      "loss: 0.801831  [379200/525306]\n",
      "loss: 0.502007  [380800/525306]\n",
      "loss: 0.920955  [382400/525306]\n",
      "loss: 1.069718  [384000/525306]\n",
      "loss: 0.378895  [385600/525306]\n",
      "loss: 0.608405  [387200/525306]\n",
      "loss: 1.625366  [388800/525306]\n",
      "loss: 1.130862  [390400/525306]\n",
      "loss: 1.271028  [392000/525306]\n",
      "loss: 0.636237  [393600/525306]\n",
      "loss: 1.254754  [395200/525306]\n",
      "loss: 1.004809  [396800/525306]\n",
      "loss: 0.753307  [398400/525306]\n",
      "loss: 0.747000  [400000/525306]\n",
      "loss: 0.802040  [401600/525306]\n",
      "loss: 0.466966  [403200/525306]\n",
      "loss: 0.882248  [404800/525306]\n",
      "loss: 0.804338  [406400/525306]\n",
      "loss: 0.739283  [408000/525306]\n",
      "loss: 0.610610  [409600/525306]\n",
      "loss: 0.703850  [411200/525306]\n",
      "loss: 0.660519  [412800/525306]\n",
      "loss: 0.836469  [414400/525306]\n",
      "loss: 0.342262  [416000/525306]\n",
      "loss: 0.863067  [417600/525306]\n",
      "loss: 0.911648  [419200/525306]\n",
      "loss: 0.663893  [420800/525306]\n",
      "loss: 0.739221  [422400/525306]\n",
      "loss: 0.583952  [424000/525306]\n",
      "loss: 1.450017  [425600/525306]\n",
      "loss: 1.137350  [427200/525306]\n",
      "loss: 0.852484  [428800/525306]\n",
      "loss: 0.743903  [430400/525306]\n",
      "loss: 0.654088  [432000/525306]\n",
      "loss: 0.801797  [433600/525306]\n",
      "loss: 1.132535  [435200/525306]\n",
      "loss: 1.248492  [436800/525306]\n",
      "loss: 1.191554  [438400/525306]\n",
      "loss: 0.538093  [440000/525306]\n",
      "loss: 0.723719  [441600/525306]\n",
      "loss: 1.006950  [443200/525306]\n",
      "loss: 0.853203  [444800/525306]\n",
      "loss: 0.607201  [446400/525306]\n",
      "loss: 0.738091  [448000/525306]\n",
      "loss: 0.642166  [449600/525306]\n",
      "loss: 1.142117  [451200/525306]\n",
      "loss: 1.538661  [452800/525306]\n",
      "loss: 0.365863  [454400/525306]\n",
      "loss: 0.645747  [456000/525306]\n",
      "loss: 0.592430  [457600/525306]\n",
      "loss: 0.351407  [459200/525306]\n",
      "loss: 0.824731  [460800/525306]\n",
      "loss: 0.662497  [462400/525306]\n",
      "loss: 0.557436  [464000/525306]\n",
      "loss: 0.663748  [465600/525306]\n",
      "loss: 0.972273  [467200/525306]\n",
      "loss: 0.659974  [468800/525306]\n",
      "loss: 0.642746  [470400/525306]\n",
      "loss: 0.852172  [472000/525306]\n",
      "loss: 0.432019  [473600/525306]\n",
      "loss: 0.706645  [475200/525306]\n",
      "loss: 0.605257  [476800/525306]\n",
      "loss: 1.254581  [478400/525306]\n",
      "loss: 1.130091  [480000/525306]\n",
      "loss: 1.085989  [481600/525306]\n",
      "loss: 1.051396  [483200/525306]\n",
      "loss: 0.636969  [484800/525306]\n",
      "loss: 1.057291  [486400/525306]\n",
      "loss: 0.272093  [488000/525306]\n",
      "loss: 0.725571  [489600/525306]\n",
      "loss: 1.419886  [491200/525306]\n",
      "loss: 0.587175  [492800/525306]\n",
      "loss: 0.662894  [494400/525306]\n",
      "loss: 0.786471  [496000/525306]\n",
      "loss: 0.390544  [497600/525306]\n",
      "loss: 0.730937  [499200/525306]\n",
      "loss: 0.832511  [500800/525306]\n",
      "loss: 0.508651  [502400/525306]\n",
      "loss: 0.664783  [504000/525306]\n",
      "loss: 0.477059  [505600/525306]\n",
      "loss: 0.886494  [507200/525306]\n",
      "loss: 0.503159  [508800/525306]\n",
      "loss: 0.448007  [510400/525306]\n",
      "loss: 0.948422  [512000/525306]\n",
      "loss: 0.971405  [513600/525306]\n",
      "loss: 1.150404  [515200/525306]\n",
      "loss: 0.732438  [516800/525306]\n",
      "loss: 1.011982  [518400/525306]\n",
      "loss: 0.497391  [520000/525306]\n",
      "loss: 0.645782  [521600/525306]\n",
      "loss: 0.656040  [523200/525306]\n",
      "loss: 0.494542  [524800/525306]\n",
      "Train Accuracy: 70.2227%\n",
      "Test Error: \n",
      " Accuracy: 63.2%, Avg loss: 0.964435, F1-score: 68.96%, Macro_F1-Score:  40.12%  \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.845058  [    0/525306]\n",
      "loss: 0.863712  [ 1600/525306]\n",
      "loss: 0.860487  [ 3200/525306]\n",
      "loss: 0.821359  [ 4800/525306]\n",
      "loss: 1.002194  [ 6400/525306]\n",
      "loss: 0.699103  [ 8000/525306]\n",
      "loss: 0.892346  [ 9600/525306]\n",
      "loss: 1.124725  [11200/525306]\n",
      "loss: 0.613570  [12800/525306]\n",
      "loss: 0.250996  [14400/525306]\n",
      "loss: 0.942799  [16000/525306]\n",
      "loss: 1.126270  [17600/525306]\n",
      "loss: 0.672406  [19200/525306]\n",
      "loss: 0.530581  [20800/525306]\n",
      "loss: 0.743548  [22400/525306]\n",
      "loss: 0.699351  [24000/525306]\n",
      "loss: 1.061318  [25600/525306]\n",
      "loss: 0.956487  [27200/525306]\n",
      "loss: 0.891059  [28800/525306]\n",
      "loss: 0.528102  [30400/525306]\n",
      "loss: 0.860568  [32000/525306]\n",
      "loss: 1.197901  [33600/525306]\n",
      "loss: 0.769581  [35200/525306]\n",
      "loss: 1.341728  [36800/525306]\n",
      "loss: 0.615927  [38400/525306]\n",
      "loss: 0.802348  [40000/525306]\n",
      "loss: 0.537231  [41600/525306]\n",
      "loss: 0.902435  [43200/525306]\n",
      "loss: 0.390947  [44800/525306]\n",
      "loss: 0.706940  [46400/525306]\n",
      "loss: 0.895663  [48000/525306]\n",
      "loss: 0.893602  [49600/525306]\n",
      "loss: 0.519940  [51200/525306]\n",
      "loss: 0.337747  [52800/525306]\n",
      "loss: 0.962735  [54400/525306]\n",
      "loss: 0.542472  [56000/525306]\n",
      "loss: 0.951958  [57600/525306]\n",
      "loss: 0.588978  [59200/525306]\n",
      "loss: 0.465052  [60800/525306]\n",
      "loss: 0.548177  [62400/525306]\n",
      "loss: 0.601653  [64000/525306]\n",
      "loss: 0.919844  [65600/525306]\n",
      "loss: 0.933782  [67200/525306]\n",
      "loss: 0.636654  [68800/525306]\n",
      "loss: 0.323447  [70400/525306]\n",
      "loss: 1.277190  [72000/525306]\n",
      "loss: 0.855582  [73600/525306]\n",
      "loss: 0.593125  [75200/525306]\n",
      "loss: 1.151941  [76800/525306]\n",
      "loss: 0.871523  [78400/525306]\n",
      "loss: 0.656418  [80000/525306]\n",
      "loss: 0.551076  [81600/525306]\n",
      "loss: 0.648656  [83200/525306]\n",
      "loss: 0.933035  [84800/525306]\n",
      "loss: 0.347191  [86400/525306]\n",
      "loss: 0.783630  [88000/525306]\n",
      "loss: 0.553296  [89600/525306]\n",
      "loss: 0.820576  [91200/525306]\n",
      "loss: 0.708784  [92800/525306]\n",
      "loss: 0.375556  [94400/525306]\n",
      "loss: 0.757705  [96000/525306]\n",
      "loss: 0.509087  [97600/525306]\n",
      "loss: 0.399188  [99200/525306]\n",
      "loss: 1.042811  [100800/525306]\n",
      "loss: 0.716160  [102400/525306]\n",
      "loss: 0.762763  [104000/525306]\n",
      "loss: 0.636523  [105600/525306]\n",
      "loss: 0.809097  [107200/525306]\n",
      "loss: 0.320272  [108800/525306]\n",
      "loss: 1.371830  [110400/525306]\n",
      "loss: 0.906934  [112000/525306]\n",
      "loss: 0.743888  [113600/525306]\n",
      "loss: 0.773799  [115200/525306]\n",
      "loss: 1.067793  [116800/525306]\n",
      "loss: 0.777297  [118400/525306]\n",
      "loss: 0.510665  [120000/525306]\n",
      "loss: 0.897723  [121600/525306]\n",
      "loss: 0.918404  [123200/525306]\n",
      "loss: 0.911712  [124800/525306]\n",
      "loss: 0.784924  [126400/525306]\n",
      "loss: 0.898610  [128000/525306]\n",
      "loss: 0.893644  [129600/525306]\n",
      "loss: 0.591542  [131200/525306]\n",
      "loss: 0.684442  [132800/525306]\n",
      "loss: 0.690405  [134400/525306]\n",
      "loss: 0.584647  [136000/525306]\n",
      "loss: 0.391924  [137600/525306]\n",
      "loss: 1.048690  [139200/525306]\n",
      "loss: 0.733126  [140800/525306]\n",
      "loss: 0.899046  [142400/525306]\n",
      "loss: 0.869112  [144000/525306]\n",
      "loss: 0.566097  [145600/525306]\n",
      "loss: 0.721136  [147200/525306]\n",
      "loss: 1.061598  [148800/525306]\n",
      "loss: 0.917927  [150400/525306]\n",
      "loss: 0.517028  [152000/525306]\n",
      "loss: 1.074332  [153600/525306]\n",
      "loss: 0.642493  [155200/525306]\n",
      "loss: 0.706362  [156800/525306]\n",
      "loss: 0.679011  [158400/525306]\n",
      "loss: 0.736266  [160000/525306]\n",
      "loss: 0.948399  [161600/525306]\n",
      "loss: 1.126637  [163200/525306]\n",
      "loss: 0.512565  [164800/525306]\n",
      "loss: 0.921315  [166400/525306]\n",
      "loss: 0.900784  [168000/525306]\n",
      "loss: 0.686480  [169600/525306]\n",
      "loss: 0.993685  [171200/525306]\n",
      "loss: 1.104882  [172800/525306]\n",
      "loss: 1.003126  [174400/525306]\n",
      "loss: 1.122881  [176000/525306]\n",
      "loss: 0.811565  [177600/525306]\n",
      "loss: 1.183076  [179200/525306]\n",
      "loss: 1.247263  [180800/525306]\n",
      "loss: 0.876267  [182400/525306]\n",
      "loss: 0.588325  [184000/525306]\n",
      "loss: 0.680225  [185600/525306]\n",
      "loss: 0.562855  [187200/525306]\n",
      "loss: 1.031743  [188800/525306]\n",
      "loss: 0.539377  [190400/525306]\n",
      "loss: 0.891843  [192000/525306]\n",
      "loss: 1.019514  [193600/525306]\n",
      "loss: 0.685097  [195200/525306]\n",
      "loss: 0.644053  [196800/525306]\n",
      "loss: 0.542934  [198400/525306]\n",
      "loss: 0.448036  [200000/525306]\n",
      "loss: 0.577978  [201600/525306]\n",
      "loss: 0.697416  [203200/525306]\n",
      "loss: 0.573553  [204800/525306]\n",
      "loss: 0.595629  [206400/525306]\n",
      "loss: 0.487591  [208000/525306]\n",
      "loss: 0.978215  [209600/525306]\n",
      "loss: 1.013249  [211200/525306]\n",
      "loss: 0.806280  [212800/525306]\n",
      "loss: 0.576321  [214400/525306]\n",
      "loss: 0.600525  [216000/525306]\n",
      "loss: 1.280938  [217600/525306]\n",
      "loss: 1.384085  [219200/525306]\n",
      "loss: 0.351158  [220800/525306]\n",
      "loss: 0.800846  [222400/525306]\n",
      "loss: 0.512972  [224000/525306]\n",
      "loss: 1.313313  [225600/525306]\n",
      "loss: 0.890950  [227200/525306]\n",
      "loss: 0.457055  [228800/525306]\n",
      "loss: 0.797789  [230400/525306]\n",
      "loss: 0.599576  [232000/525306]\n",
      "loss: 0.639203  [233600/525306]\n",
      "loss: 1.065560  [235200/525306]\n",
      "loss: 0.787168  [236800/525306]\n",
      "loss: 0.728061  [238400/525306]\n",
      "loss: 1.141656  [240000/525306]\n",
      "loss: 1.152048  [241600/525306]\n",
      "loss: 0.667980  [243200/525306]\n",
      "loss: 1.175219  [244800/525306]\n",
      "loss: 0.500455  [246400/525306]\n",
      "loss: 1.110502  [248000/525306]\n",
      "loss: 0.678184  [249600/525306]\n",
      "loss: 1.123316  [251200/525306]\n",
      "loss: 0.902887  [252800/525306]\n",
      "loss: 0.844629  [254400/525306]\n",
      "loss: 0.778487  [256000/525306]\n",
      "loss: 0.781524  [257600/525306]\n",
      "loss: 0.620802  [259200/525306]\n",
      "loss: 0.759337  [260800/525306]\n",
      "loss: 0.451591  [262400/525306]\n",
      "loss: 0.810192  [264000/525306]\n",
      "loss: 1.166479  [265600/525306]\n",
      "loss: 0.716588  [267200/525306]\n",
      "loss: 1.071924  [268800/525306]\n",
      "loss: 0.691550  [270400/525306]\n",
      "loss: 1.121635  [272000/525306]\n",
      "loss: 0.760329  [273600/525306]\n",
      "loss: 0.540781  [275200/525306]\n",
      "loss: 0.930526  [276800/525306]\n",
      "loss: 0.870124  [278400/525306]\n",
      "loss: 0.837920  [280000/525306]\n",
      "loss: 0.723903  [281600/525306]\n",
      "loss: 0.759333  [283200/525306]\n",
      "loss: 1.261903  [284800/525306]\n",
      "loss: 0.580630  [286400/525306]\n",
      "loss: 0.677652  [288000/525306]\n",
      "loss: 1.492517  [289600/525306]\n",
      "loss: 0.807069  [291200/525306]\n",
      "loss: 0.559589  [292800/525306]\n",
      "loss: 0.628598  [294400/525306]\n",
      "loss: 1.463387  [296000/525306]\n",
      "loss: 0.936675  [297600/525306]\n",
      "loss: 0.816590  [299200/525306]\n",
      "loss: 0.994108  [300800/525306]\n",
      "loss: 0.729963  [302400/525306]\n",
      "loss: 0.760418  [304000/525306]\n",
      "loss: 1.206980  [305600/525306]\n",
      "loss: 0.658416  [307200/525306]\n",
      "loss: 0.841248  [308800/525306]\n",
      "loss: 1.020287  [310400/525306]\n",
      "loss: 0.619262  [312000/525306]\n",
      "loss: 0.693209  [313600/525306]\n",
      "loss: 0.595574  [315200/525306]\n",
      "loss: 0.844904  [316800/525306]\n",
      "loss: 0.797271  [318400/525306]\n",
      "loss: 0.841882  [320000/525306]\n",
      "loss: 0.576051  [321600/525306]\n",
      "loss: 0.399403  [323200/525306]\n",
      "loss: 0.437787  [324800/525306]\n",
      "loss: 0.815702  [326400/525306]\n",
      "loss: 0.421345  [328000/525306]\n",
      "loss: 1.009653  [329600/525306]\n",
      "loss: 0.857132  [331200/525306]\n",
      "loss: 1.110460  [332800/525306]\n",
      "loss: 0.686294  [334400/525306]\n",
      "loss: 0.720575  [336000/525306]\n",
      "loss: 0.540784  [337600/525306]\n",
      "loss: 0.612373  [339200/525306]\n",
      "loss: 0.742241  [340800/525306]\n",
      "loss: 0.982440  [342400/525306]\n",
      "loss: 0.552447  [344000/525306]\n",
      "loss: 0.885676  [345600/525306]\n",
      "loss: 0.435992  [347200/525306]\n",
      "loss: 0.859106  [348800/525306]\n",
      "loss: 0.540321  [350400/525306]\n",
      "loss: 0.786060  [352000/525306]\n",
      "loss: 0.863137  [353600/525306]\n",
      "loss: 0.775391  [355200/525306]\n",
      "loss: 1.272613  [356800/525306]\n",
      "loss: 0.708037  [358400/525306]\n",
      "loss: 0.313721  [360000/525306]\n",
      "loss: 0.571588  [361600/525306]\n",
      "loss: 1.088083  [363200/525306]\n",
      "loss: 0.479938  [364800/525306]\n",
      "loss: 0.697282  [366400/525306]\n",
      "loss: 1.071250  [368000/525306]\n",
      "loss: 0.661645  [369600/525306]\n",
      "loss: 1.050379  [371200/525306]\n",
      "loss: 1.169313  [372800/525306]\n",
      "loss: 0.781990  [374400/525306]\n",
      "loss: 0.738745  [376000/525306]\n",
      "loss: 0.687631  [377600/525306]\n",
      "loss: 0.842630  [379200/525306]\n",
      "loss: 0.608210  [380800/525306]\n",
      "loss: 1.152091  [382400/525306]\n",
      "loss: 0.968651  [384000/525306]\n",
      "loss: 0.612813  [385600/525306]\n",
      "loss: 0.666806  [387200/525306]\n",
      "loss: 1.425527  [388800/525306]\n",
      "loss: 0.683475  [390400/525306]\n",
      "loss: 0.793905  [392000/525306]\n",
      "loss: 0.997826  [393600/525306]\n",
      "loss: 1.194588  [395200/525306]\n",
      "loss: 0.678947  [396800/525306]\n",
      "loss: 0.703164  [398400/525306]\n",
      "loss: 0.600969  [400000/525306]\n",
      "loss: 0.779029  [401600/525306]\n",
      "loss: 0.781577  [403200/525306]\n",
      "loss: 0.808005  [404800/525306]\n",
      "loss: 0.536327  [406400/525306]\n",
      "loss: 0.392722  [408000/525306]\n",
      "loss: 0.731146  [409600/525306]\n",
      "loss: 0.796615  [411200/525306]\n",
      "loss: 0.959082  [412800/525306]\n",
      "loss: 1.089885  [414400/525306]\n",
      "loss: 1.072547  [416000/525306]\n",
      "loss: 1.282856  [417600/525306]\n",
      "loss: 0.568733  [419200/525306]\n",
      "loss: 0.906286  [420800/525306]\n",
      "loss: 1.083670  [422400/525306]\n",
      "loss: 1.019341  [424000/525306]\n",
      "loss: 0.485816  [425600/525306]\n",
      "loss: 0.894605  [427200/525306]\n",
      "loss: 0.796539  [428800/525306]\n",
      "loss: 0.792866  [430400/525306]\n",
      "loss: 1.170201  [432000/525306]\n",
      "loss: 0.632061  [433600/525306]\n",
      "loss: 1.391401  [435200/525306]\n",
      "loss: 0.824203  [436800/525306]\n",
      "loss: 0.611582  [438400/525306]\n",
      "loss: 0.498474  [440000/525306]\n",
      "loss: 0.741131  [441600/525306]\n",
      "loss: 0.517987  [443200/525306]\n",
      "loss: 0.929218  [444800/525306]\n",
      "loss: 0.579676  [446400/525306]\n",
      "loss: 0.530245  [448000/525306]\n",
      "loss: 1.238179  [449600/525306]\n",
      "loss: 0.787467  [451200/525306]\n",
      "loss: 0.671697  [452800/525306]\n",
      "loss: 0.939919  [454400/525306]\n",
      "loss: 0.714913  [456000/525306]\n",
      "loss: 0.689899  [457600/525306]\n",
      "loss: 0.576919  [459200/525306]\n",
      "loss: 1.008959  [460800/525306]\n",
      "loss: 0.586071  [462400/525306]\n",
      "loss: 1.387347  [464000/525306]\n",
      "loss: 0.811607  [465600/525306]\n",
      "loss: 0.626273  [467200/525306]\n",
      "loss: 0.906526  [468800/525306]\n",
      "loss: 1.127607  [470400/525306]\n",
      "loss: 1.184217  [472000/525306]\n",
      "loss: 1.058430  [473600/525306]\n",
      "loss: 0.597682  [475200/525306]\n",
      "loss: 1.180038  [476800/525306]\n",
      "loss: 0.757270  [478400/525306]\n",
      "loss: 0.793147  [480000/525306]\n",
      "loss: 0.644342  [481600/525306]\n",
      "loss: 0.431614  [483200/525306]\n",
      "loss: 0.784761  [484800/525306]\n",
      "loss: 0.408723  [486400/525306]\n",
      "loss: 0.555931  [488000/525306]\n",
      "loss: 1.284562  [489600/525306]\n",
      "loss: 1.491262  [491200/525306]\n",
      "loss: 1.092159  [492800/525306]\n",
      "loss: 0.954348  [494400/525306]\n",
      "loss: 1.095327  [496000/525306]\n",
      "loss: 0.714235  [497600/525306]\n",
      "loss: 0.762847  [499200/525306]\n",
      "loss: 0.808033  [500800/525306]\n",
      "loss: 0.623715  [502400/525306]\n",
      "loss: 0.806916  [504000/525306]\n",
      "loss: 0.629455  [505600/525306]\n",
      "loss: 0.586271  [507200/525306]\n",
      "loss: 1.171301  [508800/525306]\n",
      "loss: 1.452337  [510400/525306]\n",
      "loss: 0.648568  [512000/525306]\n",
      "loss: 0.454651  [513600/525306]\n",
      "loss: 0.848502  [515200/525306]\n",
      "loss: 0.691035  [516800/525306]\n",
      "loss: 0.991947  [518400/525306]\n",
      "loss: 1.012112  [520000/525306]\n",
      "loss: 0.977793  [521600/525306]\n",
      "loss: 1.360718  [523200/525306]\n",
      "loss: 0.886637  [524800/525306]\n",
      "Train Accuracy: 70.3253%\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.957526, F1-score: 67.77%, Macro_F1-Score:  37.65%  \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.806475  [    0/525306]\n",
      "loss: 0.684060  [ 1600/525306]\n",
      "loss: 1.121810  [ 3200/525306]\n",
      "loss: 0.585674  [ 4800/525306]\n",
      "loss: 1.193075  [ 6400/525306]\n",
      "loss: 0.533014  [ 8000/525306]\n",
      "loss: 0.397531  [ 9600/525306]\n",
      "loss: 0.690156  [11200/525306]\n",
      "loss: 0.607677  [12800/525306]\n",
      "loss: 0.459068  [14400/525306]\n",
      "loss: 0.545640  [16000/525306]\n",
      "loss: 1.511051  [17600/525306]\n",
      "loss: 1.277904  [19200/525306]\n",
      "loss: 0.616568  [20800/525306]\n",
      "loss: 0.890338  [22400/525306]\n",
      "loss: 0.884003  [24000/525306]\n",
      "loss: 0.148484  [25600/525306]\n",
      "loss: 0.535176  [27200/525306]\n",
      "loss: 1.378716  [28800/525306]\n",
      "loss: 0.892815  [30400/525306]\n",
      "loss: 0.889434  [32000/525306]\n",
      "loss: 0.628738  [33600/525306]\n",
      "loss: 0.894602  [35200/525306]\n",
      "loss: 0.724961  [36800/525306]\n",
      "loss: 0.854212  [38400/525306]\n",
      "loss: 1.090951  [40000/525306]\n",
      "loss: 0.374742  [41600/525306]\n",
      "loss: 1.003139  [43200/525306]\n",
      "loss: 0.952078  [44800/525306]\n",
      "loss: 0.618484  [46400/525306]\n",
      "loss: 1.234031  [48000/525306]\n",
      "loss: 0.573277  [49600/525306]\n",
      "loss: 0.687587  [51200/525306]\n",
      "loss: 1.048423  [52800/525306]\n",
      "loss: 0.958958  [54400/525306]\n",
      "loss: 0.653688  [56000/525306]\n",
      "loss: 0.530185  [57600/525306]\n",
      "loss: 0.523079  [59200/525306]\n",
      "loss: 0.830802  [60800/525306]\n",
      "loss: 1.323013  [62400/525306]\n",
      "loss: 0.971173  [64000/525306]\n",
      "loss: 0.551803  [65600/525306]\n",
      "loss: 0.681571  [67200/525306]\n",
      "loss: 0.889527  [68800/525306]\n",
      "loss: 0.964478  [70400/525306]\n",
      "loss: 0.752889  [72000/525306]\n",
      "loss: 0.866190  [73600/525306]\n",
      "loss: 0.647306  [75200/525306]\n",
      "loss: 0.847608  [76800/525306]\n",
      "loss: 0.790424  [78400/525306]\n",
      "loss: 1.103940  [80000/525306]\n",
      "loss: 0.688630  [81600/525306]\n",
      "loss: 0.924894  [83200/525306]\n",
      "loss: 0.772844  [84800/525306]\n",
      "loss: 0.256486  [86400/525306]\n",
      "loss: 0.615601  [88000/525306]\n",
      "loss: 0.720783  [89600/525306]\n",
      "loss: 0.671126  [91200/525306]\n",
      "loss: 0.761824  [92800/525306]\n",
      "loss: 0.581435  [94400/525306]\n",
      "loss: 0.491248  [96000/525306]\n",
      "loss: 0.920203  [97600/525306]\n",
      "loss: 0.564062  [99200/525306]\n",
      "loss: 0.699142  [100800/525306]\n",
      "loss: 0.678031  [102400/525306]\n",
      "loss: 0.863578  [104000/525306]\n",
      "loss: 0.703143  [105600/525306]\n",
      "loss: 1.046996  [107200/525306]\n",
      "loss: 1.323110  [108800/525306]\n",
      "loss: 1.338040  [110400/525306]\n",
      "loss: 0.756051  [112000/525306]\n",
      "loss: 0.783530  [113600/525306]\n",
      "loss: 0.789245  [115200/525306]\n",
      "loss: 0.707008  [116800/525306]\n",
      "loss: 1.009535  [118400/525306]\n",
      "loss: 0.649408  [120000/525306]\n",
      "loss: 0.628062  [121600/525306]\n",
      "loss: 0.930765  [123200/525306]\n",
      "loss: 0.728091  [124800/525306]\n",
      "loss: 1.115162  [126400/525306]\n",
      "loss: 0.826206  [128000/525306]\n",
      "loss: 1.039492  [129600/525306]\n",
      "loss: 1.182333  [131200/525306]\n",
      "loss: 0.324082  [132800/525306]\n",
      "loss: 1.027135  [134400/525306]\n",
      "loss: 0.786240  [136000/525306]\n",
      "loss: 0.568704  [137600/525306]\n",
      "loss: 0.601926  [139200/525306]\n",
      "loss: 0.897561  [140800/525306]\n",
      "loss: 0.447753  [142400/525306]\n",
      "loss: 0.950468  [144000/525306]\n",
      "loss: 0.322003  [145600/525306]\n",
      "loss: 0.575972  [147200/525306]\n",
      "loss: 0.920974  [148800/525306]\n",
      "loss: 0.714401  [150400/525306]\n",
      "loss: 1.358347  [152000/525306]\n",
      "loss: 0.270994  [153600/525306]\n",
      "loss: 0.747984  [155200/525306]\n",
      "loss: 0.586862  [156800/525306]\n",
      "loss: 0.539270  [158400/525306]\n",
      "loss: 0.860454  [160000/525306]\n",
      "loss: 0.733169  [161600/525306]\n",
      "loss: 0.709589  [163200/525306]\n",
      "loss: 1.088271  [164800/525306]\n",
      "loss: 0.856293  [166400/525306]\n",
      "loss: 0.913432  [168000/525306]\n",
      "loss: 0.560560  [169600/525306]\n",
      "loss: 0.621529  [171200/525306]\n",
      "loss: 0.404969  [172800/525306]\n",
      "loss: 0.803969  [174400/525306]\n",
      "loss: 0.768771  [176000/525306]\n",
      "loss: 0.669967  [177600/525306]\n",
      "loss: 0.480666  [179200/525306]\n",
      "loss: 1.156656  [180800/525306]\n",
      "loss: 0.651807  [182400/525306]\n",
      "loss: 0.557839  [184000/525306]\n",
      "loss: 0.462012  [185600/525306]\n",
      "loss: 0.844916  [187200/525306]\n",
      "loss: 0.598073  [188800/525306]\n",
      "loss: 0.910031  [190400/525306]\n",
      "loss: 0.845956  [192000/525306]\n",
      "loss: 0.989408  [193600/525306]\n",
      "loss: 0.919631  [195200/525306]\n",
      "loss: 0.956368  [196800/525306]\n",
      "loss: 0.714598  [198400/525306]\n",
      "loss: 0.610327  [200000/525306]\n",
      "loss: 0.824817  [201600/525306]\n",
      "loss: 0.544940  [203200/525306]\n",
      "loss: 1.071315  [204800/525306]\n",
      "loss: 0.857854  [206400/525306]\n",
      "loss: 1.028994  [208000/525306]\n",
      "loss: 1.065559  [209600/525306]\n",
      "loss: 0.952671  [211200/525306]\n",
      "loss: 0.565985  [212800/525306]\n",
      "loss: 0.675976  [214400/525306]\n",
      "loss: 0.923734  [216000/525306]\n",
      "loss: 0.864737  [217600/525306]\n",
      "loss: 1.665043  [219200/525306]\n",
      "loss: 0.552504  [220800/525306]\n",
      "loss: 0.754371  [222400/525306]\n",
      "loss: 0.907760  [224000/525306]\n",
      "loss: 0.794176  [225600/525306]\n",
      "loss: 0.970143  [227200/525306]\n",
      "loss: 0.850871  [228800/525306]\n",
      "loss: 0.445915  [230400/525306]\n",
      "loss: 0.550568  [232000/525306]\n",
      "loss: 0.878554  [233600/525306]\n",
      "loss: 1.194690  [235200/525306]\n",
      "loss: 0.744465  [236800/525306]\n",
      "loss: 0.916905  [238400/525306]\n",
      "loss: 0.918172  [240000/525306]\n",
      "loss: 0.371829  [241600/525306]\n",
      "loss: 0.228796  [243200/525306]\n",
      "loss: 0.946355  [244800/525306]\n",
      "loss: 1.060483  [246400/525306]\n",
      "loss: 0.421837  [248000/525306]\n",
      "loss: 1.122580  [249600/525306]\n",
      "loss: 1.017686  [251200/525306]\n",
      "loss: 0.779792  [252800/525306]\n",
      "loss: 0.815292  [254400/525306]\n",
      "loss: 0.957922  [256000/525306]\n",
      "loss: 0.513193  [257600/525306]\n",
      "loss: 0.736727  [259200/525306]\n",
      "loss: 0.849196  [260800/525306]\n",
      "loss: 0.849313  [262400/525306]\n",
      "loss: 0.777326  [264000/525306]\n",
      "loss: 0.461414  [265600/525306]\n",
      "loss: 0.877724  [267200/525306]\n",
      "loss: 0.539741  [268800/525306]\n",
      "loss: 0.994293  [270400/525306]\n",
      "loss: 0.783615  [272000/525306]\n",
      "loss: 0.403528  [273600/525306]\n",
      "loss: 1.189273  [275200/525306]\n",
      "loss: 0.889058  [276800/525306]\n",
      "loss: 1.036052  [278400/525306]\n",
      "loss: 0.605948  [280000/525306]\n",
      "loss: 0.669748  [281600/525306]\n",
      "loss: 0.938918  [283200/525306]\n",
      "loss: 1.036620  [284800/525306]\n",
      "loss: 0.569875  [286400/525306]\n",
      "loss: 0.524157  [288000/525306]\n",
      "loss: 0.391424  [289600/525306]\n",
      "loss: 0.434636  [291200/525306]\n",
      "loss: 0.581625  [292800/525306]\n",
      "loss: 1.127210  [294400/525306]\n",
      "loss: 0.507035  [296000/525306]\n",
      "loss: 0.980401  [297600/525306]\n",
      "loss: 1.028617  [299200/525306]\n",
      "loss: 0.827895  [300800/525306]\n",
      "loss: 0.962461  [302400/525306]\n",
      "loss: 0.867289  [304000/525306]\n",
      "loss: 1.222636  [305600/525306]\n",
      "loss: 1.005095  [307200/525306]\n",
      "loss: 1.304212  [308800/525306]\n",
      "loss: 0.305786  [310400/525306]\n",
      "loss: 0.470622  [312000/525306]\n",
      "loss: 1.120855  [313600/525306]\n",
      "loss: 0.841866  [315200/525306]\n",
      "loss: 0.976893  [316800/525306]\n",
      "loss: 0.510874  [318400/525306]\n",
      "loss: 0.683860  [320000/525306]\n",
      "loss: 0.660088  [321600/525306]\n",
      "loss: 1.319247  [323200/525306]\n",
      "loss: 0.807287  [324800/525306]\n",
      "loss: 0.510879  [326400/525306]\n",
      "loss: 0.474009  [328000/525306]\n",
      "loss: 1.147819  [329600/525306]\n",
      "loss: 0.831893  [331200/525306]\n",
      "loss: 1.042464  [332800/525306]\n",
      "loss: 0.752100  [334400/525306]\n",
      "loss: 0.543804  [336000/525306]\n",
      "loss: 0.908714  [337600/525306]\n",
      "loss: 0.638725  [339200/525306]\n",
      "loss: 0.984945  [340800/525306]\n",
      "loss: 0.517695  [342400/525306]\n",
      "loss: 0.935513  [344000/525306]\n",
      "loss: 0.630419  [345600/525306]\n",
      "loss: 0.498102  [347200/525306]\n",
      "loss: 1.027611  [348800/525306]\n",
      "loss: 0.995127  [350400/525306]\n",
      "loss: 1.169024  [352000/525306]\n",
      "loss: 0.607324  [353600/525306]\n",
      "loss: 0.797481  [355200/525306]\n",
      "loss: 0.929241  [356800/525306]\n",
      "loss: 1.021087  [358400/525306]\n",
      "loss: 0.926626  [360000/525306]\n",
      "loss: 0.711959  [361600/525306]\n",
      "loss: 0.810321  [363200/525306]\n",
      "loss: 0.759218  [364800/525306]\n",
      "loss: 1.104247  [366400/525306]\n",
      "loss: 1.015640  [368000/525306]\n",
      "loss: 0.953829  [369600/525306]\n",
      "loss: 1.018782  [371200/525306]\n",
      "loss: 0.418615  [372800/525306]\n",
      "loss: 0.529578  [374400/525306]\n",
      "loss: 1.012590  [376000/525306]\n",
      "loss: 0.640024  [377600/525306]\n",
      "loss: 0.600770  [379200/525306]\n",
      "loss: 0.814431  [380800/525306]\n",
      "loss: 1.006185  [382400/525306]\n",
      "loss: 0.696254  [384000/525306]\n",
      "loss: 0.779465  [385600/525306]\n",
      "loss: 0.862866  [387200/525306]\n",
      "loss: 0.975767  [388800/525306]\n",
      "loss: 0.727244  [390400/525306]\n",
      "loss: 0.568572  [392000/525306]\n",
      "loss: 0.998813  [393600/525306]\n",
      "loss: 0.884959  [395200/525306]\n",
      "loss: 0.566416  [396800/525306]\n",
      "loss: 0.768690  [398400/525306]\n",
      "loss: 1.185525  [400000/525306]\n",
      "loss: 0.901299  [401600/525306]\n",
      "loss: 0.688532  [403200/525306]\n",
      "loss: 0.790716  [404800/525306]\n",
      "loss: 0.954305  [406400/525306]\n",
      "loss: 0.648863  [408000/525306]\n",
      "loss: 0.914447  [409600/525306]\n",
      "loss: 0.607639  [411200/525306]\n",
      "loss: 0.460679  [412800/525306]\n",
      "loss: 1.256844  [414400/525306]\n",
      "loss: 0.877547  [416000/525306]\n",
      "loss: 0.555230  [417600/525306]\n",
      "loss: 0.799186  [419200/525306]\n",
      "loss: 0.762280  [420800/525306]\n",
      "loss: 0.251230  [422400/525306]\n",
      "loss: 0.831028  [424000/525306]\n",
      "loss: 0.952128  [425600/525306]\n",
      "loss: 0.855681  [427200/525306]\n",
      "loss: 0.896544  [428800/525306]\n",
      "loss: 0.708667  [430400/525306]\n",
      "loss: 0.881272  [432000/525306]\n",
      "loss: 0.673064  [433600/525306]\n",
      "loss: 0.570186  [435200/525306]\n",
      "loss: 1.319511  [436800/525306]\n",
      "loss: 0.659006  [438400/525306]\n",
      "loss: 0.666083  [440000/525306]\n",
      "loss: 0.521946  [441600/525306]\n",
      "loss: 0.988953  [443200/525306]\n",
      "loss: 1.069673  [444800/525306]\n",
      "loss: 0.475179  [446400/525306]\n",
      "loss: 0.687529  [448000/525306]\n",
      "loss: 0.796177  [449600/525306]\n",
      "loss: 0.826151  [451200/525306]\n",
      "loss: 0.556549  [452800/525306]\n",
      "loss: 1.060574  [454400/525306]\n",
      "loss: 0.620494  [456000/525306]\n",
      "loss: 0.440763  [457600/525306]\n",
      "loss: 0.663356  [459200/525306]\n",
      "loss: 0.725520  [460800/525306]\n",
      "loss: 0.944263  [462400/525306]\n",
      "loss: 0.587233  [464000/525306]\n",
      "loss: 0.315419  [465600/525306]\n",
      "loss: 0.693240  [467200/525306]\n",
      "loss: 0.512909  [468800/525306]\n",
      "loss: 0.751097  [470400/525306]\n",
      "loss: 0.717652  [472000/525306]\n",
      "loss: 0.932730  [473600/525306]\n",
      "loss: 0.872297  [475200/525306]\n",
      "loss: 1.019377  [476800/525306]\n",
      "loss: 0.974733  [478400/525306]\n",
      "loss: 0.587968  [480000/525306]\n",
      "loss: 1.040877  [481600/525306]\n",
      "loss: 0.987167  [483200/525306]\n",
      "loss: 1.123624  [484800/525306]\n",
      "loss: 0.641296  [486400/525306]\n",
      "loss: 0.800433  [488000/525306]\n",
      "loss: 0.497695  [489600/525306]\n",
      "loss: 0.793606  [491200/525306]\n",
      "loss: 0.530317  [492800/525306]\n",
      "loss: 0.594761  [494400/525306]\n",
      "loss: 0.537259  [496000/525306]\n",
      "loss: 0.635888  [497600/525306]\n",
      "loss: 1.717288  [499200/525306]\n",
      "loss: 0.655470  [500800/525306]\n",
      "loss: 1.125728  [502400/525306]\n",
      "loss: 0.700372  [504000/525306]\n",
      "loss: 0.448333  [505600/525306]\n",
      "loss: 0.656565  [507200/525306]\n",
      "loss: 0.839045  [508800/525306]\n",
      "loss: 0.585380  [510400/525306]\n",
      "loss: 0.674000  [512000/525306]\n",
      "loss: 0.559574  [513600/525306]\n",
      "loss: 0.549961  [515200/525306]\n",
      "loss: 0.857895  [516800/525306]\n",
      "loss: 0.888406  [518400/525306]\n",
      "loss: 0.872000  [520000/525306]\n",
      "loss: 0.628258  [521600/525306]\n",
      "loss: 0.621871  [523200/525306]\n",
      "loss: 0.442724  [524800/525306]\n",
      "Train Accuracy: 70.4656%\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 0.981933, F1-score: 67.79%, Macro_F1-Score:  37.63%  \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.750911  [    0/525306]\n",
      "loss: 0.919269  [ 1600/525306]\n",
      "loss: 0.933137  [ 3200/525306]\n",
      "loss: 0.760997  [ 4800/525306]\n",
      "loss: 0.950521  [ 6400/525306]\n",
      "loss: 0.778296  [ 8000/525306]\n",
      "loss: 0.432140  [ 9600/525306]\n",
      "loss: 1.279316  [11200/525306]\n",
      "loss: 0.803568  [12800/525306]\n",
      "loss: 0.547806  [14400/525306]\n",
      "loss: 0.729706  [16000/525306]\n",
      "loss: 0.742212  [17600/525306]\n",
      "loss: 0.937989  [19200/525306]\n",
      "loss: 0.568536  [20800/525306]\n",
      "loss: 1.286675  [22400/525306]\n",
      "loss: 0.813755  [24000/525306]\n",
      "loss: 0.807217  [25600/525306]\n",
      "loss: 0.485961  [27200/525306]\n",
      "loss: 0.865335  [28800/525306]\n",
      "loss: 0.708269  [30400/525306]\n",
      "loss: 0.630127  [32000/525306]\n",
      "loss: 0.684045  [33600/525306]\n",
      "loss: 0.446839  [35200/525306]\n",
      "loss: 1.312859  [36800/525306]\n",
      "loss: 0.573819  [38400/525306]\n",
      "loss: 0.604630  [40000/525306]\n",
      "loss: 0.466462  [41600/525306]\n",
      "loss: 0.285743  [43200/525306]\n",
      "loss: 0.528338  [44800/525306]\n",
      "loss: 0.933831  [46400/525306]\n",
      "loss: 0.479184  [48000/525306]\n",
      "loss: 1.568969  [49600/525306]\n",
      "loss: 0.944524  [51200/525306]\n",
      "loss: 0.793824  [52800/525306]\n",
      "loss: 0.372556  [54400/525306]\n",
      "loss: 1.699318  [56000/525306]\n",
      "loss: 0.915878  [57600/525306]\n",
      "loss: 1.339827  [59200/525306]\n",
      "loss: 1.105266  [60800/525306]\n",
      "loss: 0.941788  [62400/525306]\n",
      "loss: 0.776571  [64000/525306]\n",
      "loss: 0.802810  [65600/525306]\n",
      "loss: 1.137441  [67200/525306]\n",
      "loss: 0.548523  [68800/525306]\n",
      "loss: 1.394255  [70400/525306]\n",
      "loss: 0.674395  [72000/525306]\n",
      "loss: 0.502594  [73600/525306]\n",
      "loss: 1.083627  [75200/525306]\n",
      "loss: 1.082843  [76800/525306]\n",
      "loss: 0.676991  [78400/525306]\n",
      "loss: 1.087469  [80000/525306]\n",
      "loss: 0.523901  [81600/525306]\n",
      "loss: 0.721632  [83200/525306]\n",
      "loss: 0.712611  [84800/525306]\n",
      "loss: 0.704990  [86400/525306]\n",
      "loss: 0.703800  [88000/525306]\n",
      "loss: 1.102802  [89600/525306]\n",
      "loss: 0.832777  [91200/525306]\n",
      "loss: 1.292894  [92800/525306]\n",
      "loss: 0.684578  [94400/525306]\n",
      "loss: 0.438954  [96000/525306]\n",
      "loss: 1.114600  [97600/525306]\n",
      "loss: 0.564711  [99200/525306]\n",
      "loss: 0.542374  [100800/525306]\n",
      "loss: 0.688205  [102400/525306]\n",
      "loss: 1.087268  [104000/525306]\n",
      "loss: 0.758692  [105600/525306]\n",
      "loss: 0.983014  [107200/525306]\n",
      "loss: 0.857670  [108800/525306]\n",
      "loss: 0.799735  [110400/525306]\n",
      "loss: 1.312759  [112000/525306]\n",
      "loss: 0.763989  [113600/525306]\n",
      "loss: 1.085646  [115200/525306]\n",
      "loss: 0.650007  [116800/525306]\n",
      "loss: 1.789732  [118400/525306]\n",
      "loss: 0.843970  [120000/525306]\n",
      "loss: 0.728054  [121600/525306]\n",
      "loss: 0.875953  [123200/525306]\n",
      "loss: 0.850322  [124800/525306]\n",
      "loss: 0.709124  [126400/525306]\n",
      "loss: 0.785195  [128000/525306]\n",
      "loss: 0.507519  [129600/525306]\n",
      "loss: 0.697723  [131200/525306]\n",
      "loss: 1.081674  [132800/525306]\n",
      "loss: 0.742095  [134400/525306]\n",
      "loss: 0.537581  [136000/525306]\n",
      "loss: 0.531625  [137600/525306]\n",
      "loss: 0.421569  [139200/525306]\n",
      "loss: 0.914663  [140800/525306]\n",
      "loss: 0.832127  [142400/525306]\n",
      "loss: 1.080713  [144000/525306]\n",
      "loss: 0.816852  [145600/525306]\n",
      "loss: 0.477459  [147200/525306]\n",
      "loss: 0.539635  [148800/525306]\n",
      "loss: 0.690179  [150400/525306]\n",
      "loss: 0.944487  [152000/525306]\n",
      "loss: 1.176997  [153600/525306]\n",
      "loss: 0.697713  [155200/525306]\n",
      "loss: 0.484840  [156800/525306]\n",
      "loss: 0.700564  [158400/525306]\n",
      "loss: 0.402543  [160000/525306]\n",
      "loss: 0.555884  [161600/525306]\n",
      "loss: 0.761016  [163200/525306]\n",
      "loss: 0.818790  [164800/525306]\n",
      "loss: 0.740757  [166400/525306]\n",
      "loss: 0.835779  [168000/525306]\n",
      "loss: 0.985499  [169600/525306]\n",
      "loss: 0.671335  [171200/525306]\n",
      "loss: 0.392747  [172800/525306]\n",
      "loss: 0.403193  [174400/525306]\n",
      "loss: 0.751435  [176000/525306]\n",
      "loss: 1.059549  [177600/525306]\n",
      "loss: 0.851243  [179200/525306]\n",
      "loss: 0.950114  [180800/525306]\n",
      "loss: 0.617924  [182400/525306]\n",
      "loss: 1.181185  [184000/525306]\n",
      "loss: 1.003631  [185600/525306]\n",
      "loss: 1.087044  [187200/525306]\n",
      "loss: 1.832073  [188800/525306]\n",
      "loss: 0.974304  [190400/525306]\n",
      "loss: 0.262240  [192000/525306]\n",
      "loss: 1.005555  [193600/525306]\n",
      "loss: 0.937984  [195200/525306]\n",
      "loss: 0.590813  [196800/525306]\n",
      "loss: 0.789008  [198400/525306]\n",
      "loss: 0.680155  [200000/525306]\n",
      "loss: 0.665008  [201600/525306]\n",
      "loss: 0.877859  [203200/525306]\n",
      "loss: 0.776199  [204800/525306]\n",
      "loss: 0.862272  [206400/525306]\n",
      "loss: 0.799726  [208000/525306]\n",
      "loss: 0.639603  [209600/525306]\n",
      "loss: 0.834107  [211200/525306]\n",
      "loss: 0.645705  [212800/525306]\n",
      "loss: 0.904550  [214400/525306]\n",
      "loss: 0.491224  [216000/525306]\n",
      "loss: 0.642663  [217600/525306]\n",
      "loss: 1.048040  [219200/525306]\n",
      "loss: 0.696431  [220800/525306]\n",
      "loss: 1.055310  [222400/525306]\n",
      "loss: 0.542844  [224000/525306]\n",
      "loss: 0.586493  [225600/525306]\n",
      "loss: 0.792951  [227200/525306]\n",
      "loss: 0.906531  [228800/525306]\n",
      "loss: 0.591233  [230400/525306]\n",
      "loss: 0.896294  [232000/525306]\n",
      "loss: 0.793723  [233600/525306]\n",
      "loss: 0.668220  [235200/525306]\n",
      "loss: 0.733040  [236800/525306]\n",
      "loss: 0.590653  [238400/525306]\n",
      "loss: 1.037602  [240000/525306]\n",
      "loss: 0.481297  [241600/525306]\n",
      "loss: 0.900795  [243200/525306]\n",
      "loss: 0.848694  [244800/525306]\n",
      "loss: 0.972431  [246400/525306]\n",
      "loss: 0.725912  [248000/525306]\n",
      "loss: 0.988425  [249600/525306]\n",
      "loss: 0.609210  [251200/525306]\n",
      "loss: 0.450825  [252800/525306]\n",
      "loss: 1.215670  [254400/525306]\n",
      "loss: 0.671788  [256000/525306]\n",
      "loss: 0.613250  [257600/525306]\n",
      "loss: 0.666522  [259200/525306]\n",
      "loss: 0.676848  [260800/525306]\n",
      "loss: 0.441769  [262400/525306]\n",
      "loss: 0.790321  [264000/525306]\n",
      "loss: 0.777581  [265600/525306]\n",
      "loss: 0.901813  [267200/525306]\n",
      "loss: 1.404418  [268800/525306]\n",
      "loss: 0.717492  [270400/525306]\n",
      "loss: 0.506443  [272000/525306]\n",
      "loss: 1.038325  [273600/525306]\n",
      "loss: 0.711454  [275200/525306]\n",
      "loss: 1.681497  [276800/525306]\n",
      "loss: 1.347592  [278400/525306]\n",
      "loss: 0.823945  [280000/525306]\n",
      "loss: 0.886750  [281600/525306]\n",
      "loss: 0.609293  [283200/525306]\n",
      "loss: 0.469422  [284800/525306]\n",
      "loss: 0.599470  [286400/525306]\n",
      "loss: 1.048372  [288000/525306]\n",
      "loss: 0.532088  [289600/525306]\n",
      "loss: 0.841217  [291200/525306]\n",
      "loss: 0.748565  [292800/525306]\n",
      "loss: 0.557637  [294400/525306]\n",
      "loss: 0.574347  [296000/525306]\n",
      "loss: 0.752918  [297600/525306]\n",
      "loss: 0.829121  [299200/525306]\n",
      "loss: 0.745322  [300800/525306]\n",
      "loss: 0.970321  [302400/525306]\n",
      "loss: 0.436032  [304000/525306]\n",
      "loss: 1.019999  [305600/525306]\n",
      "loss: 0.414478  [307200/525306]\n",
      "loss: 0.613674  [308800/525306]\n",
      "loss: 0.995611  [310400/525306]\n",
      "loss: 0.593151  [312000/525306]\n",
      "loss: 0.660381  [313600/525306]\n",
      "loss: 0.935846  [315200/525306]\n",
      "loss: 0.709572  [316800/525306]\n",
      "loss: 1.124321  [318400/525306]\n",
      "loss: 0.911000  [320000/525306]\n",
      "loss: 0.972313  [321600/525306]\n",
      "loss: 1.147118  [323200/525306]\n",
      "loss: 0.858504  [324800/525306]\n",
      "loss: 0.538379  [326400/525306]\n",
      "loss: 0.849819  [328000/525306]\n",
      "loss: 1.064829  [329600/525306]\n",
      "loss: 0.432454  [331200/525306]\n",
      "loss: 0.467993  [332800/525306]\n",
      "loss: 0.951045  [334400/525306]\n",
      "loss: 0.844211  [336000/525306]\n",
      "loss: 1.122718  [337600/525306]\n",
      "loss: 0.645203  [339200/525306]\n",
      "loss: 0.894022  [340800/525306]\n",
      "loss: 0.925283  [342400/525306]\n",
      "loss: 0.892670  [344000/525306]\n",
      "loss: 0.527207  [345600/525306]\n",
      "loss: 0.678305  [347200/525306]\n",
      "loss: 0.709638  [348800/525306]\n",
      "loss: 0.988247  [350400/525306]\n",
      "loss: 0.577695  [352000/525306]\n",
      "loss: 0.957864  [353600/525306]\n",
      "loss: 0.692427  [355200/525306]\n",
      "loss: 0.614167  [356800/525306]\n",
      "loss: 0.694430  [358400/525306]\n",
      "loss: 0.980296  [360000/525306]\n",
      "loss: 0.549823  [361600/525306]\n",
      "loss: 0.469280  [363200/525306]\n",
      "loss: 0.458789  [364800/525306]\n",
      "loss: 0.735642  [366400/525306]\n",
      "loss: 0.768484  [368000/525306]\n",
      "loss: 0.972337  [369600/525306]\n",
      "loss: 0.479139  [371200/525306]\n",
      "loss: 0.588674  [372800/525306]\n",
      "loss: 1.446638  [374400/525306]\n",
      "loss: 0.346462  [376000/525306]\n",
      "loss: 0.921374  [377600/525306]\n",
      "loss: 1.029847  [379200/525306]\n",
      "loss: 1.083347  [380800/525306]\n",
      "loss: 0.663992  [382400/525306]\n",
      "loss: 0.756620  [384000/525306]\n",
      "loss: 1.029168  [385600/525306]\n",
      "loss: 0.910660  [387200/525306]\n",
      "loss: 1.067501  [388800/525306]\n",
      "loss: 0.983958  [390400/525306]\n",
      "loss: 0.700661  [392000/525306]\n",
      "loss: 0.975896  [393600/525306]\n",
      "loss: 0.710020  [395200/525306]\n",
      "loss: 0.670470  [396800/525306]\n",
      "loss: 0.755651  [398400/525306]\n",
      "loss: 1.409768  [400000/525306]\n",
      "loss: 1.077062  [401600/525306]\n",
      "loss: 0.453844  [403200/525306]\n",
      "loss: 1.404920  [404800/525306]\n",
      "loss: 0.899050  [406400/525306]\n",
      "loss: 0.656510  [408000/525306]\n",
      "loss: 1.487762  [409600/525306]\n",
      "loss: 0.757240  [411200/525306]\n",
      "loss: 0.776284  [412800/525306]\n",
      "loss: 0.610628  [414400/525306]\n",
      "loss: 0.689674  [416000/525306]\n",
      "loss: 1.318491  [417600/525306]\n",
      "loss: 0.689406  [419200/525306]\n",
      "loss: 0.898929  [420800/525306]\n",
      "loss: 0.310925  [422400/525306]\n",
      "loss: 0.702851  [424000/525306]\n",
      "loss: 0.797129  [425600/525306]\n",
      "loss: 0.965522  [427200/525306]\n",
      "loss: 1.338386  [428800/525306]\n",
      "loss: 0.613891  [430400/525306]\n",
      "loss: 0.539070  [432000/525306]\n",
      "loss: 0.833488  [433600/525306]\n",
      "loss: 1.282057  [435200/525306]\n",
      "loss: 0.593455  [436800/525306]\n",
      "loss: 0.415139  [438400/525306]\n",
      "loss: 1.395452  [440000/525306]\n",
      "loss: 0.456857  [441600/525306]\n",
      "loss: 0.847745  [443200/525306]\n",
      "loss: 0.942886  [444800/525306]\n",
      "loss: 0.894021  [446400/525306]\n",
      "loss: 0.615076  [448000/525306]\n",
      "loss: 0.696838  [449600/525306]\n",
      "loss: 0.684988  [451200/525306]\n",
      "loss: 1.097857  [452800/525306]\n",
      "loss: 1.023291  [454400/525306]\n",
      "loss: 0.686318  [456000/525306]\n",
      "loss: 0.258340  [457600/525306]\n",
      "loss: 0.642261  [459200/525306]\n",
      "loss: 0.350769  [460800/525306]\n",
      "loss: 0.750505  [462400/525306]\n",
      "loss: 0.624551  [464000/525306]\n",
      "loss: 0.811739  [465600/525306]\n",
      "loss: 0.888790  [467200/525306]\n",
      "loss: 0.850835  [468800/525306]\n",
      "loss: 0.497381  [470400/525306]\n",
      "loss: 0.487121  [472000/525306]\n",
      "loss: 1.106410  [473600/525306]\n",
      "loss: 1.667564  [475200/525306]\n",
      "loss: 1.449489  [476800/525306]\n",
      "loss: 0.435244  [478400/525306]\n",
      "loss: 0.605457  [480000/525306]\n",
      "loss: 0.607635  [481600/525306]\n",
      "loss: 0.826917  [483200/525306]\n",
      "loss: 0.880740  [484800/525306]\n",
      "loss: 0.544473  [486400/525306]\n",
      "loss: 1.119264  [488000/525306]\n",
      "loss: 0.577417  [489600/525306]\n",
      "loss: 0.614396  [491200/525306]\n",
      "loss: 0.601564  [492800/525306]\n",
      "loss: 1.267515  [494400/525306]\n",
      "loss: 1.104709  [496000/525306]\n",
      "loss: 0.868228  [497600/525306]\n",
      "loss: 0.703926  [499200/525306]\n",
      "loss: 0.882876  [500800/525306]\n",
      "loss: 0.708220  [502400/525306]\n",
      "loss: 0.734931  [504000/525306]\n",
      "loss: 0.833966  [505600/525306]\n",
      "loss: 0.986900  [507200/525306]\n",
      "loss: 0.548758  [508800/525306]\n",
      "loss: 0.410622  [510400/525306]\n",
      "loss: 0.645236  [512000/525306]\n",
      "loss: 0.539708  [513600/525306]\n",
      "loss: 0.784697  [515200/525306]\n",
      "loss: 0.987100  [516800/525306]\n",
      "loss: 1.021660  [518400/525306]\n",
      "loss: 0.931507  [520000/525306]\n",
      "loss: 0.508953  [521600/525306]\n",
      "loss: 0.592697  [523200/525306]\n",
      "loss: 0.757178  [524800/525306]\n",
      "Train Accuracy: 70.5629%\n",
      "Test Error: \n",
      " Accuracy: 61.8%, Avg loss: 0.977340, F1-score: 67.99%, Macro_F1-Score:  38.03%  \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.945556  [    0/525306]\n",
      "loss: 0.369380  [ 1600/525306]\n",
      "loss: 0.313755  [ 3200/525306]\n",
      "loss: 0.558196  [ 4800/525306]\n",
      "loss: 0.823247  [ 6400/525306]\n",
      "loss: 1.088839  [ 8000/525306]\n",
      "loss: 1.466537  [ 9600/525306]\n",
      "loss: 0.450780  [11200/525306]\n",
      "loss: 0.662521  [12800/525306]\n",
      "loss: 1.177829  [14400/525306]\n",
      "loss: 0.565568  [16000/525306]\n",
      "loss: 0.472195  [17600/525306]\n",
      "loss: 0.918378  [19200/525306]\n",
      "loss: 0.900540  [20800/525306]\n",
      "loss: 1.187614  [22400/525306]\n",
      "loss: 0.865961  [24000/525306]\n",
      "loss: 0.695098  [25600/525306]\n",
      "loss: 0.883321  [27200/525306]\n",
      "loss: 0.611368  [28800/525306]\n",
      "loss: 0.437403  [30400/525306]\n",
      "loss: 0.553968  [32000/525306]\n",
      "loss: 1.266041  [33600/525306]\n",
      "loss: 0.479585  [35200/525306]\n",
      "loss: 0.723082  [36800/525306]\n",
      "loss: 0.850059  [38400/525306]\n",
      "loss: 0.778106  [40000/525306]\n",
      "loss: 0.531023  [41600/525306]\n",
      "loss: 0.867770  [43200/525306]\n",
      "loss: 0.770521  [44800/525306]\n",
      "loss: 0.412278  [46400/525306]\n",
      "loss: 0.901544  [48000/525306]\n",
      "loss: 0.369070  [49600/525306]\n",
      "loss: 0.527488  [51200/525306]\n",
      "loss: 0.589527  [52800/525306]\n",
      "loss: 0.589957  [54400/525306]\n",
      "loss: 0.712802  [56000/525306]\n",
      "loss: 0.778089  [57600/525306]\n",
      "loss: 0.953801  [59200/525306]\n",
      "loss: 0.977341  [60800/525306]\n",
      "loss: 0.700353  [62400/525306]\n",
      "loss: 0.918820  [64000/525306]\n",
      "loss: 0.822834  [65600/525306]\n",
      "loss: 0.699839  [67200/525306]\n",
      "loss: 0.974402  [68800/525306]\n",
      "loss: 0.483144  [70400/525306]\n",
      "loss: 0.778881  [72000/525306]\n",
      "loss: 0.758358  [73600/525306]\n",
      "loss: 1.349236  [75200/525306]\n",
      "loss: 1.147161  [76800/525306]\n",
      "loss: 0.580041  [78400/525306]\n",
      "loss: 0.573091  [80000/525306]\n",
      "loss: 0.566738  [81600/525306]\n",
      "loss: 0.582973  [83200/525306]\n",
      "loss: 0.834698  [84800/525306]\n",
      "loss: 0.987615  [86400/525306]\n",
      "loss: 0.947484  [88000/525306]\n",
      "loss: 0.579826  [89600/525306]\n",
      "loss: 0.582841  [91200/525306]\n",
      "loss: 0.594522  [92800/525306]\n",
      "loss: 0.798754  [94400/525306]\n",
      "loss: 0.917887  [96000/525306]\n",
      "loss: 0.846408  [97600/525306]\n",
      "loss: 0.896616  [99200/525306]\n",
      "loss: 0.523253  [100800/525306]\n",
      "loss: 0.459661  [102400/525306]\n",
      "loss: 0.509815  [104000/525306]\n",
      "loss: 0.454199  [105600/525306]\n",
      "loss: 1.333827  [107200/525306]\n",
      "loss: 1.372725  [108800/525306]\n",
      "loss: 0.565251  [110400/525306]\n",
      "loss: 0.467918  [112000/525306]\n",
      "loss: 0.599919  [113600/525306]\n",
      "loss: 0.862037  [115200/525306]\n",
      "loss: 0.994696  [116800/525306]\n",
      "loss: 0.758235  [118400/525306]\n",
      "loss: 0.721767  [120000/525306]\n",
      "loss: 0.701246  [121600/525306]\n",
      "loss: 0.764666  [123200/525306]\n",
      "loss: 0.840623  [124800/525306]\n",
      "loss: 0.591280  [126400/525306]\n",
      "loss: 1.044173  [128000/525306]\n",
      "loss: 1.343493  [129600/525306]\n",
      "loss: 0.815763  [131200/525306]\n",
      "loss: 0.804663  [132800/525306]\n",
      "loss: 1.407950  [134400/525306]\n",
      "loss: 0.474996  [136000/525306]\n",
      "loss: 0.372513  [137600/525306]\n",
      "loss: 0.732465  [139200/525306]\n",
      "loss: 0.741324  [140800/525306]\n",
      "loss: 0.586640  [142400/525306]\n",
      "loss: 1.000419  [144000/525306]\n",
      "loss: 0.962295  [145600/525306]\n",
      "loss: 1.318962  [147200/525306]\n",
      "loss: 0.601407  [148800/525306]\n",
      "loss: 0.689098  [150400/525306]\n",
      "loss: 0.871648  [152000/525306]\n",
      "loss: 1.010595  [153600/525306]\n",
      "loss: 0.734362  [155200/525306]\n",
      "loss: 0.678850  [156800/525306]\n",
      "loss: 1.204160  [158400/525306]\n",
      "loss: 0.712240  [160000/525306]\n",
      "loss: 1.007292  [161600/525306]\n",
      "loss: 0.763438  [163200/525306]\n",
      "loss: 0.799029  [164800/525306]\n",
      "loss: 0.786741  [166400/525306]\n",
      "loss: 0.963726  [168000/525306]\n",
      "loss: 0.798007  [169600/525306]\n",
      "loss: 0.675460  [171200/525306]\n",
      "loss: 1.284242  [172800/525306]\n",
      "loss: 0.944740  [174400/525306]\n",
      "loss: 0.792986  [176000/525306]\n",
      "loss: 0.193113  [177600/525306]\n",
      "loss: 0.842116  [179200/525306]\n",
      "loss: 0.753271  [180800/525306]\n",
      "loss: 1.139673  [182400/525306]\n",
      "loss: 0.688309  [184000/525306]\n",
      "loss: 0.756051  [185600/525306]\n",
      "loss: 0.651267  [187200/525306]\n",
      "loss: 0.934167  [188800/525306]\n",
      "loss: 1.208450  [190400/525306]\n",
      "loss: 0.639933  [192000/525306]\n",
      "loss: 0.951466  [193600/525306]\n",
      "loss: 0.886535  [195200/525306]\n",
      "loss: 0.721581  [196800/525306]\n",
      "loss: 1.063913  [198400/525306]\n",
      "loss: 0.555340  [200000/525306]\n",
      "loss: 0.786924  [201600/525306]\n",
      "loss: 0.384739  [203200/525306]\n",
      "loss: 0.800814  [204800/525306]\n",
      "loss: 1.057188  [206400/525306]\n",
      "loss: 0.540897  [208000/525306]\n",
      "loss: 0.359593  [209600/525306]\n",
      "loss: 0.471142  [211200/525306]\n",
      "loss: 1.263157  [212800/525306]\n",
      "loss: 1.087970  [214400/525306]\n",
      "loss: 0.578363  [216000/525306]\n",
      "loss: 0.375778  [217600/525306]\n",
      "loss: 1.243458  [219200/525306]\n",
      "loss: 0.763103  [220800/525306]\n",
      "loss: 0.740896  [222400/525306]\n",
      "loss: 1.008373  [224000/525306]\n",
      "loss: 0.580375  [225600/525306]\n",
      "loss: 0.480093  [227200/525306]\n",
      "loss: 1.114456  [228800/525306]\n",
      "loss: 0.829517  [230400/525306]\n",
      "loss: 1.353587  [232000/525306]\n",
      "loss: 1.120950  [233600/525306]\n",
      "loss: 1.130189  [235200/525306]\n",
      "loss: 0.618455  [236800/525306]\n",
      "loss: 1.146991  [238400/525306]\n",
      "loss: 0.812382  [240000/525306]\n",
      "loss: 0.897594  [241600/525306]\n",
      "loss: 1.106672  [243200/525306]\n",
      "loss: 1.003384  [244800/525306]\n",
      "loss: 0.606294  [246400/525306]\n",
      "loss: 1.037639  [248000/525306]\n",
      "loss: 0.945009  [249600/525306]\n",
      "loss: 0.307457  [251200/525306]\n",
      "loss: 0.809605  [252800/525306]\n",
      "loss: 0.547312  [254400/525306]\n",
      "loss: 0.762475  [256000/525306]\n",
      "loss: 0.654831  [257600/525306]\n",
      "loss: 0.938553  [259200/525306]\n",
      "loss: 1.110587  [260800/525306]\n",
      "loss: 0.629881  [262400/525306]\n",
      "loss: 0.611501  [264000/525306]\n",
      "loss: 1.096018  [265600/525306]\n",
      "loss: 0.610602  [267200/525306]\n",
      "loss: 0.690373  [268800/525306]\n",
      "loss: 0.415743  [270400/525306]\n",
      "loss: 0.740636  [272000/525306]\n",
      "loss: 1.188142  [273600/525306]\n",
      "loss: 0.687442  [275200/525306]\n",
      "loss: 0.680966  [276800/525306]\n",
      "loss: 0.798465  [278400/525306]\n",
      "loss: 1.099721  [280000/525306]\n",
      "loss: 0.935256  [281600/525306]\n",
      "loss: 0.789700  [283200/525306]\n",
      "loss: 0.568216  [284800/525306]\n",
      "loss: 0.460651  [286400/525306]\n",
      "loss: 1.001926  [288000/525306]\n",
      "loss: 1.020012  [289600/525306]\n",
      "loss: 0.512659  [291200/525306]\n",
      "loss: 0.641116  [292800/525306]\n",
      "loss: 0.686964  [294400/525306]\n",
      "loss: 1.477027  [296000/525306]\n",
      "loss: 0.546826  [297600/525306]\n",
      "loss: 0.433961  [299200/525306]\n",
      "loss: 0.687547  [300800/525306]\n",
      "loss: 0.696911  [302400/525306]\n",
      "loss: 0.650963  [304000/525306]\n",
      "loss: 1.078677  [305600/525306]\n",
      "loss: 0.680468  [307200/525306]\n",
      "loss: 0.928266  [308800/525306]\n",
      "loss: 1.250499  [310400/525306]\n",
      "loss: 0.655044  [312000/525306]\n",
      "loss: 1.203366  [313600/525306]\n",
      "loss: 0.790604  [315200/525306]\n",
      "loss: 0.459568  [316800/525306]\n",
      "loss: 1.055999  [318400/525306]\n",
      "loss: 1.240349  [320000/525306]\n",
      "loss: 0.619988  [321600/525306]\n",
      "loss: 0.701470  [323200/525306]\n",
      "loss: 0.883012  [324800/525306]\n",
      "loss: 0.775289  [326400/525306]\n",
      "loss: 1.210299  [328000/525306]\n",
      "loss: 0.604028  [329600/525306]\n",
      "loss: 0.463017  [331200/525306]\n",
      "loss: 0.583476  [332800/525306]\n",
      "loss: 0.693674  [334400/525306]\n",
      "loss: 0.758772  [336000/525306]\n",
      "loss: 0.647699  [337600/525306]\n",
      "loss: 0.534345  [339200/525306]\n",
      "loss: 0.538150  [340800/525306]\n",
      "loss: 0.525376  [342400/525306]\n",
      "loss: 0.982317  [344000/525306]\n",
      "loss: 0.594889  [345600/525306]\n",
      "loss: 0.523074  [347200/525306]\n",
      "loss: 0.417945  [348800/525306]\n",
      "loss: 0.348652  [350400/525306]\n",
      "loss: 0.889394  [352000/525306]\n",
      "loss: 0.719187  [353600/525306]\n",
      "loss: 0.956555  [355200/525306]\n",
      "loss: 0.877336  [356800/525306]\n",
      "loss: 0.889582  [358400/525306]\n",
      "loss: 0.715796  [360000/525306]\n",
      "loss: 1.325144  [361600/525306]\n",
      "loss: 0.671628  [363200/525306]\n",
      "loss: 0.701348  [364800/525306]\n",
      "loss: 1.582703  [366400/525306]\n",
      "loss: 0.932567  [368000/525306]\n",
      "loss: 0.934173  [369600/525306]\n",
      "loss: 0.940051  [371200/525306]\n",
      "loss: 0.684133  [372800/525306]\n",
      "loss: 0.542278  [374400/525306]\n",
      "loss: 0.532355  [376000/525306]\n",
      "loss: 1.300184  [377600/525306]\n",
      "loss: 0.694121  [379200/525306]\n",
      "loss: 0.786392  [380800/525306]\n",
      "loss: 0.652771  [382400/525306]\n",
      "loss: 1.193802  [384000/525306]\n",
      "loss: 0.900620  [385600/525306]\n",
      "loss: 0.876509  [387200/525306]\n",
      "loss: 0.653237  [388800/525306]\n",
      "loss: 0.837381  [390400/525306]\n",
      "loss: 0.894560  [392000/525306]\n",
      "loss: 0.303709  [393600/525306]\n",
      "loss: 0.818441  [395200/525306]\n",
      "loss: 1.072202  [396800/525306]\n",
      "loss: 0.613402  [398400/525306]\n",
      "loss: 0.786030  [400000/525306]\n",
      "loss: 0.682140  [401600/525306]\n",
      "loss: 1.123378  [403200/525306]\n",
      "loss: 0.599006  [404800/525306]\n",
      "loss: 0.503135  [406400/525306]\n",
      "loss: 0.973643  [408000/525306]\n",
      "loss: 0.385174  [409600/525306]\n",
      "loss: 0.376861  [411200/525306]\n",
      "loss: 0.433276  [412800/525306]\n",
      "loss: 0.435456  [414400/525306]\n",
      "loss: 0.795827  [416000/525306]\n",
      "loss: 1.349795  [417600/525306]\n",
      "loss: 0.586754  [419200/525306]\n",
      "loss: 0.543842  [420800/525306]\n",
      "loss: 0.772074  [422400/525306]\n",
      "loss: 0.545065  [424000/525306]\n",
      "loss: 0.859707  [425600/525306]\n",
      "loss: 0.973671  [427200/525306]\n",
      "loss: 0.920456  [428800/525306]\n",
      "loss: 0.672546  [430400/525306]\n",
      "loss: 1.270168  [432000/525306]\n",
      "loss: 0.878638  [433600/525306]\n",
      "loss: 0.753552  [435200/525306]\n",
      "loss: 0.738549  [436800/525306]\n",
      "loss: 0.510315  [438400/525306]\n",
      "loss: 0.615683  [440000/525306]\n",
      "loss: 0.879240  [441600/525306]\n",
      "loss: 0.882550  [443200/525306]\n",
      "loss: 0.740967  [444800/525306]\n",
      "loss: 0.906253  [446400/525306]\n",
      "loss: 0.620662  [448000/525306]\n",
      "loss: 0.854410  [449600/525306]\n",
      "loss: 0.651595  [451200/525306]\n",
      "loss: 0.658084  [452800/525306]\n",
      "loss: 0.851019  [454400/525306]\n",
      "loss: 0.883717  [456000/525306]\n",
      "loss: 1.035956  [457600/525306]\n",
      "loss: 0.853452  [459200/525306]\n",
      "loss: 0.446504  [460800/525306]\n",
      "loss: 0.784062  [462400/525306]\n",
      "loss: 0.654851  [464000/525306]\n",
      "loss: 1.061103  [465600/525306]\n",
      "loss: 0.562136  [467200/525306]\n",
      "loss: 0.976831  [468800/525306]\n",
      "loss: 1.522316  [470400/525306]\n",
      "loss: 1.064442  [472000/525306]\n",
      "loss: 0.610774  [473600/525306]\n",
      "loss: 0.975854  [475200/525306]\n",
      "loss: 0.717243  [476800/525306]\n",
      "loss: 1.011630  [478400/525306]\n",
      "loss: 0.798920  [480000/525306]\n",
      "loss: 0.790083  [481600/525306]\n",
      "loss: 0.697524  [483200/525306]\n",
      "loss: 0.938116  [484800/525306]\n",
      "loss: 0.784587  [486400/525306]\n",
      "loss: 0.701261  [488000/525306]\n",
      "loss: 0.657786  [489600/525306]\n",
      "loss: 0.772903  [491200/525306]\n",
      "loss: 0.526187  [492800/525306]\n",
      "loss: 1.117429  [494400/525306]\n",
      "loss: 0.602285  [496000/525306]\n",
      "loss: 1.031230  [497600/525306]\n",
      "loss: 0.753522  [499200/525306]\n",
      "loss: 0.864620  [500800/525306]\n",
      "loss: 0.928687  [502400/525306]\n",
      "loss: 0.509303  [504000/525306]\n",
      "loss: 0.920671  [505600/525306]\n",
      "loss: 0.557588  [507200/525306]\n",
      "loss: 0.481214  [508800/525306]\n",
      "loss: 0.447606  [510400/525306]\n",
      "loss: 0.800628  [512000/525306]\n",
      "loss: 0.816043  [513600/525306]\n",
      "loss: 0.772988  [515200/525306]\n",
      "loss: 0.581250  [516800/525306]\n",
      "loss: 0.657887  [518400/525306]\n",
      "loss: 0.260459  [520000/525306]\n",
      "loss: 0.685799  [521600/525306]\n",
      "loss: 0.657097  [523200/525306]\n",
      "loss: 0.840795  [524800/525306]\n",
      "Train Accuracy: 70.5760%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.956625, F1-score: 68.25%, Macro_F1-Score:  38.63%  \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001,weight_decay=1e-4)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b427034-602d-4252-af52-9c7d0908f074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001,weight_decay=1e-4)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115f1b7-87f8-41a5-8992-af1752600f88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001,weight_decay=1e-4)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14137f6-f30f-4334-b08b-83c562404f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0  # For accuracy tracking\n",
    "    total = 0\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(pred, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    \n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    print(f\"Train Accuracy: {accuracy:.4f}%\")\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "            # Collect all predictions and true labels for F1-score calculation\n",
    "            all_preds.extend(pred.argmax(1).cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted') * 100  # Weighted F1-score to handle class imbalance\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}, F1-score: {f1:.2f}% \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d3b8c-ed93-47e2-ae7c-367c66fcfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KAN([40, 20,6, 3,10],grid_size = 3, scale_noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785bff68-72f6-4b56-9691-bb96c34fcbe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a33c4-8087-4b5c-80cf-c10334d2b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KAN([40, 15,6, 3,10],grid_size = 4, scale_noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada289ca-73cc-4ac6-8f1c-89c10d83b914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a6d93-0220-4085-bb3f-8965b97240b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KAN([40, 10,6, 3,10],grid_size = 4, scale_noise=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e34344-c96e-42c9-b318-96c5e291cfed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f0ad0-0334-4f18-b8a8-2e653a66b477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing function using a moving average\n",
    "def smooth_loss(losses, window_size=100):\n",
    "    \"\"\"\n",
    "    Smooth the loss values using a moving average.\n",
    "    :param losses: List of loss values.\n",
    "    :param window_size: Size of the moving window.\n",
    "    :return: Smoothed loss values.\n",
    "    \"\"\"\n",
    "    smoothed_losses = np.convolve(losses, np.ones(window_size) / window_size, mode='valid')\n",
    "    return smoothed_losses\n",
    "\n",
    "# Plot the training loss over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Smooth and plot training loss for each fold\n",
    "for fold, losses in enumerate(all_losses):\n",
    "    smoothed_loss = smooth_loss(losses, window_size=100)  # Adjust window_size as needed\n",
    "    plt.plot(smoothed_loss, label=f'Fold {fold + 1}')\n",
    "\n",
    "# Calculate and plot the average smoothed loss across folds\n",
    "avg_loss = np.mean(all_losses, axis=0)\n",
    "smoothed_avg_loss = smooth_loss(avg_loss, window_size=100)\n",
    "plt.plot(smoothed_avg_loss, label='Average Loss', linewidth=2, color='black')\n",
    "\n",
    "plt.xlabel('Mini-Batch Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Mini-Batches (Smoothed)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc939cd5-1ad5-43f9-97d3-d06382dedfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Mini-Batches per Epoch: {len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c46642c-d070-4eed-bfb4-3c5a7d21e93c",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605965a8-0cd9-434c-aee0-478a4531365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the LabelEncoder object from the file\n",
    "with open(r\"C:\\Users\\ADMIN\\Desktop\\Thesis Space Desktop\\Data After Preprocess\\label_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "\n",
    "# Now you can use the label_encoder object in the second notebook\n",
    "original_class_labels = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c1d9c-dcf8-497e-931d-9ad812150687",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_labels_test = label_encoder.inverse_transform(test_labels_encoded.values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1517902-9ea6-4c23-8654-e295a0f3c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(test_X_tensor)  # Forward pass\n",
    "    y_pred = torch.argmax(y_pred, dim=1)  # Get class predictions\n",
    "\n",
    "# Convert tensors to NumPy arrays for sklearn\n",
    "y_pred = y_pred.cpu().numpy()\n",
    "y_true = test_Y_tensor.cpu().numpy()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Get class labels from the LabelEncoder\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  #Creates both a figure and an ax\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap='Blues', values_format='d', ax=ax)\n",
    "\n",
    "# Rotate axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd35ae8-6d07-4480-ac58-1ed59db4db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_score = F.softmax(model(test_X_tensor), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcbd44-687c-45a2-9c00-879918c67e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(y_score.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd8846-8af7-4fd7-9d88-9fefb32eb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer().fit(train_data_y)\n",
    "y_onehot_test = label_binarizer.transform(test_labels_encoded)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff20700c-6029-414e-bac8-a661f60724a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "display = RocCurveDisplay.from_predictions(\n",
    "    y_onehot_test.ravel(),\n",
    "    y_score.ravel(),\n",
    "    name=\"micro-average OvR\",\n",
    "    color=\"darkorange\",\n",
    "    plot_chance_level=True)\n",
    "_ = display.ax_.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Micro-averaged One-vs-Rest\\nReceiver Operating Characteristic\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2356024a-ac67-4f9a-9d85-05fc7bbd6516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units1: int, hidden_units2: int, hidden_units3: int, hidden_units4: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units1, out_features=hidden_units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units1, out_features=hidden_units2),\n",
    "        )\n",
    "\n",
    "        self.linear_relu_stack2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_units2, out_features=hidden_units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units2, out_features=hidden_units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units2, out_features=hidden_units3),\n",
    "        )\n",
    "\n",
    "        # **New Block Added Here**\n",
    "        self.linear_relu_stack3 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_units3, out_features=hidden_units3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units3, out_features=hidden_units3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units3, out_features=hidden_units4),\n",
    "        )\n",
    "\n",
    "        self.linear_relu_stack4 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_units4, out_features=hidden_units4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units4, out_features=hidden_units4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features=hidden_units4, out_features=output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        x = self.linear_relu_stack2(x)\n",
    "        x = self.linear_relu_stack3(x)  # Pass through new block\n",
    "        logits = self.linear_relu_stack4(x)  # Final output layer\n",
    "\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b2e731-3fbc-4bab-b4bc-31d9643160e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = NeuralNetwork(40,128,64,32,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e58bf04-0ab7-468f-b80a-bba0e13ff1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "epochs = 200\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model_test, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model_test, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b16805-13a2-47e6-8c8d-cc677b5aa227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa08a28-cb43-4ecb-924e-34c39a6b8702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686dbe6-e354-46d6-98e8-d9eb3f4e5949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d2a7e-e9a4-43a1-8731-3345a578a4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd505fb2-28cc-44a8-beb3-4baee288e02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f79f78-753b-4d86-89bc-6f85eec05b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
