{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c04eae1c-c343-40d8-a4a0-4eb4999ab427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "#pip install git+https://github.com/KindXiaoming/pykan.git\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83a82c1a-1495-4649-8933-55554a6c723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport pandas as pd\\n\\ntest_data_path = os.getenv(\"TEST_DATA_PATH\", \"data/UNSW_NB15_testing-set.csv\")\\ntrain_data_path = os.getenv(\"TRAIN_DATA_PATH\", \"data/UNSW_NB15_training-set.csv\")\\n\\ntest_data = pd.read_csv(test_data_path)\\ntrain_data = pd.read_csv(train_data_path)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "\n",
    "test_data_path = os.getenv(\"TEST_DATA_PATH\", \"data/UNSW_NB15_testing-set.csv\")\n",
    "train_data_path = os.getenv(\"TRAIN_DATA_PATH\", \"data/UNSW_NB15_training-set.csv\")\n",
    "\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "train_data = pd.read_csv(train_data_path)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d4b8c325-66b7-446a-96bb-1c7a7a4081d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r\"UNSW_NB15_testing-set.csv\")\n",
    "train_data = pd.read_csv(r\"UNSW_NB15_training-set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "540ee571-e16a-4fb5-9196-90a5bec3c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns = [\"attack_cat\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e846d0f5-56d7-4f9e-99c6-0510803f48ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns = [\"attack_cat\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7dd4a003-96ee-443f-8565-af1fb09339a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[\"attack_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "59a0e620-6aaf-46e9-90d8-c11f9970e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[\"attack_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b7c5c69-2f13-4a0c-85a9-31b766627069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class OutlierTreatmentTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the transformer.\n",
    "        \"\"\"\n",
    "        self.iqr_bounds = {}  # Store IQR bounds for each numeric column\n",
    "        self.columns_numeric = []  # Store numeric columns to process\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Compute IQR bounds for each numeric column.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The training data (feature matrix).\n",
    "            y (ignored): Not used, present for compatibility.\n",
    "\n",
    "        Returns:\n",
    "            self (OutlierTreatmentTransformer): The fitted transformer.\n",
    "        \"\"\"\n",
    "        print(\"Fitting outlier treatment...\")\n",
    "\n",
    "        # Identify numeric columns (excluding 'id' and columns with fewer than 3 unique values)\n",
    "        self.columns_numeric = X.select_dtypes(include=\"number\").drop(columns=\"id\", errors=\"ignore\").columns\n",
    "        self.columns_numeric = [\n",
    "            col for col in self.columns_numeric\n",
    "            if X[col].nunique() >= 3  # Ensure column has at least 3 unique values\n",
    "        ]\n",
    "\n",
    "        # Ensure all numeric columns are cast to float\n",
    "        for col in self.columns_numeric:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].astype(float)\n",
    "            else:\n",
    "                raise ValueError(f\"Column '{col}' not found in the input data.\")\n",
    "\n",
    "        # Process each numeric column\n",
    "        for col in self.columns_numeric:\n",
    "            # Calculate IQR bounds for the column\n",
    "            q1 = X[col].quantile(0.25)\n",
    "            q3 = X[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            self.iqr_bounds[col] = (lower_bound, upper_bound)\n",
    "\n",
    "        print(\"Fitting completed.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Treat outliers in the dataset using the stored IQR bounds.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The data to transform (feature matrix).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The transformed data with outliers treated.\n",
    "        \"\"\"\n",
    "        print(\"Transforming data...\")\n",
    "\n",
    "        # Ensure all numeric columns are cast to float\n",
    "        for col in self.columns_numeric:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].astype(float)\n",
    "            else:\n",
    "                raise ValueError(f\"Column '{col}' not found in the input data.\")\n",
    "\n",
    "        # Process each numeric column\n",
    "        for col in self.columns_numeric:\n",
    "            lower_bound, upper_bound = self.iqr_bounds[col]\n",
    "\n",
    "            # Identify outliers\n",
    "            outliers = (X[col] < lower_bound) | (X[col] > upper_bound)\n",
    "\n",
    "            # Replace outliers with the column mean\n",
    "            replacement_mean = X[col].mean()\n",
    "            X.loc[outliers, col] = replacement_mean\n",
    "\n",
    "        print(\"Transformation completed.\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "123249e2-ec43-4f27-80f9-267ff8fc9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting outlier treatment...\n",
      "Fitting completed.\n",
      "Transforming data...\n",
      "Transformation completed.\n",
      "Transforming data...\n",
      "Transformation completed.\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "OutlierTreater = OutlierTreatmentTransformer()\n",
    "\n",
    "train_data = OutlierTreater.fit_transform(train_data)\n",
    "test_data = OutlierTreater.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5ff474af-5c06-498b-98ff-0ee62bfb011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CategoryPruner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=6, debug=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            threshold (int): The maximum number of categories to keep for each feature.\n",
    "            debug (bool): Whether to print debug information.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.debug = debug\n",
    "        self.top_categories = {}  # Store top categories for each feature\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Identify the top categories for each categorical feature in the training data.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The training data (feature matrix).\n",
    "            y (ignored): Not used, present for compatibility.\n",
    "\n",
    "        Returns:\n",
    "            self (CategoryPruner): The fitted transformer.\n",
    "        \"\"\"\n",
    "        # Select categorical columns\n",
    "        categorical_columns = X.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "        # Iterate through categorical columns\n",
    "        for feature in categorical_columns:\n",
    "            if self.debug:\n",
    "                print(f\"Processing feature: {feature}\")\n",
    "                print(f\"Number of unique categories before reduction: {X[feature].nunique()}\")\n",
    "                print('----------------------------------------------------')\n",
    "\n",
    "            # Check if the number of unique categories exceeds the threshold\n",
    "            if X[feature].nunique() > self.threshold:\n",
    "                # Identify the top categories in the training data\n",
    "                self.top_categories[feature] = X[feature].value_counts().head(self.threshold).index\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Reduce categories in the dataset to the top categories identified during fitting.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The data to transform (feature matrix).\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The transformed data with reduced categories.\n",
    "        \"\"\"\n",
    "        # Select categorical columns\n",
    "        categorical_columns = X.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "        # Iterate through categorical columns\n",
    "        for feature in categorical_columns:\n",
    "            if feature in self.top_categories:\n",
    "                # Reduce data to the top categories, replacing others with '-'\n",
    "                X[feature] = np.where(X[feature].isin(self.top_categories[feature]), X[feature], '-')\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd025b0a-5bf1-4a81-87a2-cb3c7ff9b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoryPruner_object = CategoryPruner(target_column = \"attack_cat\").fit(train_data)\n",
    "\n",
    "train_data = CategoryPruner_object.transform(train_data)\n",
    "\n",
    "test_data = CategoryPruner_object.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4a9b651-5eea-4383-82f0-ab53f5a0bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class SkewnessLogTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, skew_threshold=1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            skew_threshold (float): Threshold for identifying skewed columns.\n",
    "        \"\"\"\n",
    "        self.skew_threshold = skew_threshold\n",
    "        self.skewed_columns = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        numeric_cols = X.select_dtypes(include=\"number\").columns\n",
    "\n",
    "        # Calculate skewness for numeric columns\n",
    "        skewness = X[numeric_cols].skew()\n",
    "\n",
    "        # Identify columns with skewness above the threshold\n",
    "        self.skewed_cols = skewness[skewness.abs() > self.skew_threshold].index\n",
    "        print(\"Skewed columns identified during fit:\", self.skewed_cols)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self,X):\n",
    "\n",
    "        for col in self.skewed_cols:\n",
    "            if col in X.columns:\n",
    "                X[col] = np.log1p(X[col])  # log1p to avoid log(0)\n",
    "            else:\n",
    "                raise ValueError(f\"Column '{col}' not found in the input data.\")\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e2dbd-0f70-4582-b290-47b2d28dd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "#standardScaler\n",
    "#minmaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e7cb2e4-264c-45a3-928a-b9f42fb26bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class CategoricalColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.categorical_cols = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Identify categorical columns dynamically\n",
    "        self.categorical_cols = X.select_dtypes(include=\"object\").columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Return only the categorical columns\n",
    "        return X[self.categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3684c72d-eda4-4010-903e-0762dad1a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = []\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Pass through non-categorical columns unchanged\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d1b12a9-adf1-4d59-befb-9ddda612bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficient_kan import KAN\n",
    "\n",
    "model = KAN([40, 20,6, 3,10],grid_size = 3, scale_noise=0.2, scale_base=0.2, scale_spline=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bdfc0-f5dc-4c19-84a8-34cc0f28b9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
