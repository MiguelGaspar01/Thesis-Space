{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c04eae1c-c343-40d8-a4a0-4eb4999ab427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "#pip install git+https://github.com/KindXiaoming/pykan.git\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83a82c1a-1495-4649-8933-55554a6c723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nimport pandas as pd\\n\\ntest_data_path = os.getenv(\"TEST_DATA_PATH\", \"data/UNSW_NB15_testing-set.csv\")\\ntrain_data_path = os.getenv(\"TRAIN_DATA_PATH\", \"data/UNSW_NB15_training-set.csv\")\\n\\ntest_data = pd.read_csv(test_data_path)\\ntrain_data = pd.read_csv(train_data_path)'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import os\n",
    "import pandas as pd\n",
    "\n",
    "test_data_path = os.getenv(\"TEST_DATA_PATH\", \"data/UNSW_NB15_testing-set.csv\")\n",
    "train_data_path = os.getenv(\"TRAIN_DATA_PATH\", \"data/UNSW_NB15_training-set.csv\")\n",
    "\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "train_data = pd.read_csv(train_data_path)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4b8c325-66b7-446a-96bb-1c7a7a4081d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r\"UNSW_NB15_testing-set.csv\")\n",
    "train_data = pd.read_csv(r\"UNSW_NB15_training-set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b7c5c69-2f13-4a0c-85a9-31b766627069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "#testing out different approach\n",
    "class OutlierTreatmentTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            columns_numeric (list): List of numeric columns to treat for outliers.\n",
    "        \"\"\"\n",
    "        self.iqr_bounds = {}  # Store IQR bounds for each column and class\n",
    "        self.columns_numeric = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Compute IQR bounds for each numeric column grouped by \"attack_cat\".\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The training data.\n",
    "            y (ignored): Not used, present for compatibility.\n",
    "\n",
    "        Returns:\n",
    "            self (OutlierTreatmentTransformer): The fitted transformer.\n",
    "        \"\"\"\n",
    "        print(\"Fitting outlier treatment...\")\n",
    "\n",
    "        # Ensure all numeric columns are cast to float\n",
    "        columns_numeric = X.select_dtypes(include=\"number\").drop(columns=\"id\").columns.tolist()\n",
    "        columns_numeric = [\n",
    "            col for col in columns_numeric\n",
    "            if not len(X[col].value_counts()) < 3\n",
    "        ]\n",
    "        self.columns_numeric = columns_numeric\n",
    "        \n",
    "        for col in columns_numeric:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].astype(float)\n",
    "            else:\n",
    "                raise ValueError(f\"Column '{col}' not found in the input data.\")\n",
    "            \n",
    "\n",
    "        # Process each numeric column\n",
    "        for col in columns_numeric:\n",
    "            self.iqr_bounds[col] = {}\n",
    "\n",
    "            # Group by \"attack_cat\" to calculate class-specific IQR bounds\n",
    "            for attack_cat, group in X.groupby(\"attack_cat\"):\n",
    "                q1 = group[col].quantile(0.25)\n",
    "                q3 = group[col].quantile(0.75)\n",
    "                iqr = q3 - q1\n",
    "                lower_bound = q1 - 1.5 * iqr\n",
    "                upper_bound = q3 + 1.5 * iqr\n",
    "                self.iqr_bounds[col][attack_cat] = (lower_bound, upper_bound)\n",
    "\n",
    "        print(\"Fitting completed.\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Treat outliers in the dataset using the stored IQR bounds.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The data to transform.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The transformed data with outliers treated.\n",
    "        \"\"\"\n",
    "        print(\"Transforming data...\")\n",
    "\n",
    "        # Ensure all numeric columns are cast to float\n",
    "        for col in self.columns_numeric:\n",
    "            if col in X.columns:\n",
    "                X[col] = X[col].astype(float)\n",
    "            else:\n",
    "                raise ValueError(f\"Column '{col}' not found in the input data.\")\n",
    "\n",
    "        # Process each numeric column\n",
    "        for col in self.columns_numeric:\n",
    "            for attack_cat, bounds in self.iqr_bounds[col].items():\n",
    "                lower_bound, upper_bound = bounds\n",
    "\n",
    "                # Get rows for this attack_cat\n",
    "                class_rows = X[X[\"attack_cat\"] == attack_cat]\n",
    "\n",
    "                # Identify outliers\n",
    "                outliers = (class_rows[col] < lower_bound) | (class_rows[col] > upper_bound)\n",
    "\n",
    "                # Replace outliers with the training class mean\n",
    "                replacement_mean = X[X[\"attack_cat\"] == attack_cat][col].mean()\n",
    "                X.loc[class_rows[outliers].index, col] = replacement_mean\n",
    "\n",
    "        print(\"Transformation completed.\")\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "123249e2-ec43-4f27-80f9-267ff8fc9299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting outlier treatment...\n",
      "Fitting completed.\n",
      "Transforming data...\n",
      "Transformation completed.\n",
      "Transforming data...\n",
      "Transformation completed.\n"
     ]
    }
   ],
   "source": [
    "OutlierTreater = OutlierTreatmentTransformer()\n",
    "\n",
    "train_data = OutlierTreater.fit_transform(train_data)\n",
    "test_data = OutlierTreater.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff474af-5c06-498b-98ff-0ee62bfb011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CategoryPruner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_column, threshold=6, debug=False):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            target_column (str): The name of the target column to preserve.\n",
    "            threshold (int): The maximum number of categories to keep for each feature.\n",
    "            debug (bool): Whether to print debug information.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.debug = debug\n",
    "        self.target_column = target_column\n",
    "        self.top_categories = {}  # Store top categories for each feature\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Identify the top categories for each categorical feature in the training data.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The training data.\n",
    "            y (ignored): Not used, present for compatibility.\n",
    "\n",
    "        Returns:\n",
    "            self (CategoryPruner): The fitted transformer.\n",
    "        \"\"\"\n",
    "        # Select categorical columns, excluding the target column\n",
    "        categorical_columns = X.select_dtypes(exclude=[np.number]).drop(columns=[self.target_column], errors='ignore').columns\n",
    "\n",
    "        # Iterate through categorical columns\n",
    "        for feature in categorical_columns:\n",
    "            if self.debug:\n",
    "                print(f\"Processing feature: {feature}\")\n",
    "                print(f\"Number of unique categories before reduction: {X[feature].nunique()}\")\n",
    "                print('----------------------------------------------------')\n",
    "\n",
    "            # Check if the number of unique categories exceeds the threshold\n",
    "            if X[feature].nunique() > self.threshold:\n",
    "                # Identify the top categories in the training data\n",
    "                self.top_categories[feature] = X[feature].value_counts().head(self.threshold).index\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Reduce categories in the dataset to the top categories identified during fitting.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): The data to transform.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The transformed data with reduced categories.\n",
    "        \"\"\"\n",
    "        # Select categorical columns, excluding the target column\n",
    "        categorical_columns = X.select_dtypes(exclude=[np.number]).drop(columns=[self.target_column], errors='ignore').columns\n",
    "\n",
    "        # Iterate through categorical columns\n",
    "        for feature in categorical_columns:\n",
    "            if feature in self.top_categories:\n",
    "                # Reduce data to the top categories, replacing others with '-'\n",
    "                X[feature] = np.where(X[feature].isin(self.top_categories[feature]), X[feature], '-')\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b29cb29f-40ad-42ad-8b04-d09a2d7b2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoryPruner_object = CategoryPruner(target_column = \"attack_cat\").fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd025b0a-5bf1-4a81-87a2-cb3c7ff9b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CategoryPruner_object.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f687a89c-be6d-48f4-be09-a00f28de419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = CategoryPruner_object.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18ff27-7b65-45ea-8fe1-cb662414fe0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
